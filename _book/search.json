[{"path":"index.html","id":"about","chapter":"1 About","heading":"1 About","text":"book dedicated family, Balqisu, Nyarko Ekuba.young scientists benefit book colleagues , every way, helped write , say big thank . motivation comes dire urgent need many, especially developing countries, use freely available yet sophisticated statistical software analysing clinical data. regions buying statistical software often affordable people, R comes great relief. huge gap theoretical practical knowledge statistical applications many scientists. R, open-source statistical software, offers unique vital opportunity bridge gap.book introduces data analysis R persons little knowledge . step--step introduction data analysis R deliberately organised limited text many practical examples.Readers briefly introduced R RStudio. Required packages used chapters require . However, using function package explained.","code":""},{"path":"introduction.html","id":"introduction","chapter":"2 Introduction","heading":"2 Introduction","text":"","code":""},{"path":"introduction.html","id":"the-statistical-data-analyst","chapter":"2 Introduction","heading":"2.1 The statistical data analyst","text":"Statistical data analysis just using computer software generate results. involves basic understanding data type best way analyse present data make meaning general population. Thus, data analyst:Must understand genesis (study methodology) involved obtaining data first place. conclusion data may differ depending study methodology used hypothesis tested. prudent, therefore, statistical data analyst involved data collection process right beginning.able point errors data collection process early stages. avoids wasting valuable resources data may answer question.Provide valuable advice best method analysing data hand.Perform analysis scientifically soundly applying current statistically appropriate principles.Present result analysis manner makes easy persons without statistical analytical expertise understand least effort. requires statistical data analyst position explain analysis common language.Finally, data analyst must know limit. often instances analyst seek ”professional” help, even though may feel right path. never hurts seek second opinion peers.\n, therefore, goes without saying prior discussion data analyst must firm understanding statistical research methodology.","code":""},{"path":"introduction.html","id":"statistical-software","chapter":"2 Introduction","heading":"2.2 Statistical software","text":"years back, statistical analysis one tedious processes done mainly dedicated statisticians. advent computers statistical software, become rather handy, many advantages disadvantages.\nmain advantages :\n1. tremendous speed large data processed results obtained.\n1. accuracy statistical calculations performed. Computers make mistakes one beware rounding software. software can perform calculations specific number decimal places. Therefore, one confronted figure 1.00377655432, software may work 1.0037765, leaving last four digits. Calculations using truncated value likely different result non-truncated figure, thus affecting accuracy final result.\n1. Many modern statistical software can read data varied sources formats. makes easy transfer data one software another without re-enter data collected second computer software. transferability enabled use digital equipment smartphones, personal digital assistants tablets data collection. Data collected manner said ready cleaning analysis, bypassing data entry stage.\n1. Plotting graphs one important uses modern-day computerised data analysis. Statistical software tends make rather tedious process almost hassle-free accords us ability redo plot scratch click button.Despite advantages, many disadvantages also inherent use computers statistical software. include:Many people little statistical knowledge can manipulate data come conclusions often tend spurious. cliche ”Garbage Garbage ” apply better situation.Many commonly used software tend reliable accurate. large number often user-written statistical software freely available online, one needs cautious output generated. wrongly written codes errors, thus producing faulty results.Unfortunately, used, reliable accurate statistical software tends expensive well. notwithstanding, , R, combine free open source versatility reliability. forms basis choice R book.","code":""},{"path":"introduction.html","id":"obtaining-and-installing-r","chapter":"2 Introduction","heading":"2.3 Obtaining and installing R","text":"R free software programming language environment data manipulation, calculation graphical display. can run Windows, MacOS X Unix systems. great applications many academic fields, including mathematics, economics epidemiology. capability enhanced many packages written individuals years. R great advantage able handle many datasets simultaneously. However, functionality comes cost, discussed subsequent chapters. R also great graphics functionality requires practice.Several advanced statistical mathematical functions, regression survival analysis, also implemented R.\nR many packages obtainable free http://cran.r-project.org/. current version time writing book R-4.2.1. Windows operating system version can installed 32 64-bit operating systems. Download base file https://cran.r-project.org/bin/windows/base/, save computer install , preferably administrator, following -screen instructions.","code":""},{"path":"introduction.html","id":"obtaining-and-installing-rstudio","chapter":"2 Introduction","heading":"2.4 Obtaining and installing RStudio","text":"RStudio Integrated Development Environment R software Python. provides interface adds functionality automation R. downloadable https://posit.co/download/rstudio-desktop/. two forms, desktop version Server version used within web browser. simplicity easy following processes book, preferable download install RStudio.","code":""},{"path":"statistical-data-types.html","id":"statistical-data-types","chapter":"3 Statistical data types","heading":"3 Statistical data types","text":"begin proper data analysis revising statistical data types . two broad types data; Quantitative Qualitative","code":""},{"path":"statistical-data-types.html","id":"qualitative-data","chapter":"3 Statistical data types","heading":"3.1 Qualitative data","text":"data type, observations fall distinctive categories. \nusually scale applicable qualitative data type. divided :","code":""},{"path":"statistical-data-types.html","id":"nominal","chapter":"3 Statistical data types","heading":"3.1.1 Nominal","text":"qualitative data types order. colors flag instance can ”red” ”yellow” ”green”. None can said coming . Contrast one immediately .","code":""},{"path":"statistical-data-types.html","id":"binary","chapter":"3 Statistical data types","heading":"3.1.2 Binary","text":"special type nominal data type binary data. common statistical analysis. observations can take two values. question instance records presence disease ”Yes” ”” answer. Sex usually recorded ”Male” ”Female”.","code":""},{"path":"statistical-data-types.html","id":"ordinal","chapter":"3 Statistical data types","heading":"3.1.3 Ordinal","text":"ordinal qualitative data type order . commonly used one socioeconomic status, often categorised ”Low”, ”Middle” ”High”. Although say interval ”Low” ”Middle” ”Middle” ”High”, know ”Low” lower ”Middle” turn also lower ”High”. Likert scale, well-known scale many social science research also example ordinal scale. Ordinal variables often created quantitative (see )variables. E.g. ages group men\ncan converted age groups desired number categories.","code":""},{"path":"statistical-data-types.html","id":"quantitative-data","chapter":"3 Statistical data types","heading":"3.2 Quantitative data","text":"Quantitative numerical data observations numbers can measured. two types:","code":""},{"path":"statistical-data-types.html","id":"discrete","chapter":"3 Statistical data types","heading":"3.2.1 Discrete","text":"Discrete quantitative data one specific values can obtained. number persons attending theatre can whole number. number votes obtained election. Although discrete quantitative variables often analysed continuous ones can occasionally pose problems analysed . dealing subsequent chapters.","code":""},{"path":"statistical-data-types.html","id":"continuous","chapter":"3 Statistical data types","heading":"3.2.2 Continuous","text":"Continuous quantitative variables hand can measured precision, thereby making figures present precise experimenter desires. instance, distance two towns can measured kilometres much precision possible. Theoretically, can 12.0kms much 12.0234278kms.","code":""},{"path":"statistical-data-types.html","id":"other-specific-data-types","chapter":"3 Statistical data types","heading":"3.3 Other specific data types","text":"specific subtypes data encountered statistical analysis. :","code":""},{"path":"statistical-data-types.html","id":"ratios","chapter":"3 Statistical data types","heading":"3.3.1 Ratios","text":"Ratios special continuous variables generated two variables. example, ratio boys girls sample can determined dividing number boys girls. figures obtained similar continuous variables require special techniques analysis.","code":""},{"path":"statistical-data-types.html","id":"rates","chapter":"3 Statistical data types","heading":"3.3.2 Rates","text":"Rates population parameters often used medicine epidemiology. Examples include population growth rate mortality rate. also statistic parameter generated two\nothers. mortality rate generated instance number deaths time interval. case neonatal mortality rate, generated number deaths number live births period. analysis, often treated indicated ratios .","code":""},{"path":"statistical-data-types.html","id":"percentage","chapter":"3 Statistical data types","heading":"3.3.3 Percentage","text":"Percentages peculiar often definite maximum minimum 0% 100% respectively. However, percentage changes can take value. instance, change 4 3 yield negative (-25%) change. avoid tedious nature percentages advisable often retain work specific values involved determining percentage rather percentages derived.","code":""},{"path":"statistical-data-types.html","id":"ranks","chapter":"3 Statistical data types","heading":"3.3.4 Ranks","text":"Ranks often treated continuous variables though often . well-known example position student class test. position just relative others differs actual mark scored. ranks may give impression equal space consecutive ranks actual difference may much smaller bigger rank difference.","code":""},{"path":"r-data-types.html","id":"r-data-types","chapter":"4 R data types","heading":"4 R data types","text":"data objects R made smaller units referred ”Atomic” data.\nvarious atomic data types Integer, Double, Complex, Logical,\nCharacter, Factor Date Time. explained\nsubsequently. determine data types R commonly used function\nclass(). example uses function determine data type \n4.2.expected numeric variable. Next, determine class data\n””R classifies character data type. Finally, FALSE?logical data type.","code":"class(4.2)\n[1] \"numeric\"class(\"A\")\n[1] \"character\"class(FALSE)\n[1] \"logical\""},{"path":"r-data-types.html","id":"integer","chapter":"4 R data types","heading":"4.1 Integer","text":"integer data types made numeric variables can counted,\nsimilar discrete quantitative variable described . default, R\nstore numbers integers may arise situations numbers\nconverted integers facilitate manipulations. determine\ndata class integer use function .integer(). convert data\nanother type integer use function .integer(). illustration,\ndetermine number 9 R integer. first, assign number 9\nX ask X stored integer.! Next, convert integer, time calling Y. find\n.integer now.","code":"X <- 9\nis.integer(X)\n[1] FALSEY <- as.integer(X)\nis.integer(Y)\n[1] TRUE"},{"path":"r-data-types.html","id":"double","chapter":"4 R data types","heading":"4.2 Double","text":"number can take value including decimals, similar \ncontinuous quantitative variable discussed . Double default type\nnumeric variable used R. illustrate point let’s look \nproperties number 7.1 R. First assign name “” 7.1.find class “Double”.Numeric data types stored double never stored exact rather \napproximations real numbers. illustrate , add three test \nanswer 21.3It may appear strange adding 7.1 three times equal 21.3. \nstored approximate exact. \nimportant manipulating data R many statistical software.","code":"\nA <- 7.1is.double(A)\n[1] TRUE21.3 == A + A + A \n[1] FALSE"},{"path":"r-data-types.html","id":"logical","chapter":"4 R data types","heading":"4.3 Logical","text":"Logical object stored TRUE FALSE. example shows \ncreation “Z” statement asking 5 less 8. Z, therefore, \nlogical (TRUE) data type. First, assign values 5 8 X Y\nrespectively create logical data type Z asking X less \nY R.Next, determine class ZLogical objects innate values R FALSE considered \nvalue 0 TRUE value 1. output demonstrates .Apart “<” operator used example logical\noperators R. following examples illustrate use logical\noperators. begin assigning ages man wife 45 23\nyears, respectively.Next, use answer basic questions couple. First, \nask wife’s age less equal 35Next, ask husband greater equal 45 yearsThe next example combines three logical operators. ask wife \nless 25 years time, husband greater 35 yearsFinally, ask whether wife less 25 years husband greater\n50 years","code":"X <- 5\nY <- 8\nZ <- X < Y\nZ\n[1] TRUEclass(Z)\n[1] \"logical\"FALSE + FALSE\n[1] 0\nFALSE + TRUE\n[1] 1\nTRUE + TRUE\n[1] 2\nwife <- 23\nhusband <- 45wife <= 34\n[1] TRUEhusband >= 45\n[1] TRUE(wife < 25) & (husband > 35)\n[1] TRUE(wife < 25) | (husband > 50)\n[1] TRUE"},{"path":"r-data-types.html","id":"character","chapter":"4 R data types","heading":"4.4 Character","text":"Character object enclosed double quotes. called strings \nnames used mathematical calculations. Examples include “red”,\n“Male”, “1”. seen, “1” (different number 1) character \nused calculations unless converted another object form \ninteger double. illustrate creating two characters belowAnd determine class.illustrate “2” character added, doHowever, can convert B numeric variable C using function .numeric().can now use numeric variable C calculations ","code":"\nA <- \"x\"\nB <- \"2\"class(A)\n[1] \"character\"\nclass(B)\n[1] \"character\"B + B\nError in B + B: non-numeric argument to binary operatorC <- as.numeric(B)\nclass(C)\n[1] \"numeric\"C + C\n[1] 4"},{"path":"r-data-types.html","id":"factor","chapter":"4 R data types","heading":"4.5 Factor","text":"Factor R categorical variable sex (male & female). Factor\nvariables levels representing different categories. Sex naturally \ntwo levels, Male, Female. Factors can derived numeric character\nobjects using .factor(). form character variable length four\ncalled blood.grp using one used functions R c().convert factor variableNext, determine categories (levels) factor variable using \nfunction levels()Often, becomes necessary factor variables converted integer\nretaining order categories appear. instance, one may\nfactor variable levels “”, “B”, “C”, “D” wants convert\ninteger variable , B, C D represented 1, 2, 3 \n4. achieved R unclassing. Unclassing factor variable assigns\nnumbers, starting 1 levels factors order \nlevels. output shows unclassed numbers factor blood.grp2\nlevels refer . use unclass() function.useful function R generate factor variable gl(). generates\nfactor variable specified number levels (n) replications (k). \npractical example shown . Factor fac.1 created forming vector\nthree levels two replications.factor can also created labels shown","code":"blood.grp <- c(\"O\", \"AB\", \"B\", \"A\")\nclass(blood.grp)\n[1] \"character\"blood.grp2 <- as.factor(blood.grp)\nclass(blood.grp2) \n[1] \"factor\"levels(blood.grp2) \n[1] \"A\"  \"AB\" \"B\"  \"O\" unclass(blood.grp2)\n[1] 4 2 3 1\nattr(,\"levels\")\n[1] \"A\"  \"AB\" \"B\"  \"O\" fac.1 <- gl(n=3, k=2)\nfac.1\n[1] 1 1 2 2 3 3\nLevels: 1 2 3fac.2 <- gl(n=3, k=2, label=c(\"Apple\", \"Mango\",\" Pear\"))\nfac.2\n[1] Apple Apple Mango Mango  Pear  Pear\nLevels: Apple Mango  Pear"},{"path":"r-data-types.html","id":"ordered-factor","chapter":"4 R data types","heading":"4.6 Ordered Factor","text":"order factor important must declared ordered factor,\nalso known ordinal categorical variable explained earlier chapter.\ncreate character variable.Next, convert ordered factor using function ordered().ordered factor variable can also derived using gl() function introduced .","code":"size <- c(\"Medium\", \"Large\", \"Small\", \"Medium\")\nclass(size)\n[1] \"character\"ord.size <- ordered(size, levels=c(\"Small\", \"Medium\", \"Large\"))\nord.size\n[1] Medium Large  Small  Medium\nLevels: Small < Medium < Large\nclass(ord.size)\n[1] \"ordered\" \"factor\" fac.3 <- gl(n=3, k=2, ordered=TRUE, label=c(\"Small\", \"Medium\", \"Large\"))\nfac.3\n[1] Small  Small  Medium Medium Large  Large \nLevels: Small < Medium < Large"},{"path":"r-data-types.html","id":"date-and-time","chapter":"4 R data types","heading":"4.7 Date and time","text":"Date Time objects last discussed section. can \ncreated functionsas.Date(), .POSIXct(), .POSIXlt(), strptime(), ISOdatetime() ISOdate().date time data creation require use character data \n“format”. format dictates function format character\ndata recorded .e. dd/mm/yy, mm/dd/yyyy, yyyy/mm/dd hh:mm:ss etc. \nformats declared % symbol.first object create class “Date” created using \ncharacter object “01/01/1970”. first create character objectNext, convert character object Date objectNote format specified. day, month year preceded %\nsymbol. symbols separate values dates also specified\naccordingly. Next, derive object class Date time referred\nR POSIXct POSIXlt. Though referred “Date Time” \ncan Date Date Time specified formats. create \nPOSIXct Date format.Next, create Date Time variable shows date timeThe next example uses function strptime() create “POSIXlt” DateTime\nformat data.Next, use ISOdatetime() create “POSIXct” DateTime format data type.\nNote two functions ISOdatetime() ISOdate() take individual\nnumeric values combine rather convert character variables.finally function ISOdate()Mathematical manipulations can done date objects. Subtracting one date\nyields object period two. object\nclass difftime. illustration, determine time difference\ndt5 dt6It worth noting function R, difftime() specifically\ndesigned finding time differences.functions weekdays(), months() quarters() extract “character”\ndatatype days, months quarters date objects respectively.","code":"dt.str <- \"01/01/1970\"\nclass(dt.str)\n[1] \"character\"dt1<-as.Date(dt.str, format=\"%d/%m/%Y\")\ndt1\n[1] \"1970-01-01\"\nclass(dt1)\n[1] \"Date\"dt2 <- as.POSIXct(\"2003-01-23\")\ndt2\n[1] \"2003-01-23 GMT\"\nclass(dt2)\n[1] \"POSIXct\" \"POSIXt\" dt3 <- as.POSIXct(\"2003-04-23 15:34\")\ndt3\n[1] \"2003-04-23 15:34:00 GMT\"\nclass(dt3)\n[1] \"POSIXct\" \"POSIXt\" dt4<-strptime(\"02/27/92 11:30:10\", format=\"%m/%d/%y %H:%M:%S\")\ndt4\n[1] \"1992-02-27 11:30:10 GMT\"\nclass(dt4)\n[1] \"POSIXlt\" \"POSIXt\" dt5<-ISOdatetime(\n    year=2013, month=4, day=7, hour = 12, min = 33, sec = 10, tz = \"GMT\"\n    )\ndt5\n[1] \"2013-04-07 12:33:10 GMT\"\nclass(dt5)\n[1] \"POSIXct\" \"POSIXt\" dt6 <- ISOdate(year = 2013, month = 4, day = 7, tz = \"GMT\")\ndt6\n[1] \"2013-04-07 12:00:00 GMT\"\nclass(dt6)\n[1] \"POSIXct\" \"POSIXt\" dt5-dt6\nTime difference of 33.16667 minsweekdays(dt2)\n[1] \"Thursday\"\nquarters(dt2)\n[1] \"Q1\"\nmonths(dt2)\n[1] \"January\""},{"path":"r-data-types.html","id":"missing-values-in-r","chapter":"4 R data types","heading":"4.8 Missing values in R","text":"R missing values denoted NA. NaN also encountered stands \n“number”. often generated one divides instance 0 0.\noperation involving NA results NA. Examples shown belowThe function .na() produces logical indicates value missing.","code":"1 + NA\n[1] NA\nNA - 1\n[1] NA\nNA*2\n[1] NAis.na(2)\n[1] FALSE\nis.na(NA)\n[1] TRUE"},{"path":"data-structures-in-r.html","id":"data-structures-in-r","chapter":"5 Data Structures in R","heading":"5 Data Structures in R","text":"introduced R described variable types research R. Data\nstructures composite various atomic types described \npreceding chapter.Different data structures R include Vector, Matrix, Array, List, Data frame\nTime-series. data needs specific structure perform\nappropriate analysis.","code":""},{"path":"data-structures-in-r.html","id":"vectors","chapter":"5 Data Structures in R","heading":"5.1 Vectors","text":"vector simplest data structure R. made collection \nlike data types mentioned preceding chapter. numerous functions\nR capable creating vectors. c() function generic function \ncombines objects vector first converting data type.\ncreate numeric vector \nlength 10 using c() function.create integer vector sequence can use.Next, use seq() function create sequence numbers C, 0 \n20 intervals 2.vector repeated sequences atomic values can created using rep()\nfunction. repeat “B” ten times form vector length 10, \nelements “B”.R base package two functions can generate vector alphabets \neither lowercase upper cases. areA sequence dates vector can also created.Finally, vector specified length atomic type can created use\nvector() function.Mathematical operations vectors carried element \nvector. instance, dividing vector 2 means every element \nvector divided 2. First, create vector numbers 1 10And divide vector X 2 form YNext, square vector call resulting vector ZNote X divided 2 every member vector halved.\nSimilarly squaring vector meant resulting vector Z elements \nsquares X.","code":"A <- c(3, 2, 4, 5, 6, 2, 3, 1, 7, 9) \nA\n [1] 3 2 4 5 6 2 3 1 7 9B <- 1:10 \nB\n [1]  1  2  3  4  5  6  7  8  9 10C <- seq(from = 0, to = 20, by = 2) \nC\n [1]  0  2  4  6  8 10 12 14 16 18 20D <- rep(\"B\", times = 10) \nD\n [1] \"B\" \"B\" \"B\" \"B\" \"B\" \"B\" \"B\" \"B\" \"B\" \"B\"letters[1:12] \n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\"\nLETTERS[1:12]\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\"seq(as.POSIXct(\"2003-04-23\"), by = \"month\", length = 12)\n [1] \"2003-04-23 GMT\" \"2003-05-23 GMT\" \"2003-06-23 GMT\"\n [4] \"2003-07-23 GMT\" \"2003-08-23 GMT\" \"2003-09-23 GMT\"\n [7] \"2003-10-23 GMT\" \"2003-11-23 GMT\" \"2003-12-23 GMT\"\n[10] \"2004-01-23 GMT\" \"2004-02-23 GMT\" \"2004-03-23 GMT\"E <- vector(mode = \"integer\", length = 7)\nE\n[1] 0 0 0 0 0 0 0X <- 1:10\nX\n [1]  1  2  3  4  5  6  7  8  9 10Y <- X/2\nY\n [1] 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0Z <- X^2\nZ\n [1]   1   4   9  16  25  36  49  64  81 100"},{"path":"data-structures-in-r.html","id":"matrices","chapter":"5 Data Structures in R","heading":"5.2 Matrices","text":"Matrices vectors arranged two dimensions made rows columns\n(r,c). example 3 x 5 matrix (matrix three rows five\ncolumns)\\[\nC =\\begin{bmatrix}\n1 & 2 & 3 & 4 & 5 \\\\\n3 & 4 & 5 & 6 & 7 \\\\\n5 & 4 & 3 & 4 & 8\n\\end{bmatrix}\n\\]several ways matrices can created R. just one .\nFirst, can create vectors combine row using rbind(). begin\ncreating three vectors naming desired row names \nmatrixAnd bind together form matrixmat4 row names column names. therefore go\nahead name columns matrix using function colnames()","code":"\nRow1 <- c(1, 2, 3, 4, 5)\nRow2 <- c(3, 4, 5, 6, 7)\nRow3 <- c(5, 4, 3, 4, 8)mat4 <- rbind(Row1, Row2, Row3)\nmat4\n     [,1] [,2] [,3] [,4] [,5]\nRow1    1    2    3    4    5\nRow2    3    4    5    6    7\nRow3    5    4    3    4    8colnames(mat4) <- c(\"Col1\", \"Col2\", \"Col3\", \"Col4\", \"Col5\")\nmat4\n     Col1 Col2 Col3 Col4 Col5\nRow1    1    2    3    4    5\nRow2    3    4    5    6    7\nRow3    5    4    3    4    8"},{"path":"data-structures-in-r.html","id":"arrays","chapter":"5 Data Structures in R","heading":"5.3 Arrays","text":"array vector two dimensions. can created assigning dimensions vector using array() function. creation three-dimensional array illustrated .mathematical manipulations applicable vectors also applicable \nmatrices arrays. Matrices, however, can used matrix algebra \nfield mathematics statistics. beyond scope book \ndiscussed .","code":"Y <- array(X, \n           dim = c(2,3,2), \n           dimnames = list(\n               Sex = c(\"M\", \"F\"), \n               Color = c(\"red\", \"blue\", \"green\"), \n               Age=c(\"<30yrs\",\">=30yrs\")\n               )\n           )\nY\n, , Age = <30yrs\n\n   Color\nSex red blue green\n  M   1    3     5\n  F   2    4     6\n\n, , Age = >=30yrs\n\n   Color\nSex red blue green\n  M   7    9     1\n  F   8   10     2\nclass(Y)\n[1] \"array\""},{"path":"data-structures-in-r.html","id":"data-frame","chapter":"5 Data Structures in R","heading":"5.4 Data frame","text":"data frame important object R. ’s used numerous\nstatistical manipulations. Compared matrices arrays columns\nclass, data frames can various columns \ndifferent classes. standard statistical datasets manipulated R \ndata frames. example data frame can created R using function\ndata.frame(). first create four different vectors sex, age,\ncolour old.Next, combine four vectors data frameNext, check structure data frame function str().output indicates 4 variables 10 records. Also, describes\nclasses various variables, giving examples per variable.","code":"\nsex <- gl(n = 2, k = 5, label = c(\"Male\",\"Female\")) \nage <- c(5, 2, 5, 6, 5, 6, 7, 8, 7, 7) \ncolor <- rep(c(\"Red\", \"Blue\"), times=5) \nold <- age > 6df1 <- data.frame(sex, age, color, old) \ndf1\n      sex age color   old\n1    Male   5   Red FALSE\n2    Male   2  Blue FALSE\n3    Male   5   Red FALSE\n4    Male   6  Blue FALSE\n5    Male   5   Red FALSE\n6  Female   6  Blue FALSE\n7  Female   7   Red  TRUE\n8  Female   8  Blue  TRUE\n9  Female   7   Red  TRUE\n10 Female   7  Blue  TRUEstr(df1)\n'data.frame':   10 obs. of  4 variables:\n $ sex  : Factor w/ 2 levels \"Male\",\"Female\": 1 1 1 1 1 2 2 2 2 2\n $ age  : num  5 2 5 6 5 6 7 8 7 7\n $ color: chr  \"Red\" \"Blue\" \"Red\" \"Blue\" ...\n $ old  : logi  FALSE FALSE FALSE FALSE FALSE FALSE ..."},{"path":"data-structures-in-r.html","id":"list","chapter":"5 Data Structures in R","heading":"5.5 List","text":"R, list set different elements objects put together. \nsimilar data frame components can made objects \nvector. include matrices, arrays, data frames etc. create \nlist called list1 made three elements using list() function.\nfirst data frame called DF. second numeric vector length\n5 called Vec last character called Color.","code":"list1 <- list(DF = df1,  Vec =1 :5, Color = \"Red\")\nlist1\n$DF\n      sex age color   old\n1    Male   5   Red FALSE\n2    Male   2  Blue FALSE\n3    Male   5   Red FALSE\n4    Male   6  Blue FALSE\n5    Male   5   Red FALSE\n6  Female   6  Blue FALSE\n7  Female   7   Red  TRUE\n8  Female   8  Blue  TRUE\n9  Female   7   Red  TRUE\n10 Female   7  Blue  TRUE\n\n$Vec\n[1] 1 2 3 4 5\n\n$Color\n[1] \"Red\""},{"path":"data-structures-in-r.html","id":"tables","chapter":"5 Data Structures in R","heading":"5.6 Tables","text":"Tables objects display frequencies. use popular \nstatistical mathematical literature. Tables can constructed many ways\nR using function table(). can also created objects\narrays matrices using .table(). simplest form table \ncount frequency occurrence elements vector.outpatient clinic hospital Accra, Ghana, 8 patients randomly\nselected sex noted. recorded vector Gender\n.determine frequencies different sexes tabulate vector\nyielding table object, table.1.result indicates five males three females selected\npatients. function .table() determines object table. Though\nknow table.1 table test belowContingency tables, cross-tabulation two variables vectors \ncommon research. vectors represent data randomly selected\n8 pupils basic school Ghana. Four pens randomly given \npupils. vector Sex recording sex Pen indicates \npupil given pen . create two vectors.Next, cross-tabulate using table() function.output indicates three females two pens.\nAlso, five males two pens given .","code":"Sex <- c(\"Male\",  \"Female\",  \"Female\",  \"Male\",  \"Male\", \"Female\", \"Male\", \"Male\")\nSex\n[1] \"Male\"   \"Female\" \"Female\" \"Male\"   \"Male\"   \"Female\"\n[7] \"Male\"   \"Male\"  table.1 <- table(Sex)\ntable.1\nSex\nFemale   Male \n     3      5 is.table(table.1)\n[1] TRUE\nSex<-c(\"Male\", \"Female\", \"Female\", \"Male\", \"Male\", \"Female\", \"Male\", \"Male\")\nPen<-c(\"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"No\")table(Sex, Pen)\n        Pen\nSex      No Yes\n  Female  1   2\n  Male    3   2\nPen\n[1] \"No\"  \"Yes\" \"Yes\" \"Yes\" \"Yes\" \"No\"  \"No\"  \"No\" "},{"path":"importing-data-into-r.html","id":"importing-data-into-r","chapter":"6 Importing data into R","heading":"6 Importing data into R","text":"chapter, discuss ways getting data R, either directly entering R importing another software. R, data frame data structure desirable data analysis. advent tidy data, tibble now predominant data structure used. section, reading various file formats presenting tibble.","code":""},{"path":"importing-data-into-r.html","id":"using-data-in-r-packages","chapter":"6 Importing data into R","heading":"6.1 Using data in R packages","text":"Many packages R come data can used practice. able use dataset specific package package first installed. instance, able use data Oswego data native package epiDisplay first ensure package installed running command line :Note install package packages epiDisplay package depends .next step make data available R session belowNow data available working environment, can visualise first 6 rows belowTable 6.1:  finally visualise details data using help() function ","code":"\ninstall.packages(\"epiDisplay\")\ndata(\"Oswego\", package = \"epiDisplay\")\nOswego %>% head()\nhelp(Oswego)"},{"path":"importing-data-into-r.html","id":"direct-entry-into-r","chapter":"6 Importing data into R","heading":"6.2 Direct entry into R","text":"first use data.frame() function base package create data frame.Table 6.2:  first describe manually enter data R. aim create tibble using tibble function.Table 6.3:  ","code":"\ndata.frame(\n    name = c(\"Ama\", \"Yakubu\", \"John\"), \n    sex = c(\"Female\", \"Male\", \"Male\"),\n    age = c(12, 9, 4),\n    school = c(\"JHS\", \"Primary\", \"Creche\")\n    )\ntibble(\n    name = c(\"Ama\", \"Yakubu\", \"John\"), \n    sex = c(\"Female\", \"Male\", \"Male\"),\n    age = c(12, 9, 4),\n    school = c(\"JHS\", \"Primary\", \"Creche\")\n    )"},{"path":"importing-data-into-r.html","id":"r-data-file","chapter":"6 Importing data into R","heading":"6.3 R data file","text":"working R, frequent mode storage data .Rdata file. preserves structure environment data. read already saved .Rdata file.visualise first 4 rows single data within loaded file called data1_stataTable 6.4:  ","code":"load(file = \"./Data/data1.Rdata\")\nls()\n[1] \"data1_stata\" \"Oswego\"     \ndata1_stata %>% head(n=4)"},{"path":"importing-data-into-r.html","id":"text-files","chapter":"6 Importing data into R","heading":"6.4 Text files","text":"first file format going read flat file text file. usually extension .txt. data files separated various delimiters. include tabs, commas, spaces, etc. section, read one tab delimiter prototype rest similar.Table 6.5:  last file read subsection comma-delimited text fileTable 6.6:  Comma-delimited files extension .csv can also imported commnandsTable 6.7:  ","code":"\nread_delim(\n    file = \"./Data/bpA.txt\", \n    delim = \"\\t\", \n    col_types = c(\"c\", \"c\", \"d\", \"d\")\n    )\nread_delim(\n    file = \"./Data/blood.txt\", \n    delim = \",\", \n    col_types = c(\"c\", \"d\", \"d\", \"d\", \"d\", \"d\", \"d\")\n    ) %>% \n    head(n=4)\nread_csv(\n    file = \"./Data/blood.txt\",\n    col_types = c(\"c\", \"d\", \"d\", \"d\", \"d\", \"d\", \"d\")) %>% \n    head(n=4)"},{"path":"importing-data-into-r.html","id":"microsoft-excel","chapter":"6 Importing data into R","heading":"6.5 Microsoft Excel","text":"Probably common format transferring data Microsoft Excel. two versions Excel extensions .xls .xlsx. reading .xlsx demonstrated using readxl package.Table 6.8:  ","code":"\nreadxl::read_xlsx(path = \"./Data/data1.xlsx\") %>% \n    head(n=4)"},{"path":"importing-data-into-r.html","id":"spss-files","chapter":"6 Importing data into R","heading":"6.6 SPSS files","text":"Files SPSS usually saved extension .sav. read SSPSS data file using haven packageTable 6.9:  ","code":"\nhaven::read_sav(file = \"./Data/data1.sav\") %>% \n    head(n=4)"},{"path":"importing-data-into-r.html","id":"stata-files","chapter":"6 Importing data into R","heading":"6.7 Stata files","text":"Stata files, similar SPSS data files can imported using haven package. illustrated belowTable 6.10:  ","code":"\nhaven::read_dta(file = \"./Data/data1.dta\") %>% \n    head(n=4)"},{"path":"importing-data-into-r.html","id":"sas-files","chapter":"6 Importing data into R","heading":"6.8 SAS files","text":"haven package also offers ability read R SAS data file. illustrated belowTable 6.11:  ","code":"\nhaven::read_sas(data_file = \"./Data/data1.sas7bdat\") %>% \n    head(n=4)"},{"path":"importing-data-into-r.html","id":"conclusion","chapter":"6 Importing data into R","heading":"6.9 Conclusion","text":"section, learned import data R various file formats programs. next section, learn export data R file formats.","code":""},{"path":"data-wrangling.html","id":"data-wrangling","chapter":"7 Data wrangling","heading":"7 Data wrangling","text":"chapter, begin delve manipulation data form \ndata frame tibble. , introduce tidyverse package\nvarious verbs (function) provides.tidyverse package just single package composite group\npackages. include among others dplyr package. function\nemploying chapter comes dplyr.begin reading blood_donors.xlsThe output shows 25-row 6-column tibble.","code":"df_blood <- readxl::read_xls(\"./Data/blood_donors_1.xls\")\ndf_blood\n# A tibble: 25 × 6\n      id    hb   hct sex   bldgrp pdonor\n   <dbl> <dbl> <dbl> <chr> <chr>   <dbl>\n 1     1 10.5   31.8 Male  O           3\n 2     2 11.9   37.2 Male  AB          0\n 3     3  1     26   Male  A           1\n 4     4  8.90  26.8 Male  A           3\n 5     5  7.80  24.2 Male  A           2\n 6     6 10     30.9 Male  B           1\n 7     7 10.4   33.9 Male  B           0\n 8     8 11.3   35   Male  O           1\n 9     9 16.4   NA   Male  AB          1\n10    10 14.4   43.6 Male  AB          1\n# ℹ 15 more rows"},{"path":"data-wrangling.html","id":"renaming-variables","chapter":"7 Data wrangling","heading":"7.1 Renaming variables","text":"rename variables hb hemog id studyid using \nrename function, show first 5 records head function.","code":"df_blood %>% \n    rename(hemog = hb, studyid = id) %>% \n    head(5)\n# A tibble: 5 × 6\n  studyid hemog   hct sex   bldgrp pdonor\n    <dbl> <dbl> <dbl> <chr> <chr>   <dbl>\n1       1 10.5   31.8 Male  O           3\n2       2 11.9   37.2 Male  AB          0\n3       3  1     26   Male  A           1\n4       4  8.90  26.8 Male  A           3\n5       5  7.80  24.2 Male  A           2"},{"path":"data-wrangling.html","id":"sorting-data","chapter":"7 Data wrangling","heading":"7.2 Sorting data","text":"use arrange function sort bldgrp ascending order \nhb descending order.","code":"df_blood %>% \n    arrange(bldgrp, desc(hb))\n# A tibble: 25 × 6\n      id    hb   hct sex    bldgrp pdonor\n   <dbl> <dbl> <dbl> <chr>  <chr>   <dbl>\n 1    17  9.80  30.5 Female A           4\n 2    21  9.10  28.0 <NA>   A           3\n 3     4  8.90  26.8 Male   A           3\n 4     5  7.80  24.2 Male   A           2\n 5     3  1     26   Male   A           1\n 6     9 16.4   NA   Male   AB          1\n 7    10 14.4   43.6 Male   AB          1\n 8    16 12.7   99   Female AB          0\n 9    24 12.3   38.2 <NA>   AB          2\n10    14 12.2   36.8 Female AB          1\n# ℹ 15 more rows"},{"path":"data-wrangling.html","id":"subsetting-data","chapter":"7 Data wrangling","heading":"7.3 Subsetting data","text":"subsection, demonstrate use filter select function\nselect specific records variables tibble. filter select\nrecords hb > 12g/dl keep id, hb sex\ncolumns.","code":"df_blood %>% \n    filter(hb > 12) %>% \n    select(id, hb, sex)\n# A tibble: 6 × 3\n     id    hb sex   \n  <dbl> <dbl> <chr> \n1     9  16.4 Male  \n2    10  14.4 Male  \n3    14  12.2 Female\n4    14  16.4 Female\n5    16  12.7 Female\n6    24  12.3 <NA>  "},{"path":"data-wrangling.html","id":"generating-new-variables","chapter":"7 Data wrangling","heading":"7.4 Generating new variables","text":"generate new variables use mutate function. Based knowledge\nhematocrit approximately three times haemoglobin generate\nnew variable, hb_from_hct.","code":"df_blood %>% \n    mutate(hb_from_hct = hct/3)\n# A tibble: 25 × 7\n      id    hb   hct sex   bldgrp pdonor hb_from_hct\n   <dbl> <dbl> <dbl> <chr> <chr>   <dbl>       <dbl>\n 1     1 10.5   31.8 Male  O           3       10.6 \n 2     2 11.9   37.2 Male  AB          0       12.4 \n 3     3  1     26   Male  A           1        8.67\n 4     4  8.90  26.8 Male  A           3        8.93\n 5     5  7.80  24.2 Male  A           2        8.07\n 6     6 10     30.9 Male  B           1       10.3 \n 7     7 10.4   33.9 Male  B           0       11.3 \n 8     8 11.3   35   Male  O           1       11.7 \n 9     9 16.4   NA   Male  AB          1       NA   \n10    10 14.4   43.6 Male  AB          1       14.5 \n# ℹ 15 more rows"},{"path":"data-wrangling.html","id":"aggregating-data","chapter":"7 Data wrangling","heading":"7.5 Aggregating data","text":"Data can aggregated R using summarize function. determine\nmean standard deviation haemoglobin patient data.Grouping data “bldgrp” aggregation yields aggregated\nmeans standard deviations various blood groups.","code":"df_blood %>% \n    summarize(mean_hb = mean(hb), sd_hb = sd(hb))\n# A tibble: 1 × 2\n  mean_hb sd_hb\n    <dbl> <dbl>\n1    11.0  2.89df_blood %>% \n    group_by(bldgrp) %>% \n    summarize(mean_hb = mean(hb), sd_hb = sd(hb))\n# A tibble: 5 × 3\n  bldgrp mean_hb  sd_hb\n  <chr>    <dbl>  <dbl>\n1 A         7.32  3.61 \n2 AB       13.1   1.69 \n3 B        10.2   0.283\n4 O        11.0   0.427\n5 P        16.4  NA    "},{"path":"data-wrangling.html","id":"reshaping-data","chapter":"7 Data wrangling","heading":"7.6 Reshaping data","text":"longitudinal studies, data captured individual repeatedly.\ndata recorded either long wide formats. typical example \ndata frame long form bpB .format, visit round data taking captured new row, \nappropriate study ID period record, captured variable\nmeasure . Measurement systolic blood pressure day 1 indicated \nsbp1 measure variable. Day 2 measurements indicated sbp2.wide format data can obtained ., study participant’s record whole study one row data different measurements systolic blood pressure captured different variables. Next, convert wide back long format.","code":"bp_long <- read_csv(\n    file = \"./Data/bp_long.txt\",\n    col_names = TRUE, \n    col_types = c(\"c\", \"c\", \"i\")\n    )\n\nbp_long\n# A tibble: 5 × 3\n  id    measure   sbp\n  <chr> <chr>   <dbl>\n1 B01   sbp1      141\n2 B01   sbp2      137\n3 B02   sbp1      155\n4 B02   sbp2      153\n5 B03   sbp1      153bp_wide <- \n    bp_long %>% \n    pivot_wider(\n        id_cols = id, \n        names_from = measure, \n        values_from = sbp\n    )\n\nbp_wide\n# A tibble: 3 × 3\n  id     sbp1  sbp2\n  <chr> <dbl> <dbl>\n1 B01     141   137\n2 B02     155   153\n3 B03     153    NAbp_wide %>% \n    pivot_longer(\n        cols = c(sbp1, sbp2),\n        names_to = \"time\",\n        values_to = \"syst_bp\"\n    )\n# A tibble: 6 × 3\n  id    time  syst_bp\n  <chr> <chr>   <dbl>\n1 B01   sbp1      141\n2 B01   sbp2      137\n3 B02   sbp1      155\n4 B02   sbp2      153\n5 B03   sbp1      153\n6 B03   sbp2       NA"},{"path":"data-wrangling.html","id":"combining-data","chapter":"7 Data wrangling","heading":"7.7 Combining data","text":"study determine change weight athletes running marathon,\ndata athletes obtained investigators. Since marathon\nstarts town ends town B, investigators decided weigh \nathletes just starting race. took records ID \nathlete’s sid, sex, age weight start (wgtst). records five \nathletes data marathonA. end point marathon,\nanother member investigation team recorded IDs (eid), weight upon\ncompletion (wgtend) time took athletes complete marathon\n(dura).can determine weight change matching \nweight individual. merging useful. , \nmerge two data one. done .","code":"dataA <- \n    read_delim(\n        file = \"./Data/marathonA.txt\",\n        col_names = TRUE,\n        delim = \"\\t\",\n        col_types = c(\"c\",\"c\",\"i\",\"d\")\n    )\n\ndataB <- \n    read_delim(\n        file = \"./Data/marathonB.txt\",\n        col_names = TRUE,\n        delim = \"\\t\",\n        col_types = c(\"c\",\"c\",\"i\",\"d\")\n    )\n\ndataA\n# A tibble: 5 × 4\n  sid   sex     age wgtst\n  <chr> <chr> <dbl> <dbl>\n1 C001  M        23  57.1\n2 C002  F        27  62.3\n3 C003  M        19  54.5\n4 C004  M        21  59.4\n5 C005  F        32  53.4\n\ndataB\n# A tibble: 4 × 3\n  eid   wgtend  dura\n  <chr>  <dbl> <dbl>\n1 C003    53.9   189\n2 C005    53     197\n3 C002    62.2   201\n4 C001    56.8   209dataA %>% \n    full_join(dataB, by = join_by(sid==eid))\n# A tibble: 5 × 6\n  sid   sex     age wgtst wgtend  dura\n  <chr> <chr> <dbl> <dbl>  <dbl> <dbl>\n1 C001  M        23  57.1   56.8   209\n2 C002  F        27  62.3   62.2   201\n3 C003  M        19  54.5   53.9   189\n4 C004  M        21  59.4   NA      NA\n5 C005  F        32  53.4   53     197"},{"path":"data-cleaning.html","id":"data-cleaning","chapter":"8 Data Cleaning","heading":"8 Data Cleaning","text":"Data analysed ”cleaned” first abnormal invalid values. \ndone understanding data hand, collected\nfirst place little prejudice bias. critical\nstage analysis arbitrary deletion insertion data \nsignificantly alter conclusions., therefore, goes without saying modifications done data\ncleaning stage must sound statistical, clinical well commonsensical\nreasons . Also, whole process data cleaning well\ndocumented appropriately stored future reference. regard, \ngood practice edit data software Microsoft Excel though\nmay appear easy tempting. software keep \naudit trail.","code":""},{"path":"data-cleaning.html","id":"data-dictionary-or-codebook","chapter":"8 Data Cleaning","heading":"8.1 Data dictionary or codebook","text":"well-collected managed data, always dictionary. \ndictionary outlines every variable dataset variable name, \nmeaning variable, source variable (questionnaire, data\ncollection sheet, etc.), valid ranges codes format. \ninvaluable tool determining wrong abnormal entries. also sometimes\nreferred codebook.typical example one . data dictionary \nblood_donors_3.dta file going use.","code":""},{"path":"data-cleaning.html","id":"importing-the-data-into-r","chapter":"8 Data Cleaning","heading":"8.2 Importing the data into R","text":"first step analysis read import data data analysis\nsoftware general overview can obtained. begin importing \nblood_donors_3.dta R calling blood3.","code":"\nblood3 <- readxl::read_xls(\"./Data/blood_donors_2.xls\")"},{"path":"data-cleaning.html","id":"visualising-the-data-in-r","chapter":"8 Data Cleaning","heading":"8.3 Visualising the data in R","text":"Next, visualize dataTo visualise data can use print() View() functions. Note\nmight best relatively big data. \nuse .data.frame() function display whole data.","code":"blood3\n# A tibble: 25 × 6\n      id    hb   hct   sex bldgrp pdonor\n   <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl>\n 1     1 10.5   31.8     1      3      3\n 2     2 11.9   37.2     1      4      0\n 3     3  1     26       1      1      1\n 4     4  8.90  26.8     1      1      3\n 5     5  7.80  24.2     1      1      2\n 6     6 10     30.9     1      2      1\n 7     7 10.4   33.9     1      2      0\n 8     8 11.3   35       1      3      1\n 9     9 16.4   NA       1      4      1\n10    10 14.4   43.6     1      4      1\n# ℹ 15 more rowsblood3 %>% as.data.frame()\n   id   hb  hct sex bldgrp pdonor\n1   1 10.5 31.8   1      3      3\n2   2 11.9 37.2   1      4      0\n3   3  1.0 26.0   1      1      1\n4   4  8.9 26.8   1      1      3\n5   5  7.8 24.2   1      1      2\n6   6 10.0 30.9   1      2      1\n7   7 10.4 33.9   1      2      0\n8   8 11.3 35.0   1      3      1\n9   9 16.4   NA   1      4      1\n10 10 14.4 43.6   1      4      1\n11 11 11.2 33.2   0      3     99\n12 12 11.5 35.5   0      3      1\n13 13 10.5 33.7   0      3      2\n14 14 12.2 36.8   0      4      1\n15 14 16.4 48.8   0      5      2\n16 16 12.7 99.0   0      4      0\n17 17  9.8 30.5   0      1      4\n18 18 10.9 33.8   0      3      0\n19 19 11.6 35.4   0      3      3\n20 20 10.6 34.9   0      9      2\n21 21  9.1 28.0   9      1      3\n22 22 11.9 36.1   9      4      3\n23 23 10.5 34.2   9      3      2\n24 24 12.3 38.2   9      4      2\n25 25 11.0 35.7   9      3      2"},{"path":"data-cleaning.html","id":"describing-or-summarizing-the-data","chapter":"8 Data Cleaning","heading":"8.4 Describing or summarizing the data","text":"first use glimpse() function basic view variable names variable typesWe can also use dfSummary() function summarytools package \ngive comprehensive output variable.","code":"blood3 %>% glimpse()\nRows: 25\nColumns: 6\n$ id     <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, …\n$ hb     <dbl> 10.5, 11.9, 1.0, 8.9, 7.8, 10.0, 10.4, 11.3…\n$ hct    <dbl> 31.8, 37.2, 26.0, 26.8, 24.2, 30.9, 33.9, 3…\n$ sex    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0…\n$ bldgrp <dbl> 3, 4, 1, 1, 1, 2, 2, 3, 4, 4, 3, 3, 3, 4, 5…\n$ pdonor <dbl> 3, 0, 1, 3, 2, 1, 0, 1, 1, 1, 99, 1, 2, 1, …blood3 %>% summarytools::dfSummary()\nData Frame Summary  \nblood3  \nDimensions: 25 x 6  \nDuplicates: 0  \n\n--------------------------------------------------------------------------------------------------------\nNo   Variable    Stats / Values            Freqs (% of Valid)   Graph               Valid      Missing  \n---- ----------- ------------------------- -------------------- ------------------- ---------- ---------\n1    id          Mean (sd) : 13 (7.4)      24 distinct values   : : : : :           25         0        \n     [numeric]   min < med < max:                               : : : : :           (100.0%)   (0.0%)   \n                 1 < 13 < 25                                    : : : : :                               \n                 IQR (CV) : 12 (0.6)                            : : : : :                               \n                                                                : : : : :                               \n\n2    hb          Mean (sd) : 11 (2.9)      21 distinct values             :         25         0        \n     [numeric]   min < med < max:                                         :         (100.0%)   (0.0%)   \n                 1 < 11 < 16.4                                            :                             \n                 IQR (CV) : 1.5 (0.3)                                   . :                             \n                                                                .     . : : : . :                       \n\n3    hct         Mean (sd) : 36.8 (14.3)   24 distinct values     :                 24         1        \n     [numeric]   min < med < max:                                 :                 (96.0%)    (4.0%)   \n                 24.2 < 34.6 < 99                                 :                                     \n                 IQR (CV) : 4.7 (0.4)                             :                                     \n                                                                : : .         .                         \n\n4    sex         Mean (sd) : 2.2 (3.5)     0 : 10 (40.0%)       IIIIIIII            25         0        \n     [numeric]   min < med < max:          1 : 10 (40.0%)       IIIIIIII            (100.0%)   (0.0%)   \n                 0 < 1 < 9                 9 :  5 (20.0%)       IIII                                    \n                 IQR (CV) : 1 (1.6)                                                                     \n\n5    bldgrp      Mean (sd) : 3.1 (1.7)     1 : 5 (20.0%)        IIII                25         0        \n     [numeric]   min < med < max:          2 : 2 ( 8.0%)        I                   (100.0%)   (0.0%)   \n                 1 < 3 < 9                 3 : 9 (36.0%)        IIIIIII                                 \n                 IQR (CV) : 2 (0.5)        4 : 7 (28.0%)        IIIII                                   \n                                           5 : 1 ( 4.0%)                                                \n                                           9 : 1 ( 4.0%)                                                \n\n6    pdonor      Mean (sd) : 5.6 (19.5)    0 : 4 (16.0%)        III                 25         0        \n     [numeric]   min < med < max:          1 : 7 (28.0%)        IIIII               (100.0%)   (0.0%)   \n                 0 < 2 < 99                2 : 7 (28.0%)        IIIII                                   \n                 IQR (CV) : 2 (3.5)        3 : 5 (20.0%)        IIII                                    \n                                           4 : 1 ( 4.0%)                                                \n                                           99 : 1 ( 4.0%)                                               \n--------------------------------------------------------------------------------------------------------"},{"path":"data-cleaning.html","id":"cleaning-individual-variables","chapter":"8 Data Cleaning","heading":"8.5 Cleaning individual variables","text":"note variables type “double”. sex bldgrp\nhowever, factors. done subsequently summarized .","code":"blood3 <-  \n    blood3 %>% \n    mutate(sex = factor(sex, \n                        levels = c(0,1,9),\n                        labels = c(\"Female\", \"Male\", \"Missing\")),\n           bldgrp= factor(bldgrp, \n                          levels = c(1, 2, 3, 4, 9),\n                          labels = c(\"A\", \"B\", \"O\", \"AB\", \"Missing\"))) \n\nblood3 %>% summarytools::dfSummary()\nData Frame Summary  \nblood3  \nDimensions: 25 x 6  \nDuplicates: 0  \n\n--------------------------------------------------------------------------------------------------------\nNo   Variable    Stats / Values            Freqs (% of Valid)   Graph               Valid      Missing  \n---- ----------- ------------------------- -------------------- ------------------- ---------- ---------\n1    id          Mean (sd) : 13 (7.4)      24 distinct values   : : : : :           25         0        \n     [numeric]   min < med < max:                               : : : : :           (100.0%)   (0.0%)   \n                 1 < 13 < 25                                    : : : : :                               \n                 IQR (CV) : 12 (0.6)                            : : : : :                               \n                                                                : : : : :                               \n\n2    hb          Mean (sd) : 11 (2.9)      21 distinct values             :         25         0        \n     [numeric]   min < med < max:                                         :         (100.0%)   (0.0%)   \n                 1 < 11 < 16.4                                            :                             \n                 IQR (CV) : 1.5 (0.3)                                   . :                             \n                                                                .     . : : : . :                       \n\n3    hct         Mean (sd) : 36.8 (14.3)   24 distinct values     :                 24         1        \n     [numeric]   min < med < max:                                 :                 (96.0%)    (4.0%)   \n                 24.2 < 34.6 < 99                                 :                                     \n                 IQR (CV) : 4.7 (0.4)                             :                                     \n                                                                : : .         .                         \n\n4    sex         1. Female                 10 (40.0%)           IIIIIIII            25         0        \n     [factor]    2. Male                   10 (40.0%)           IIIIIIII            (100.0%)   (0.0%)   \n                 3. Missing                 5 (20.0%)           IIII                                    \n\n5    bldgrp      1. A                      5 (20.8%)            IIII                24         1        \n     [factor]    2. B                      2 ( 8.3%)            I                   (96.0%)    (4.0%)   \n                 3. O                      9 (37.5%)            IIIIIII                                 \n                 4. AB                     7 (29.2%)            IIIII                                   \n                 5. Missing                1 ( 4.2%)                                                    \n\n6    pdonor      Mean (sd) : 5.6 (19.5)    0 : 4 (16.0%)        III                 25         0        \n     [numeric]   min < med < max:          1 : 7 (28.0%)        IIIII               (100.0%)   (0.0%)   \n                 0 < 2 < 99                2 : 7 (28.0%)        IIIII                                   \n                 IQR (CV) : 2 (3.5)        3 : 5 (20.0%)        IIII                                    \n                                           4 : 1 ( 4.0%)                                                \n                                           99 : 1 ( 4.0%)                                               \n--------------------------------------------------------------------------------------------------------"},{"path":"data-cleaning.html","id":"checking-for-duplicated-records","chapter":"8 Data Cleaning","heading":"8.6 Checking for duplicated records","text":"begin official data cleaning checking duplicate records \ndata","code":"blood3 %>% janitor::get_dupes()\nNo variable names specified - using all columns.\nNo duplicate combinations found of: id, hb, hct, sex, bldgrp, pdonor\n# A tibble: 0 × 7\n# ℹ 7 variables: id <dbl>, hb <dbl>, hct <dbl>, sex <fct>,\n#   bldgrp <fct>, pdonor <dbl>, dupe_count <int>"},{"path":"data-cleaning.html","id":"cleaning-individual-variables-1","chapter":"8 Data Cleaning","heading":"8.7 Cleaning individual variables","text":"Next, begin sort variables one one. begin study id\nvariable. begin looking duplicated study ids.Study id 14 duplicated! Next, visually inspect study idsIt looks like study ids numeric order 1 25 14 duplicated 15 \nmissing. solve writing new study id variable. Afterwards, check see \nduplicates.Next, inspect hb variable summary boxplot. observe \nsummary none haemoglobin observations missing. boxplot \nhb shown . observe 4 outliers one looks \nextreme.convert observation missing .redraw boxplot without outlier.Next, focus hct variable. note 99 represents ‘missing’. \ntherefore remove belowAnd draw boxplot belowBecause know hematocrit relationship haemoglobin, use scatter plot \nvisualise possibly pick suspicious data.Next, inspect sex variableWe convert “Missing” category NAAnd checkNext, sort bldgrp variableWe convert Missing NA visualize variableNext, sort pdonor","code":"blood3 %>% janitor::get_dupes(id)\n# A tibble: 2 × 7\n     id dupe_count    hb   hct sex    bldgrp pdonor\n  <dbl>      <int> <dbl> <dbl> <fct>  <fct>   <dbl>\n1    14          2  12.2  36.8 Female AB          1\n2    14          2  16.4  48.8 Female <NA>        2blood3$id\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 14 16 17 18\n[19] 19 20 21 22 23 24 25blood3 <- \n    blood3 %>% \n    mutate(id = 1:25) \n\nblood3 %>% janitor::get_dupes(id)\nNo duplicate combinations found of: id\n# A tibble: 0 × 7\n# ℹ 7 variables: id <int>, dupe_count <int>, hb <dbl>,\n#   hct <dbl>, sex <fct>, bldgrp <fct>, pdonor <dbl>blood3 %$% summary(hb)\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00   10.40   11.00   10.99   11.90   16.40 \nA <-\n    blood3 %>% \n    ggplot(aes(y = hb)) +\n    geom_boxplot(fill = \"grey\") +\n    labs(y = \"Hemoglobin (mg/dl)\",\n         title = \"Boxplot of hemoglobin of participants \n         with outliers\") +\n    theme_bw()\nblood3 <- \n    blood3 %>% \n    mutate(hb = ifelse(hb < 4, NA, hb))B <-\n    blood3 %>% \n    ggplot(aes(y = hb)) +\n    geom_boxplot(fill = \"grey\") +\n    labs(y = \"Hemoglobin (mg/dl)\",\n         title = \"Boxplot of hemoglobin of participants \n         after outlier removed\") +\n    theme_bw()\n\nA + B + plot_annotation(tag_levels = 'A')\nWarning: Removed 1 rows containing non-finite values\n(`stat_boxplot()`).\nblood3 %>% \n    drop_na() %>% \n    ggplot(aes(y = hb)) +\n    geom_boxplot(fill =\"grey\") +\n    labs(y = \"Hemoglobin (mg/dl)\",\n         title = \"Boxplot of hemoglobin of participants\") +\n    theme_bw()\nblood3 <- \n    blood3 %>% \n    mutate(hct = ifelse(hct >90, NA, hct))\nblood3 %>% \n    drop_na(hct) %>% \n    ggplot(aes(y = hct)) + \n    geom_boxplot(fill = \"grey\")+ \n    labs(y = \"Hematocrit (%)\",\n         title = \"Boxplot of hematocrit of participants\") +\n    theme_bw()\nblood3 %>% \n    drop_na(hb, hct) %>% \n    ggplot(aes(x = hct, y = hb)) + \n    geom_point(col = \"red\") + \n    labs(x = \"Hematocrit (%)\",\n         y = \"Hemoglobin (mg/dl)\",\n         title = \"Scatterplot showing the relationship between the hematocrit and hemoglobin\")+\n    theme_bw()blood3 %>% \n    count(sex)\n# A tibble: 3 × 2\n  sex         n\n  <fct>   <int>\n1 Female     10\n2 Male       10\n3 Missing     5\nblood3 <- \n    blood3 %>% \n    mutate(sex = fct_recode(sex, NULL = \"Missing\"))blood3 %>% \n    count(sex)\n# A tibble: 3 × 2\n  sex        n\n  <fct>  <int>\n1 Female    10\n2 Male      10\n3 <NA>       5blood3 %>% \n    count(bldgrp)\n# A tibble: 6 × 2\n  bldgrp      n\n  <fct>   <int>\n1 A           5\n2 B           2\n3 O           9\n4 AB          7\n5 Missing     1\n6 <NA>        1blood3 <-\n    blood3 %>% \n    mutate(bldgrp = fct_recode(bldgrp, NULL = \"Missing\"))\n\nblood3 %>% count(bldgrp)\n# A tibble: 5 × 2\n  bldgrp     n\n  <fct>  <int>\n1 A          5\n2 B          2\n3 O          9\n4 AB         7\n5 <NA>       2\nblood3 <- \n    blood3 %>% \n    mutate(pdonor = ifelse(pdonor == 99, NA, pdonor))"},{"path":"data-cleaning.html","id":"visualising-the-cleaned-data","chapter":"8 Data Cleaning","heading":"8.8 Visualising the cleaned data","text":"Finally, summarize data ","code":"blood3 %>% \n    summarytools::dfSummary()\nData Frame Summary  \nblood3  \nDimensions: 25 x 6  \nDuplicates: 0  \n\n--------------------------------------------------------------------------------------------------\nNo   Variable    Stats / Values           Freqs (% of Valid)   Graph          Valid      Missing  \n---- ----------- ------------------------ -------------------- -------------- ---------- ---------\n1    id          Mean (sd) : 13 (7.4)     25 distinct values   : : : : :      25         0        \n     [integer]   min < med < max:         (Integer sequence)   : : : : :      (100.0%)   (0.0%)   \n                 1 < 13 < 25                                   : : : : :                          \n                 IQR (CV) : 12 (0.6)                           : : : : :                          \n                                                               : : : : :                          \n\n2    hb          Mean (sd) : 11.4 (2)     20 distinct values       :          24         1        \n     [numeric]   min < med < max:                                  :          (96.0%)    (4.0%)   \n                 7.8 < 11.1 < 16.4                                 :                              \n                 IQR (CV) : 1.5 (0.2)                            . :                              \n                                                               . : : : . :                        \n\n3    hct         Mean (sd) : 34.1 (5.4)   23 distinct values       :          23         2        \n     [numeric]   min < med < max:                                  : .        (92.0%)    (8.0%)   \n                 24.2 < 34.2 < 48.8                                : :                            \n                 IQR (CV) : 4.6 (0.2)                            . : :                            \n                                                               . : : : . .                        \n\n4    sex         1. Female                10 (50.0%)           IIIIIIIIII     20         5        \n     [factor]    2. Male                  10 (50.0%)           IIIIIIIIII     (80.0%)    (20.0%)  \n\n5    bldgrp      1. A                     5 (21.7%)            IIII           23         2        \n     [factor]    2. B                     2 ( 8.7%)            I              (92.0%)    (8.0%)   \n                 3. O                     9 (39.1%)            IIIIIII                            \n                 4. AB                    7 (30.4%)            IIIIII                             \n\n6    pdonor      Mean (sd) : 1.7 (1.1)    0 : 4 (16.7%)        III            24         1        \n     [numeric]   min < med < max:         1 : 7 (29.2%)        IIIII          (96.0%)    (4.0%)   \n                 0 < 2 < 4                2 : 7 (29.2%)        IIIII                              \n                 IQR (CV) : 1.2 (0.7)     3 : 5 (20.8%)        IIII                               \n                                          4 : 1 ( 4.2%)                                           \n--------------------------------------------------------------------------------------------------"},{"path":"data-cleaning.html","id":"generating-new-variables-1","chapter":"8 Data Cleaning","heading":"8.9 Generating new variables","text":"Often cleaning individual variables data analyst required \ngenerate new variables old ones. put practice \ngenerating presence Anemia hb less 11g/dl.","code":"blood3 <-\n    blood3 %>% \n    mutate(anemia = case_when(hb < 11 ~ \"Yes\", hb >= 11 ~ \"No\") %>% factor())\n\nsummarytools::dfSummary(blood3)\nData Frame Summary  \nblood3  \nDimensions: 25 x 7  \nDuplicates: 0  \n\n--------------------------------------------------------------------------------------------------\nNo   Variable    Stats / Values           Freqs (% of Valid)   Graph          Valid      Missing  \n---- ----------- ------------------------ -------------------- -------------- ---------- ---------\n1    id          Mean (sd) : 13 (7.4)     25 distinct values   : : : : :      25         0        \n     [integer]   min < med < max:         (Integer sequence)   : : : : :      (100.0%)   (0.0%)   \n                 1 < 13 < 25                                   : : : : :                          \n                 IQR (CV) : 12 (0.6)                           : : : : :                          \n                                                               : : : : :                          \n\n2    hb          Mean (sd) : 11.4 (2)     20 distinct values       :          24         1        \n     [numeric]   min < med < max:                                  :          (96.0%)    (4.0%)   \n                 7.8 < 11.1 < 16.4                                 :                              \n                 IQR (CV) : 1.5 (0.2)                            . :                              \n                                                               . : : : . :                        \n\n3    hct         Mean (sd) : 34.1 (5.4)   23 distinct values       :          23         2        \n     [numeric]   min < med < max:                                  : .        (92.0%)    (8.0%)   \n                 24.2 < 34.2 < 48.8                                : :                            \n                 IQR (CV) : 4.6 (0.2)                            . : :                            \n                                                               . : : : . .                        \n\n4    sex         1. Female                10 (50.0%)           IIIIIIIIII     20         5        \n     [factor]    2. Male                  10 (50.0%)           IIIIIIIIII     (80.0%)    (20.0%)  \n\n5    bldgrp      1. A                     5 (21.7%)            IIII           23         2        \n     [factor]    2. B                     2 ( 8.7%)            I              (92.0%)    (8.0%)   \n                 3. O                     9 (39.1%)            IIIIIII                            \n                 4. AB                    7 (30.4%)            IIIIII                             \n\n6    pdonor      Mean (sd) : 1.7 (1.1)    0 : 4 (16.7%)        III            24         1        \n     [numeric]   min < med < max:         1 : 7 (29.2%)        IIIII          (96.0%)    (4.0%)   \n                 0 < 2 < 4                2 : 7 (29.2%)        IIIII                              \n                 IQR (CV) : 1.2 (0.7)     3 : 5 (20.8%)        IIII                               \n                                          4 : 1 ( 4.2%)                                           \n\n7    anemia      1. No                    13 (54.2%)           IIIIIIIIII     24         1        \n     [factor]    2. Yes                   11 (45.8%)           IIIIIIIII      (96.0%)    (4.0%)   \n--------------------------------------------------------------------------------------------------"},{"path":"descriptive-statistics-of-categorical-data.html","id":"descriptive-statistics-of-categorical-data","chapter":"9 Descriptive Statistics of Categorical Data","heading":"9 Descriptive Statistics of Categorical Data","text":"section use Titanic data setWe visualize first 6 rows dataTable 9.1:  summarize entire ","code":"── Attaching core tidyverse packages ──── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nAttaching package: 'magrittr'\n\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\nWarning: package 'huxtable' was built under R version 4.3.1\n\nAttaching package: 'huxtable'\n\nThe following object is masked from 'package:dplyr':\n\n    add_rownames\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_grey\n\n#BlackLivesMatter\n\nAttaching package: 'gtsummary'\n\nThe following object is masked from 'package:huxtable':\n\n    as_flextable\ntitanic2 <-  \n    haven::read_dta(\"./Data/titanic2.dta\") %>% \n    mutate(sex  = haven::as_factor(sex),\n           died = haven::as_factor(died),\n           age  = haven::as_factor(age),\n           class = haven::as_factor(class)) %>% \n    haven::zap_labels()\ntitanic2 %>% head()titanic2 %>% summary()\n    class        age           sex        died     \n first :325   child: 109   female: 470   No : 711  \n second:285   adult:2092   male  :1731   Yes:1490  \n third :706                                        \n crew  :885                                        "},{"path":"descriptive-statistics-of-categorical-data.html","id":"single-categorical-variable","chapter":"9 Descriptive Statistics of Categorical Data","heading":"9.0.1 Single Categorical Variable","text":"","code":""},{"path":"descriptive-statistics-of-categorical-data.html","id":"frequencies-proportions","chapter":"9 Descriptive Statistics of Categorical Data","heading":"9.0.1.1 Frequencies & Proportions","text":"","code":"\ntitanic2 %>% \n    gtsummary::tbl_summary(\n        include = class,\n        digits = class ~ c(0,1)\n    ) %>% \n    gtsummary::bold_labels()"},{"path":"descriptive-statistics-of-categorical-data.html","id":"graph---barchart","chapter":"9 Descriptive Statistics of Categorical Data","heading":"9.0.1.2 Graph - Barchart","text":"first summarize dataTable 6.2:  plot barplot","code":"\nbar_data <-\n    titanic2 %>% \n    drop_na(class) %>% \n    count(class) %>% \n    mutate(perc = `n` / sum(`n`)) %>% \n    arrange(perc) %>%\n    mutate(labels = paste(n, \" (\", scales::percent(perc), \")\", sep=\"\"))\n\nbar_data\nbar_data %>% \n    ggplot() +\n    geom_bar(stat = \"identity\", \n             aes(y = n, x = class, fill = class), \n             col = \"black\", \n             show.legend = F) +\n    geom_label(aes(y = n, label = labels, x = class), \n               vjust = 1.2,\n               show.legend = FALSE, size=3.5) +\n    labs(x = NULL, \n         y = \"Count\", \n         title = \"Distribution of Class of passenger\") +\n    theme_bw()"},{"path":"descriptive-statistics-of-categorical-data.html","id":"pie-chart","chapter":"9 Descriptive Statistics of Categorical Data","heading":"9.0.1.3 Pie Chart","text":"use previously summarized data. draw customised Pie Chart","code":"\nbar_data %>% \n    ggplot(aes(x = \"\", y = perc, fill = class)) +\n    geom_col() +\n    geom_label(aes(label = labels),\n               position = position_stack(vjust = 0.5),\n               show.legend = FALSE, size =3) +\n    coord_polar(theta = \"y\", start=0) +\n    labs(title = \"Distribution of Blood Groups of study participants\",\n         fill = \"Blood Group\") +\n    theme_void()"},{"path":"descriptive-statistics-of-categorical-data.html","id":"two-categorical-variables","chapter":"9 Descriptive Statistics of Categorical Data","heading":"9.0.2 Two categorical Variables","text":"","code":""},{"path":"descriptive-statistics-of-categorical-data.html","id":"frequencies-proportions-1","chapter":"9 Descriptive Statistics of Categorical Data","heading":"9.0.2.1 Frequencies & Proportions","text":"","code":"\ntitanic2 %>% \n    tbl_cross(row = sex, col = died) %>% \n    bold_labels()"},{"path":"descriptive-statistics-of-categorical-data.html","id":"row-percentages","chapter":"9 Descriptive Statistics of Categorical Data","heading":"9.0.2.2 Row percentages","text":"","code":"\ntitanic2 %>% \n    tbl_cross(row = sex, col = died, percent = \"row\", digits = c(0,1)) %>% \n    bold_labels()"},{"path":"descriptive-statistics-of-categorical-data.html","id":"column-percentages","chapter":"9 Descriptive Statistics of Categorical Data","heading":"9.0.2.3 Column percentages","text":"","code":"\ntitanic2 %>% \n    tbl_cross(row = sex, col = died, percent = \"col\", digits = c(0,1)) %>% \n    bold_labels()"},{"path":"descriptive-statistics-of-categorical-data.html","id":"table-total-percentages","chapter":"9 Descriptive Statistics of Categorical Data","heading":"9.0.2.4 Table Total Percentages","text":"","code":"\ntitanic2 %>% \n    tbl_cross(\n        row = sex, \n        col = died, \n        percent = c(\"cell\"), \n        digits = c(0,1)) %>% \n    bold_labels()"},{"path":"descriptive-statistics-of-categorical-data.html","id":"bar-chart","chapter":"9 Descriptive Statistics of Categorical Data","heading":"9.0.2.5 Bar Chart","text":"","code":"\ntitanic2 %>% \n    ggplot(aes(x = class, fill = died)) +\n    geom_bar(position = position_dodge(), col = \"black\") +\n    labs(y = \"Count\", x = \"Class\", fill = \"Died\",\n          title = \"Bar plot of outcome of passengers for each class\") +\n    theme_bw()Warning: package 'huxtable' was built under R version 4.3.1"},{"path":"descriptive-statistics-of-continuous-data.html","id":"descriptive-statistics-of-continuous-data","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10 Descriptive Statistics of Continuous Data","text":"section, use NewDrug_clean.dta dataset","code":"newdrug <-  \n    haven::read_dta(\"./Data/NewDrug_clean.dta\") %>% \n    mutate(sex  = haven::as_factor(sex), treat = haven::as_factor(treat)) %>% \n    haven::zap_labels() \n\nnewdrug %>% summary()\n      id                treat         age        sex   \n Length:50          Control:22   Min.   :45.00   F:26  \n Class :character   Newdrug:28   1st Qu.:57.25   M:24  \n Mode  :character                Median :63.00         \n                                 Mean   :61.48         \n                                 3rd Qu.:65.00         \n                                 Max.   :75.00         \n      bp1              bp2            bpdiff      \n Min.   : 87.50   Min.   :78.00   Min.   : 0.500  \n 1st Qu.: 95.62   1st Qu.:85.22   1st Qu.: 4.800  \n Median : 97.70   Median :88.15   Median : 8.250  \n Mean   : 98.30   Mean   :88.60   Mean   : 9.704  \n 3rd Qu.: 99.40   3rd Qu.:92.10   3rd Qu.:13.700  \n Max.   :111.70   Max.   :99.70   Max.   :26.300  "},{"path":"descriptive-statistics-of-continuous-data.html","id":"single-continuous-variable","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10.0.1 Single continuous variable","text":"","code":""},{"path":"descriptive-statistics-of-continuous-data.html","id":"measures-of-central-tendency-dispersion","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10.0.1.1 Measures of Central Tendency & Dispersion","text":"include mean median displayed belowTable 9.1:  AlternativelyTable 6.1:  show interquartile range following.Table 10.1:  ","code":"\nnewdrug %>% \n    summarise(\n        mean.bp1 = mean(bp1), \n        median.bp1 = median(bp1), \n        sd.bp1 = sd(bp1), \n        min.bp1 = min(bp1), \n        max.bp1 = max(bp1),\n        iqr = IQR(bp1)\n    ) \nnewdrug %$% \n    psych::describe(bp1)\nnewdrug %$% \n    psych::describe(bp1, IQR = TRUE,quant = c(.25, .75))"},{"path":"descriptive-statistics-of-continuous-data.html","id":"graphs---histogram","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10.0.1.2 Graphs - Histogram","text":"","code":"\nnewdrug %>% \n    ggplot(aes(x = bp1)) + \n    geom_histogram(bins = 7, col=\"black\", alpha = .5, fill = \"red\") +\n    labs(title = \"Histogram of Blood Pressure before  intervention\",\n         x= \"BP1\")+\n    theme_light()"},{"path":"descriptive-statistics-of-continuous-data.html","id":"graphs---boxplot-and-violin-plot","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10.0.1.3 Graphs - Boxplot and violin plot","text":"","code":"\nnewdrug %>% \n    ggplot(aes(y = bp1)) + \n    geom_boxplot(col=\"black\",  \n                 alpha = .2, \n                 fill = \"blue\", \n                 outlier.fill = \"black\",\n                 outlier.shape = 22) +\n    labs(title = \"Boxplot of Blood Pressure before  intervention\",\n         y = \"BP1\")+\n    theme_light()"},{"path":"descriptive-statistics-of-continuous-data.html","id":"graphs---density-plot","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10.0.1.4 Graphs - Density plot","text":"","code":"\nnewdrug %>% \n    ggplot(aes(y = bp1)) + \n    geom_density(col=\"black\", fill = \"yellow\", alpha=.6) +\n    labs(title = \"Density Plot of Blood Pressure before  intervention\",\n         y = \"Blood Pressure before  intervention\")+\n    coord_flip() +\n    theme_light()"},{"path":"descriptive-statistics-of-continuous-data.html","id":"graphs---cumulative-frequency-plot","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10.0.1.5 Graphs - Cumulative Frequency plot","text":"","code":"\nnewdrug %>% \n    group_by(bp1) %>% \n    summarize(n = n()) %>% \n    ungroup() %>% \n    mutate(cum = cumsum(n)/sum(n)*100) %>% \n    ggplot(aes(y = cum, x = bp1)) +\n    geom_line(col=3, linewidth=1.2)+\n    labs(\n        title = \"Cumulative Frequency Plot of Blood Pressure before  intervention\",\n        x = \"BP1\",\n        y = \"Cumulative Frequency\")+\n    theme_light() "},{"path":"descriptive-statistics-of-continuous-data.html","id":"multiple-continuous-variables","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10.0.2 Multiple Continuous variables","text":"","code":""},{"path":"descriptive-statistics-of-continuous-data.html","id":"measures-of-central-tendency-dispersion-1","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10.0.2.1 Measures of Central tendency & Dispersion","text":"Table 6.5:  illustrate graphing multiple continuous variables use 2 bp variablesNext, create multiple density plots","code":"\nnewdrug %>% \n    select(where(is.numeric)) %>% \n    psych::describe()\nbps <- \n    newdrug %>%\n    select(bp1, bp2) %>% \n    pivot_longer(\n        cols = c(bp1, bp2),\n        names_to = \"measure\", \n        values_to = \"bp\") %>% \n    mutate(\n        measure = fct_recode(\n            measure, \"Pre-Treatment\" = \"bp1\", \"Post-Treatment\" = \"bp2\"\n            )\n        )bps %>% \n    ggplot(aes(y = measure, x = bp, fill = measure)) +\n    ggridges::geom_density_ridges2( col=\"black\", alpha = .5, scale=1, \n                                    show.legend = F) +\n    labs(x = \"Blood pressure (mmHg)\", \n         y = \"Density\", \n         fill = \"Blood Pressure\") +\n    theme_bw()\nPicking joint bandwidth of 1.52\nbps %>% \n    ggplot(aes(y = measure, x = bp, fill = measure))+\n    geom_boxplot(show.legend = FALSE) +\n    labs(y = NULL, \n         x = \"Blood Pressure\", \n         fill = \"Blood Pressure\") +\n    coord_flip()+\n    theme_light() \nbps %>% \n    ggplot(aes(y = measure, x = bp, fill = measure))+\n    geom_violin(show.legend = FALSE) +\n    coord_flip()+\n    theme_light() "},{"path":"descriptive-statistics-of-continuous-data.html","id":"continuous-by-a-single-categorical-variable","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10.1 Continuous by a single categorical variable","text":"","code":""},{"path":"descriptive-statistics-of-continuous-data.html","id":"summary","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10.1.1 Summary","text":"one variable.Table 6.10:  ","code":"\nnewdrug %>% \n    group_by(treat) %>% \n    summarize(mean.bp1 = mean(bp1),\n              sd.bp1 = sd(bp1),\n              var.bp1 = var(bp1),\n              se.mean.bp1 = sd(bp1)/sqrt(n()),\n              median.bp1 = median(bp1),\n              min.bp1 = min(bp1),\n              max.bp1 = max(bp1)) %>% \n    ungroup()"},{"path":"descriptive-statistics-of-continuous-data.html","id":"graph---histogram-boxplot-density-plot-and-cumulative-frequency","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10.1.2 Graph - Histogram, Boxplot, Density plot and cumulative frequency","text":"graphs similar skip .","code":""},{"path":"descriptive-statistics-of-continuous-data.html","id":"continuous-by-multiple-categorical-variables","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10.2 Continuous by multiple categorical variables","text":"","code":""},{"path":"descriptive-statistics-of-continuous-data.html","id":"summary-1","chapter":"10 Descriptive Statistics of Continuous Data","heading":"10.2.1 Summary","text":"can done .Table 6.11:  can presented boxplot ","code":"\nnewdrug %>% \n    group_by(treat, sex) %>% \n    summarize(mean.bp1 = mean(bp1),\n              sd.bp1 = sd(bp1),\n              var.bp1 = var(bp1),\n              se.mean.bp1 = sd(bp1)/sqrt(n()),\n              median.bp1 = median(bp1),\n              min.bp1 = min(bp1),\n              max.bp1 = max(bp1),\n              .groups = \"drop\") \nnewdrug %>% \n    ggplot(aes(y = bp1, x = sex, fill = treat)) +\n    geom_boxplot()+\n    labs(\n        y = \"Blood Pressure (mmHg)\",\n        x =  \"Sex\",\n        fill = 'Treatment') +\n    theme_bw()"},{"path":"hypothesis-testing.html","id":"hypothesis-testing","chapter":"11 Hypothesis-Testing","heading":"11 Hypothesis-Testing","text":"","code":""},{"path":"hypothesis-testing.html","id":"population-and-sample","chapter":"11 Hypothesis-Testing","heading":"11.1 Population and sample","text":"","code":""},{"path":"hypothesis-testing.html","id":"population","chapter":"11 Hypothesis-Testing","heading":"11.1.1 Population","text":"population statistical sense different general sense. \npopulation collection items, people, places etc. investigator\ngenerally interested wants study. population tends \nlarge necessitating investigator pick just representative sample \nstudy particular property. example:determine proportion Ghanaians males may pick representative sample study population “Ghanaians”.determine proportion defective items produced factory sample items actual population involves items produced possibly yet produced.Therefore, statistical definition population include items,\nplaces persons even born non-existent.","code":""},{"path":"hypothesis-testing.html","id":"sample","chapter":"11 Hypothesis-Testing","heading":"11.1.2 Sample","text":"part population selected whatever method, usually \nwhole population large unavailable studied. many ways\nselect sample population. sample thus usually smaller\npopulation.","code":""},{"path":"hypothesis-testing.html","id":"descriptive-versus-inferential-statistics","chapter":"11 Hypothesis-Testing","heading":"11.2 Descriptive versus Inferential Statistics","text":"almost every research idea determine specific parameter \npopulation. instance, determine proportion children age\n18 years specific flight (e.g. British Airways (BA) London \nJohannesburg) start randomly selecting sample BA flights \ntwo destinations. Next, determine ages selected\nflights finally come proportion ages less 18\nyears. Bear mind population includes future flights population\nparameter can rarely obtained. However, sample proportion\n(statistic) determined good estimate population parameter.Descriptive statistics involve statistical manipulations done specific\nsample whereas inferential statistics manipulation used estimate \npopulation parameter sample statistic. Using example ,\ndetermining proportion -18-year-old persons chosen flights\nfalls descriptive statistics whereas estimating population proportion\n-18-year-old persons fly BA along route sample\nstatistic use inferential statistics.","code":""},{"path":"hypothesis-testing.html","id":"sample-variation","chapter":"11 Hypothesis-Testing","heading":"11.3 Sample variation","text":"Mid-upper arm circumference children five measure thin\nchild quick way determining /nutritional status. \npopulation 2000 children, mean median mid-upper arm circumferences\ndetermined independently group 10 students. decided \ntake random sample 10 children estimate parameters. \ncolumn students shows measurements made student /sample\nchosen. first read data.visualise itTable 9.1:  Next, determine mean median values obtained studentTable 6.1:  obvious despite data coming population\nmeans obtained different time. effect despite using \npopulation, since choosing sample random process descriptive\nstatistic(s) obtained time sample chosen population vary.\ndifferences (variation) statistics obtained (mean median MUAC)\ninstance, every sample described sample variation. \nstatistics vary can determine population parameter? \ninferential statistics , estimating population parameter \nsample statistic.","code":"\ndf_students <- read.delim(\"./Data/students.txt\", sep = \" \")\ndf_students\ndf_students %>% \n    summarize(across(X1:X10, ~mean(.)))"},{"path":"hypothesis-testing.html","id":"hypothesis-testing-1","chapter":"11 Hypothesis-Testing","heading":"11.4 Hypothesis testing","text":"collection scientific data usually preceded idea one wants \nprove disprove. humans, often preconceived ideas opinions \nexpected results study. subconscious thinking brought light\nformally setting hypothesis testing . section deals \nformalising steps involved process affects study\ndesign, data collection, analysis, presentation results.","code":""},{"path":"hypothesis-testing.html","id":"stating-the-hypothesis.","chapter":"11 Hypothesis-Testing","heading":"11.4.1 Stating the hypothesis.","text":"Standing window one morning Mr Osei wondered () number \nwomen using services bank next door men.\nvibrant market nearby mainly women trading wares.\nproximity market bank may given impression. Now\ndecided investigate . Subconsciously wondering :proportion men using services bank women.Conversely, also wondering :proportion men using banking services different women.Bear mind second line thinking includes men using services \ncompared women vice versa. competing ideas give rise \nfollowing hypothesis:Null hypothesis (H0): proportion men using services bank next door different women.alternativelyAlternate Hypothesis (Ha): difference proportion men women using banking services.two hypotheses describing Mr Osei’s idea opposing manner.\nnull alternate hypotheses can tested well-designed\nstudy. statistical technical reasons, null hypothesis often\npreferred regard.","code":""},{"path":"hypothesis-testing.html","id":"testing-the-hypothesis","chapter":"11 Hypothesis-Testing","heading":"11.4.2 Testing the Hypothesis","text":"hypothesis stated next objective collect evidence\n(data) either prove disprove . obvious customers (study\npopulation) include future ones assertion can never completely\ndetermined customers enumerated. Hence Mr Osei decides pick\nsample customers. sample, needs determine \nenough evidence disprove null hypothesis. thinks can\nconclude “enough evidence say proportion men women using bank’s services ”.words, different proportions. hand, \ncome significant evidence null hypothesis can\nconclude “insufficient evidence conclude proportion men using bank’s services women”.","code":""},{"path":"hypothesis-testing.html","id":"type-i-error","chapter":"11 Hypothesis-Testing","heading":"11.4.3 Type I error","text":"recollect earlier chapter since many ways \nchoosing sample population results tend differ sample \nsample. called sample variability. Due sample variability, sample\nstatistics usually differ population parameter.example involving Mr Osei bank customers, proceeded collect\nsexes 250 systematically selected samples customers came \nfollowing results. 112(44.8%) males 138(55.2%) females \nsample. note sample inference, another sample\ngive entirely different result (sample variability)., question think enough evidence reject H0? think\ndifference proportion significant evidence notion \nproportions ? can never entirely sure \nrejection H0 right wrong. However, can conclude smaller \nproportion males obtained sample higher chance null\nhypothesis (proportions ) false. hypothesis testing \ntype error said made null hypothesis rejected \nfact true. can therefore say type error made H0 wrongly\nrejected.example Mr Osei making type error concludes\nbased data obtained proportions men women \nfact population.","code":""},{"path":"hypothesis-testing.html","id":"the-significance-level","chapter":"11 Hypothesis-Testing","heading":"11.4.4 The Significance Level","text":"significance level, usually denoted alpha (\\(\\alpha\\)) probability\nmaking type error. usually set investigator direct\nbearing sample size study.","code":""},{"path":"hypothesis-testing.html","id":"type-ii-error","chapter":"11 Hypothesis-Testing","heading":"11.4.5 Type II error","text":"Conversely, type II error said made researcher fails \nreject null hypothesis fact false. Applied situation \ntype II error committed Mr Osei based stated result \ndecides insufficient evidence conclude proportion two\nsexes differ fact differ population bank users.two types errors mentioned always increase expense \n. type error rises type II error falls vice versa.","code":""},{"path":"hypothesis-testing.html","id":"power","chapter":"11 Hypothesis-Testing","heading":"11.4.6 Power","text":"probability committing type II error called beta (\\(\\beta\\)). \nprobability committing type II error called Power test.\nisp(Type II error) = \\(\\beta\\) \\(Power = 1 - \\beta\\)power statistical test, therefore, measures ability reject null\nhypothesis false hence make right decision.","code":"── Attaching core tidyverse packages ──── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nAttaching package: 'magrittr'\n\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\nWarning: package 'huxtable' was built under R version 4.3.1\n\nAttaching package: 'huxtable'\n\nThe following object is masked from 'package:dplyr':\n\n    add_rownames\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_grey\n\n\nAttaching package: 'gtsummary'\n\nThe following object is masked from 'package:huxtable':\n\n    as_flextable"},{"path":"normality-of-data.html","id":"normality-of-data","chapter":"12 Normality of data","heading":"12 Normality of data","text":"Many test statistical tests, specifically parametric tests done\npremise numeric data normally distributed. Unfortunately, \nalways . chapter, look normally distributed data\ncan tell data normally distributed. section, \nuse hb variable mps.dta data.","code":""},{"path":"normality-of-data.html","id":"the-normal-distribution","chapter":"12 Normality of data","heading":"12.1 The normal distribution","text":"normal distribution, also called Gaussian Distribution bell curve,\ndefined two main statistics. mean standard deviation.\nwider standard deviation, broader curve. example \nnormal distribution shown :features normal distribution:symmetrical.mean, median mode .Approximately 68% data falls within one standard deviation mean.Approximately 95% data falls within two standard deviations meanApproximately 99.7% data fall within three standard deviations mean.normal distribution mean 1 standard deviation 1 called\nstandard normal distribution.","code":"\ndf_temp <- data.frame(x = rnorm(2000)) \n\ndf_temp %>% \n    ggplot(aes(x = x))+\n    geom_histogram(\n        aes(y=after_stat(density)), \n        bins=10, fill = \"snow\", col = \"red\") +\n    stat_function(\n        fun = dnorm, \n        args = list(\n            mean = mean(df_temp$x, na.rm=T), \n            sd = sd(df_temp$x)), col = \"blue\",\n            linewidth = 1.5) +\n    labs(x = NULL, y = NULL) +\n    scale_x_continuous(labels = NULL)+\n    scale_y_continuous(labels = NULL)+\n    theme_minimal()"},{"path":"normality-of-data.html","id":"evaluating-normality","chapter":"12 Normality of data","heading":"12.2 Evaluating normality","text":"two main modalities evaluating normality. graphical \nformal hypothesis testing.","code":""},{"path":"normality-of-data.html","id":"graphical-evaluation","chapter":"12 Normality of data","heading":"12.2.1 Graphical evaluation","text":"Histogram: Probably well know modality histogram.\nfirst read data keep hb variable:draw histogram hb.near symmetry slightly heavier left tail.Boxplot: next graphical modality boxplot drawn .conclusion good symmetry slightly heavier lower tail seen\n.Q-Q plot: Finally, Q-Q plot line. graphical modality plots\nactual values data theoretical normal distribution. Thus,\ndots straight line along line drawn \nideal normal distribution. therefore use principle determine \ndata instance heave tails, indicating skewness. Q-Q plot\ndata done :seen apart points mainly right tail rest\npretty much follow line.","code":"\ndf_mps <- haven::read_dta(\"./Data/mps.dta\")\ndf_mps %>% \n    drop_na(hb) %>% \n    ggplot(aes(x = hb)) +\n    geom_histogram(bins = 10, fill = 'white', col = \"black\") +\n    labs(title = \"Histogram of HB\", y = \"Frequency\", x = 'Hb (g/dL') +\n    theme_bw()\ndf_mps %>% \n    drop_na(hb) %>% \n    ggplot(aes(x = hb)) +\n    geom_boxplot(fill = 'white', col = \"black\") +\n    labs(title = \"Boxplot of HB\", y = \"Frequency\", x = 'Hb (g/dL') +\n    theme_bw()\ndf_mps %>%\n    drop_na(hb) %>% \n    ggpubr::ggqqplot(x = \"hb\",title = \"Q-Q plot of the HB\", conf.int = FALSE)"},{"path":"normality-of-data.html","id":"statistical-tests-for-normality","chapter":"12 Normality of data","heading":"12.2.2 Statistical tests for normality","text":"Formal statistical tests available testing.\nH0: data sampled normally distributed population.\nHa: data sampled normally distributed population\ntests concentrating Shapiro-Wilk\ntests. never advisable different tests together\nuse different algorithms may produce different results \nconclusions.Shapiro-Wilk test: perform Shapiro-wilk test normality.Table 6.3:  p-value greater 0.05 indicates reject Null hypothesis thus\nconclude data comes normally distributed population.","code":"\ndf_mps %$% \n    shapiro.test(hb) %>% \n    broom::tidy()"},{"path":"normality-of-data.html","id":"conclusion-1","chapter":"12 Normality of data","heading":"12.3 Conclusion","text":"conclusion, can seen graphical presentations well \nformal test data coming normally distributed\npopulation.various test can give contradictory results recommend evaluating\nnormality population, one first plot histogram, Q-Q plot,\nperform one formal test, combine results making \njudgement numeric data normally distributed.","code":""},{"path":"analysis-of-numeric-data.html","id":"analysis-of-numeric-data","chapter":"13 Analysis of numeric data","heading":"13 Analysis of numeric data","text":"far, dealt descriptive statistics analysis sample\ndata collected. However, bane statistical analysis make\ninferences population whole. section, mainly \ninferential analysis continuous variables.","code":""},{"path":"analysis-of-numeric-data.html","id":"confidence-interval-of-a-mean","chapter":"13 Analysis of numeric data","heading":"13.1 Confidence interval of a mean","text":"determine confidence interval mean numeric variable R, \nuse One Sample Student’s T-test. assumptions validity \ntest :sample randomly chosenThe population distribution variable normal. can \nassumed present \ndistribution population known normally distributed\npopulation distribution one mode, symmetric, without\noutliers sample size 15 less\npopulation distribution moderately skewed, without outliers,\none mode sample size 16 40\nsample size 40 data outliers.\ndistribution population known normally distributedThe population distribution one mode, symmetric, without\noutliers sample size 15 lessThe population distribution moderately skewed, without outliers,\none mode sample size 16 40The sample size 40 data outliers.sample considered randomly selected sample size 140, \napply One-sample T-test .first import dataAnd summarize belowTable 6.2:  Table 6.3:  sex stratified confidence intervals haveTable 13.1:  ","code":"\ndf_data1 <- \n    read_delim(\n        file = \"./Data/data1.txt\", \n        delim = \"\\t\",\n        col_types = c(\"c\", \"f\", \"i\",\"i\")\n    ) %>% \n    mutate(sex = factor(sex))df_data1 %>% \n    summarytools::dfSummary(graph.col = F)\nData Frame Summary  \ndf_data1  \nDimensions: 140 x 4  \nDuplicates: 0  \n\n--------------------------------------------------------------------------------------\nNo   Variable      Stats / Values            Freqs (% of Valid)   Valid      Missing  \n---- ------------- ------------------------- -------------------- ---------- ---------\n1    id            1. 1                        1 ( 0.7%)          140        0        \n     [character]   2. 10                       1 ( 0.7%)          (100.0%)   (0.0%)   \n                   3. 100                      1 ( 0.7%)                              \n                   4. 101                      1 ( 0.7%)                              \n                   5. 102                      1 ( 0.7%)                              \n                   6. 103                      1 ( 0.7%)                              \n                   7. 104                      1 ( 0.7%)                              \n                   8. 105                      1 ( 0.7%)                              \n                   9. 106                      1 ( 0.7%)                              \n                   10. 107                     1 ( 0.7%)                              \n                   [ 130 others ]            130 (92.9%)                              \n\n2    sex           1. Female                 64 (45.7%)           140        0        \n     [factor]      2. Male                   76 (54.3%)           (100.0%)   (0.0%)   \n\n3    weight        Mean (sd) : 12.2 (6.3)    28 distinct values   140        0        \n     [numeric]     min < med < max:                               (100.0%)   (0.0%)   \n                   2 < 11 < 33                                                        \n                   IQR (CV) : 7 (0.5)                                                 \n\n4    height        Mean (sd) : 90.9 (21.3)   70 distinct values   139        1        \n     [numeric]     min < med < max:                               (99.3%)    (0.7%)   \n                   49 < 88 < 137                                                      \n                   IQR (CV) : 33 (0.2)                                                \n--------------------------------------------------------------------------------------\ndf_data1 %>% \n    meantables::mean_table(height) \ndf_data1 %>% \n    group_by(sex) %>% \n    meantables::mean_table(height)"},{"path":"analysis-of-numeric-data.html","id":"comparing-the-mean-to-a-hypothesised-value","chapter":"13 Analysis of numeric data","heading":"13.2 Comparing the mean to a hypothesised value","text":"Assuming objective data collected determine average\nweight population similar population known mean weight \n14kgs.null hypothesis :H0: difference mean weight population \npopulation mean weight 14kgs.test hypothesis use One sample t-test satisfied\nassumptions use met.Table 6.4:  p-value 0.001 probability sample come \npopulation mean weight 14kgs. Since small reject \nnull H0 5% significance level conclude population mean weight\nsignificantly different 14kgs.\nconfidence interval generated sample mean. \nhypothesized value \n14kgs outside confidence interval mean conclude \ninsuficient evidence suggest mean weight population 14kgs.","code":"\ndf_data1 %$% \n    t.test(weight, mu=14) %>% \n    broom::tidy()"},{"path":"analysis-of-numeric-data.html","id":"comparing-mean-of-two-independent-groups","chapter":"13 Analysis of numeric data","heading":"13.3 Comparing mean of two independent groups","text":"possibly common use t-test. compare mean weights\nmales female study come withH0: difference weight males females \npopulation.test assertion first determine sample fits assumption \nuse Two sample t-test. :sample randomly chosenThe two samples completely independentEach population least 20 times larger respective sample.population distribution variable normal. can assumed \npresent \ndistribution population known normal\npopulation distribution one mode, symmetric, without outliers \nsample size 15 less\npopulation distribution moderately skewed, without outliers, \none mode sample size 16 40\nsample size 40 data outliers.\ndistribution population known normalThe population distribution one mode, symmetric, without outliers \nsample size 15 lessThe population distribution moderately skewed, without outliers, \none mode sample size 16 40The sample size 40 data outliers.data fulfils criteria hence apply testTable 6.5:  relatively high p-value conclude insufficient evidence\nrefute null hypothesis. words insufficient evidence \nconclude mean weights males females differ study population.\nNote sample however females appear heavier males shown \nlast two lines output .confidence interval determined (-0.86 3.47) actually \nmean sample difference females males. Since confidence\ninterval contains null value H0 .e. 0, conclude \nisn’t enough evidence difference mean weight two sexes.\nHence confidence interval p-value come similar conclusions.","code":"\ndf_data1 %$% \n    t.test(formula = weight ~ sex) %>% \n    broom::tidy()"},{"path":"analysis-of-numeric-data.html","id":"comparing-means-of-paired-observations","chapter":"13 Analysis of numeric data","heading":"13.4 Comparing means of paired observations","text":"section use bread.txt data weight grams \nbaking loaves bread. description variables \ncontained data file. Paired observations occur circumstances \nrepeated measurement done object data collected \ncharacteristics common. bread data bread weighed \nbaking. Determining significant difference \ntwo measurements requires use Paired t-test. always begin \nimporting dataNext determine structure data frame df2And summarize itOur next task compare weight loaves bread \nbaking. begin looking mean standard deviations two\nweights.Table 6.10:  obvious mean weight bread baking much higher\nhowever standard deviations appear similar. formal test \ndetermine difference means use paired t-test. \nstate assumptions paired t-testThe sample randomly chosenThe two samples independent (related)population least 20 times larger respective sample.population distribution difference two variables\nnormal.\ncan assumed present \ndistribution population known normal\npopulation distribution one mode, symmetric, without\noutliers sample size 15 less\npopulation distribution moderately skewed, without outliers,\none mode sample size 16 40\nsample size 40 data outliers.\ndistribution population known normalThe population distribution one mode, symmetric, without\noutliers sample size 15 lessThe population distribution moderately skewed, without outliers,\none mode sample size 16 40The sample size 40 data outliers.new assumption need evaluate distribution \ndifference weights . belowAlternatively, can perform Shapiro-Wilk’s test normality. H0\ndeviating normal distribution. done belowTable 13.2:  output graphical representation shows difference weight \nliterally normally distributed. therefore go ahead determine \ndifference mean weights. First state hypothesisH0: change weight loaves bread bakingAnd perform test converting data long formatTable 13.3:  average 162.5g reduction weight loaves bread \nbaking. reduction 95% confidence interval 159.1g 165.9g \nsignificantly different 0 (p-value<0.001).","code":"\ndf_bread <- \n    read.table(\"./Data/bread.txt\", sep=\"\\t\", header=T) %>% \n    mutate(oven = factor(oven), type = factor(type))df_bread %>% summarytools::dfSummary(graph.col = F)\nData Frame Summary  \ndf_bread  \nDimensions: 399 x 5  \nDuplicates: 0  \n\n--------------------------------------------------------------------------------------\nNo   Variable    Stats / Values             Freqs (% of Valid)    Valid      Missing  \n---- ----------- -------------------------- --------------------- ---------- ---------\n1    sid         Mean (sd) : 200 (115.3)    399 distinct values   399        0        \n     [integer]   min < med < max:           (Integer sequence)    (100.0%)   (0.0%)   \n                 1 < 200 < 399                                                        \n                 IQR (CV) : 199 (0.6)                                                 \n\n2    type        1. maize                   212 (53.1%)           399        0        \n     [factor]    2. wheat                   187 (46.9%)           (100.0%)   (0.0%)   \n\n3    before      Mean (sd) : 379.5 (28.1)   120 distinct values   399        0        \n     [integer]   min < med < max:                                 (100.0%)   (0.0%)   \n                 304 < 379 < 479                                                      \n                 IQR (CV) : 40 (0.1)                                                  \n\n4    after       Mean (sd) : 217 (29.8)     121 distinct values   399        0        \n     [integer]   min < med < max:                                 (100.0%)   (0.0%)   \n                 140 < 215 < 295                                                      \n                 IQR (CV) : 48 (0.1)                                                  \n\n5    oven        1. Firewood                199 (49.9%)           399        0        \n     [factor]    2. Gas                     200 (50.1%)           (100.0%)   (0.0%)   \n--------------------------------------------------------------------------------------\noptions(huxtable.knit_print_df = TRUE)\ndf_bread %>% \n    select(before, after) %>% \n    rstatix::get_summary_stats(type= \"mean_sd\")\ndf_bread %>% \n    mutate(diff_in_wgt = after - before) %>% \n    ggplot(aes(x = diff_in_wgt)) +\n    geom_histogram(bins = 10, col = \"white\") + \n    labs(x = \"Difference in weight\") +\n    theme_bw()\ndf_bread %>% \n    mutate(diff_in_wgt = after - before) %>%\n    rstatix::shapiro_test(vars = \"diff_in_wgt\")\ndf_bread %>%\n    pivot_longer(\n        cols = c(before, after), names_to = \"time\",values_to = \"weight\"\n        ) %>% \n    rstatix::t_test(formula = weight~time, paired = TRUE, detailed = TRUE)"},{"path":"analysis-of-numeric-data.html","id":"test-for-equality-of-variances","chapter":"13 Analysis of numeric data","heading":"13.5 Test for equality of variances","text":"using Student’s T-test determine difference means two\nindependent groups need mindful variances group. \ncomputations done independent groups t-test different \nvariances groups similar different. Therefore determine\nmean weight significantly differ males females need \ndetermine compare variances. function var.test() R compares\nvariances two independent groups can used \ndetermination.apply F-test compare variances weight\ntwo sexes. First determine variances.Table 13.4:  seem big difference variance weights \ntwo sexes. females almost 1.7 times males. \ndetermine chance finding apply formal statistical test.\nourH0: difference variance weights males \nfemales populationThe F-test actually tests ratio variances difference. \nregard null value 1.Table 13.5:  significant p-value (significance level 0.05) confidence\ninterval containing 1 (null value) implies little evidence\nvariance two groups (words \ndiffer significantly). case conclusion previous analysis \nvalid R assumes variances unequal default t.test()\nfunction used.Next apply principle determine mean heights \nsimilar males females population. first determine \nvariances significantly different.Table 13.6:  results variance females look much higher (1.3 times)\nmales however apply test formally determine .Table 13.7:  p-value confidence interval conclude insufficient evidence \nsay two variances different. use t.test() function determine\npossibility mean height differ males females specify\nvariance equal .Table 13.8:  ","code":"\ndf_data1 %>% \n    group_by(sex) %>%\n    summarise(across(weight, list(var = var, meam = mean)))df_data1 %>% \n    var.test(formula = weight~sex, data = .) %>% \n    broom::tidy() \nMultiple parameters; naming those columns num.df, den.df\ndf_data1 %>% \n    group_by(sex) %>%\n    summarise(\n        across(height, list(var = ~var(., na.rm=T), meam = ~mean(., na.rm=T)))\n    )df_data1 %>% \n    var.test(formula = height~sex, data = .) %>% \n    broom::tidy() \nMultiple parameters; naming those columns num.df, den.df\ndf_data1 %>%\n    rstatix::t_test(formula = height~sex, var.equal = TRUE, detailed = TRUE)── Attaching core tidyverse packages ──── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nAttaching package: 'magrittr'\n\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\nWarning: package 'huxtable' was built under R version 4.3.1\n\nAttaching package: 'huxtable'\n\nThe following object is masked from 'package:dplyr':\n\n    add_rownames\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_grey\n\n#StandWithUkraine\n\nAttaching package: 'gtsummary'\n\nThe following object is masked from 'package:huxtable':\n\n    as_flextable"},{"path":"analysis-of-categorical-data.html","id":"analysis-of-categorical-data","chapter":"14 Analysis of categorical data","heading":"14 Analysis of categorical data","text":"section discuss analyse categorical data, aggregated non-aggregated.","code":""},{"path":"analysis-of-categorical-data.html","id":"one-sample-binomial-test","chapter":"14 Analysis of categorical data","heading":"14.1 One-sample binomial test","text":"","code":""},{"path":"analysis-of-categorical-data.html","id":"one-sample-proportion-confidence-interval","chapter":"14 Analysis of categorical data","heading":"14.1.1 One sample proportion: Confidence interval","text":"study determine prevalence hypertension certain adult\npopulation, random sample taken revealed 23 67 hypertension. \nproportion hypertensive patients sample rather straightforward.\nApproximately 0.34 (34.3%) sample hypertensives. however\nextrapolate estimate proportion population estimating \nconfidence interval. single proportion estimation use \nbinom.test() function fulfilled conditions required \nuse. :sample obtained simple random samplingThere just two possible outcomes data, hypertension (successes) \nhypertension (failures).sample includes least 10 successes 10 failuresThe population least 20 times larger sample size.sample violating conditions, go ahead use one-sample\nbinomial test :Table 14.1:  binomial exact confidence interval proportion hypertension \nstudy population, therefore, 23.2% 46.9%.","code":"\nbinom.test(23, 67) %>% \n    broom::tidy() %>% \n    select(-method)"},{"path":"analysis-of-categorical-data.html","id":"one-sample-proportion-hypothesis-testing","chapter":"14 Analysis of categorical data","heading":"14.1.2 One sample proportion: Hypothesis testing","text":"data hypertension collected, investigator\nhypothesized 50% population hypertensive. Next, test \nhypothesis. usual, start setting null hypothesis.H0: population proportion hypertensive population 50%Table 9.1:  realised p-value identical last\ncomputation. binom.test() default tests proportion\n50:50 proportion population. 5% significance level, \nreject H0 conclude proportion hypertensive population\nsignificantly differs 50%., investigators hypothesized prevalence population\n40%? null hypothesis :H0: population proportion hypertensive 40%Next, test hypothesis.Table 6.1:  significance level 0.05, fail reject null hypothesis,\nconcluding insufficient evidence conclude population\nprevalence 40%.Finally, investigators hypothesized population\nprevalence hypertension least 47%? Remember one-sided test\nnull hypothesis beH0: population proportion hypertension greater equal 47%test hypothesisTable 10.1:  small p-value leads us reject H0 conclude insufficient\nevidence support assertion prevalence hypertension population least 47%.","code":"\nbinom.test(x=23, n=67, p=.5) %>% \n    broom::tidy()%>% \n    select(-method)\nbinom.test(x=23, n=67, p=.4) %>% \n    broom::tidy()%>% \n    select(-method)\nbinom.test(23, 67, p=.47, alternative = \"less\") %>% \n    broom::tidy()%>% \n    select(-method)"},{"path":"analysis-of-categorical-data.html","id":"two-or-more-sample-binomial-test","chapter":"14 Analysis of categorical data","heading":"14.2 Two or more sample binomial test","text":"","code":""},{"path":"analysis-of-categorical-data.html","id":"two-sample-proportion-hypothesis-testing","chapter":"14 Analysis of categorical data","heading":"14.2.1 Two sample proportion: Hypothesis testing","text":"Taking decide select different population sample 100\npersons determine proportion hypertension. \npopulation, came 52 hypertension patients hundred. aim compare significant difference proportion \nhypertension patients two populations. use \nprop.test() function R.First, state null hypothesis:\n>H0: population proportion hypertension populations .Next, test hypothesis. first create two vectors\nrepresenting number persons hypertension total samples\nchosen.Next, apply testTable 6.3:  p-value 0.0365 less regular significance level 0.05 \nreject null hypothesis say enough evidence conclude \nprevalence hypertension two populations.95% confidence interval generated difference \ntwo proportions, 0.177. confidence interval 0.014 0.339\ninclude null value 0 conclude difference \nprevalence hypertension 2 populations.","code":"\nhpt <-c(52, 23) # Vector of numbers with hypertension\nn <- c(100, 67) # Vector of numbers in the sample\nprop.test(x = hpt, n = n) %>% \n    broom::tidy()%>% \n    select(-method)"},{"path":"analysis-of-categorical-data.html","id":"chi-squared-test","chapter":"14 Analysis of categorical data","heading":"14.3 Chi-squared test","text":"Pearson’s chi-square test, also known chi-square goodness--fit test \nchi-square test independence used determine observed frequencies \ndata consistent expected. instance, Asia, \npercentages ABO blood groups population 38%, 10%, 3% 49% \ngroups , B, AB, O respectively. random sample 600 persons Kumasi,\nGhana 226, 82, 21 271 blood groups , B, AB, O respectively.\nchi-squared test can help us determine proportion blood groups\nfound Kumasi consistent seen Asia.","code":""},{"path":"analysis-of-categorical-data.html","id":"chi-squared-goodness-of-fit-test","chapter":"14 Analysis of categorical data","heading":"14.3.1 Chi-squared goodness of fit test","text":"blood group example investigators may want know \nproportions blood groups Kumasi consistent seen Asia.\nuse Chi-squared goodness fit test. always, begin \nmaking sure test can appropriately used condition. \nassumptions test :data obtained randomly populationThe variable study categoricalEach observed values category least 5With none conditions violated go ahead state null hypothesis asH0: distribution blood groups Kumasi different Asia.Next, perform test first create data frame \nexpected observed frequencies Asia Kumasi respectively.Table 13.1:  Next, illustrate proportions using barplot plotting blood\ngroups different regions side side.observe similarities proportions Kumasi Asia. \ninstance, blood groups regions show decreasing frequency O,\n, B AB. However, also observe adjacent bars exactly \nheight. Blood groups O B instance approximately 4%-point\ndifference two populations. Next, perform actual test \ndifference proportions.Table 6.5:  p-value 0.592, fail reject H0 conclude evidence\nproportions blood groups Kumasi different observed\nproportions Asia.","code":"\nbld_grp <- c(\"A\", \"B\", \"AB\", \"O\")\nAsia <- c(38.0, 10.0, 3.0, 49.9)\nKumasi  <- c(226, 82, 21, 271)\nKumasi <- round(Kumasi/sum(Kumasi)*100, 1)\ndf_temp <- data.frame(bld_grp, Asia, Kumasi)\ndf_temp\ndf_temp %>% \n    pivot_longer(\n        cols = c(Asia, Kumasi), \n        names_to = \"Place\", \n        values_to = \"Perc\") %>%\n    mutate(\n        labels = paste(\n            format(round(Perc,1), nsmall=1), \"%\", sep=\"\")) %>% \n    ggplot(aes(x = bld_grp, y = Perc, fill = Place)) +\n    geom_bar(stat=\"identity\", position= position_dodge()) +\n    geom_text(\n        aes(label=labels), vjust=1.5, color=\"black\", \n        size=3.5, position = position_dodge(0.9)) +\n    scale_fill_brewer(palette=\"Blues\") + \n    labs(\n        title=\"Comparative distribution of Blood Groups\", \n        x = \"Blood Group\", \n        y = \"Frequency\")+\n    theme_bw()chisq.test(x = Kumasi, p = Asia/sum(Asia)) %>% \n    broom::tidy()\nWarning in chisq.test(x = Kumasi, p = Asia/sum(Asia)):\nChi-squared approximation may be incorrect"},{"path":"analysis-of-categorical-data.html","id":"chi-squared-test-for-independent-data","chapter":"14 Analysis of categorical data","heading":"14.3.2 Chi-squared test for independent data","text":"subsection, use ANCdata epicalc package. can also\nobtained list data comes book. ANCdata\ncontains records high-risk pregnant women trial compare new \nold method antenatal care (anc) two clinics (clinic). outcome \nperinatal mortality, death baby within first week life (death).begin loading ANCdataOur objective section determine significant\nrelationship anc type perinatal death. words, \nperinatal mortality differ population depending anc method used?begin cross-tabulate two variables.cell proportions uniform. proportion deaths used\nold anc methods 11.0% 5.9% respectively. enough\nevidence conclude new better old population? \nquestion answer using formal statistical test.Test independence tabular data often entails use Chi-squared\ntest /Fisher’s exact test. Independence simply means one \none variable one predict variable.Next, apply chi-squared test verified data \nviolate assumption required use. .data obtained randomly populationThe variables study categoricalEach observation fits one cell tableThe expected values cell tabular data least 5Our data violate go ahead state null\nhypothesis.H0: difference proportion perinatal deaths mothers used new old ANC methods.perform testTable 6.11:  test yields relatively small p-value compared significance\nlevel 0.05, indicating null hypothesis independence cell\nproportions unlikely. words, cell proportions differ\nsignificantly, old method can said result significantly higher\nperinatal deaths compared new method.","code":"df_anc <- \n    read.delim(\"./Data/ANCData.txt\") %>% \n    mutate(\n        death = factor(death, levels = c(\"no\",\"yes\"), labels = c(\"No\", \"Yes\")),\n        clinic = factor(clinic),\n        anc = factor(anc, levels = c(\"old\", \"new\"), labels = c(\"Old\", \"New\")))\n\ndf_anc %>% summarytools::dfSummary(graph.col = FALSE)\nData Frame Summary  \ndf_anc  \nDimensions: 755 x 3  \nDuplicates: 747  \n\n--------------------------------------------------------------------------\nNo   Variable   Stats / Values   Freqs (% of Valid)   Valid      Missing  \n---- ---------- ---------------- -------------------- ---------- ---------\n1    death      1. No            689 (91.3%)          755        0        \n     [factor]   2. Yes            66 ( 8.7%)          (100.0%)   (0.0%)   \n\n2    anc        1. Old           419 (55.5%)          755        0        \n     [factor]   2. New           336 (44.5%)          (100.0%)   (0.0%)   \n\n3    clinic     1. A             497 (65.8%)          755        0        \n     [factor]   2. B             258 (34.2%)          (100.0%)   (0.0%)   \n--------------------------------------------------------------------------\ndf_anc %>% \n    tbl_cross(percent = \"col\",\n        row = death, \n        col = anc, \n        label = list(death ~ \"Death\", anc = \"ANC\")) %>% \n    bold_labels()\ndf_anc %>% \n    group_by(death, anc) %>% \n    count() %>% \n    ggplot(aes(fill = death, y = n, x = anc)) + \n    geom_bar(position = \"fill\", stat = \"identity\", col = \"black\") +\n    scale_fill_discrete(name = \"Death\", type = c(\"white\",\"red\"))+\n    labs(\n        y = \"Proportion\", \n        x = \"ANC Type\",\n        title = \"Distribution of the ANC method used and perinatal deaths\") +\n    theme_bw()\ndf_anc %$% \n    table(anc, death) %>% \n    chisq.test() %>% \n    broom::tidy()"},{"path":"analysis-of-categorical-data.html","id":"chi-squared-test-for-trend","chapter":"14 Analysis of categorical data","heading":"14.3.3 Chi-squared test for trend","text":"Often arise situations categorical data analysis objective \njust see difference proportions Chi-squared test independence\nFisher’s test determine trend proportions seen. \nChi-squared test trend often employed.example, study determine proportion persons eye changes\nfollowing data obtained: 4 42 persons aged less 45yrs, 7 \n43 aged 46yrs 55yrs, 12 46 aged 56yrs 65yrs \n15 44 aged 65yrs. First, input R calculate percentages eye changes.Next, determine percentage eye changes age groupNext, form matrix showing number persons eye changes, number\npersons studied percentage persons eye changes age\ngroup.analysis can said proportions persons eye\nchanges increases age. However, determine apparent rise \nchance finding apply Chi-Squared test confirm data \nviolate assumptions use. condition use like \nchi-squared test independent data addition least one \nvariables must ordered. Now satisfied data satisfies \nconditions state null hypothesis.H0: trend eye changes increasing ageNext, put formal testTable 13.5:  p-value less 0.05, reject H0 conclude \nsignificant trend (upward know ) developing eye changes \nincreasing age.","code":"\nNo.eye <- c(4,7,12,15)\nNo.studied <- c(42, 43, 46, 44)\nPerc.eye<-round(No.eye/No.studied * 100, 1)names(No.eye)<-c(\"<=45yrs\",\"46-55yrs\",\"56-65yrs\",\">65yrs\")\ncbind(No.eye, No.studied, Perc.eye)\n         No.eye No.studied Perc.eye\n<=45yrs       4         42      9.5\n46-55yrs      7         43     16.3\n56-65yrs     12         46     26.1\n>65yrs       15         44     34.1\nprop.trend.test(No.eye, No.studied) %>% \n    broom::tidy()"},{"path":"analysis-of-categorical-data.html","id":"fishers-exact-test","chapter":"14 Analysis of categorical data","heading":"14.4 Fisher’s Exact test","text":"valid conclusion use chi-squared test can guaranteed counts cells table question equal greater 5. Whenever count value cells 5, Fisher’s exact test must used instead. use interpretation similar chi-squared test demonstrated ANCdata .Table 13.6:  p-value quite like obtained chi-squared test \n. However, conclusion remains . added advantage using\nfisher.test() provision odds ratio 95% confidence\ninterval. odds ratio explained subsequent sections.","code":"\ndf_anc %$% \n    table(anc, death) %>% \n    fisher.test() %>% \n    broom::tidy()"},{"path":"risk-and-odds.html","id":"risk-and-odds","chapter":"15 Risk and Odds","heading":"15 Risk and Odds","text":"analysis effects depends mainly p-values confidence\nintervals difference proportions. common often better\nway expressing using Risk Odds. chapter, use \nANCData.txt data illustrate . First, read dataAnd summarize data","code":"\ndf_anc <- \n    read.delim(\"./Data/ANCData.txt\") %>% \n    mutate(\n        death = factor(death, levels = c(\"no\",\"yes\"), labels = c(\"No\", \"Yes\")),\n        clinic = factor(clinic),\n        anc = factor(anc, levels = c(\"old\", \"new\"), labels = c(\"Old\", \"New\")))df_anc %>% \n    summarytools::dfSummary(graph.col = FALSE)\nData Frame Summary  \ndf_anc  \nDimensions: 755 x 3  \nDuplicates: 747  \n\n--------------------------------------------------------------------------\nNo   Variable   Stats / Values   Freqs (% of Valid)   Valid      Missing  \n---- ---------- ---------------- -------------------- ---------- ---------\n1    death      1. No            689 (91.3%)          755        0        \n     [factor]   2. Yes            66 ( 8.7%)          (100.0%)   (0.0%)   \n\n2    anc        1. Old           419 (55.5%)          755        0        \n     [factor]   2. New           336 (44.5%)          (100.0%)   (0.0%)   \n\n3    clinic     1. A             497 (65.8%)          755        0        \n     [factor]   2. B             258 (34.2%)          (100.0%)   (0.0%)   \n--------------------------------------------------------------------------"},{"path":"risk-and-odds.html","id":"risk","chapter":"15 Risk and Odds","heading":"15.1 Risk","text":"Risk defined probability outcome. Therefore, \npopulation 100, 35 develop diabetes mellitus specified period \nfollow-, risk developing diabetes population \\[\\frac{35}{100} = 0.35\\]\nTabulation ANC method occurrence death , can conclude\nrisk perinatal mortality one uses old method 0.11 (11.0%)\nnew method 0.06 (5.9%).can written \n\\[Re = 0:06 \\text{ } Rne = 0:11\\]\\(Re\\) risk exposed group (new anc method) \\(Rne\\) \nrisk non-exposed (old anc method).","code":"\ndf_anc %>% \n    tbl_cross(percent = \"col\",\n        row = death, \n        col = anc, \n        label = list(death ~ \"Death\", anc = \"ANC\"),\n        digits = c(0,2)) %>% \n    bold_labels()"},{"path":"risk-and-odds.html","id":"risk-ratio","chapter":"15 Risk and Odds","heading":"15.2 Risk Ratio","text":"comparative way expressing risks two groups use \nRisk Ratio Relative Risk (RR).\n\n\\[RR = \\frac{Re}{Rne}\\]Note inference \\(Re\\) \\(Rne\\) \\(RR = 1\\). \\(RR\\)\nperinatal mortality new compared old method \\[RR = \\frac{5.952381}{10.978520} = 0.5421843 \\approx 0.54\\]epiDisplay package function cs() automatically calculates\nRR relevant stats confidence intervals. \napplied ANCdata .output first tabulates two variables producing contingency table\nmarginal totals. shows previously calculated parameters, Re\nRne. Rt (Risk total) risk exposed unexposed put\ntogether, .\\[Rt =\\frac{20 + 46}{419 + 336} = \\frac{66}{755} \\approx 0.09\\]next section output shows risk difference (difference \nrisks two groups), risk ratio, protective efficacy number\nneeded treat (NNT) together confidence intervals.Interpreting analysis far, conclude risk perinatal death\nusing new anc method significantly less using old method.\nsignificantly reduces risk death (Risk difference) 0.05 (5%) \nhalves chances death (RR = 0.54, 95%CI: 0.32 0.91). 20 (95%CI:\n11 95) pregnant women need treated new anc method prevent\none perinatal death (NNT).","code":"df_anc %$% epiDisplay::cs(outcome = death, exposure = anc, )\n\n          Exposure\nOutcome    Non-exposed Exposed Total\n  Negative 373         316     689  \n  Positive 46          20      66   \n  Total    419         336     755  \n                                    \n           Rne         Re      Rt   \n  Risk     0.11        0.06    0.09 \n                                         Estimate Lower95ci\n Risk difference (Re - Rne)              -0.05    -0.09    \n Risk ratio                              0.54     0.32     \n Protective efficacy =(Rne-Re)/Rne*100   45.8     8.71     \n   or percent of risk reduced                              \n Number needed to treat (NNT)            19.9     10.79    \n   or -1/(risk difference)                                 \n Upper95ci\n -0.01    \n 0.91     \n 68.06    \n          \n 94.2     \n          "},{"path":"risk-and-odds.html","id":"odds","chapter":"15 Risk and Odds","heading":"15.3 Odds","text":"Another way expressing risk outcome using Odds. Statistically odds\ndefined \\[Odds = \\frac{p}{1-p}\\]p probability outcome occurring. Using ANCdata probability \ndeath exposed .\\[pe = \\frac{20}{336} = 0.05952381\\]odds death exposed can determined \\[Oddse = \\frac{0.05952381}{1-0.05952381} = 0.06329114\\]Similarly, probability death non-exposed (old anc type) \\[pne = \\frac{46}{419} = 0.1097852\\]odds death non-exposed \\[Oddsne = \\frac{0.1097852}{1-0.1097852} = 0.1233244\\]","code":""},{"path":"risk-and-odds.html","id":"odds-ratio","chapter":"15 Risk and Odds","heading":"15.4 Odds ratio","text":"comparative way comparing two odds Odds Ratio (). \ndetermined \\[= \\frac{Oddse}{Oddsne} = 0.5132086 \\approx 0.51\\]fortunately go tedious procedure \ntime need calculate . cc() function epiDisplay\npackage well. apply analysis just done.output shows table variables question, 95%\nconfidence interval p-values determine chi-squared test \nFisher’s test. confidence interval odds ratio containing \nnull value 1, small p-values methods can concluded \nodds death mothers used new ANC method half (0.5) \nused old method probability obtaining values\nnull true, low (p-value = 0.019). Therefore, use new\nanc method associated significantly better perinatal outcomes compared\nold.Odds ratios important regression analysis dealt \ndetail subsequent chapters.","code":"df_anc %$% epiDisplay::cc(outcome=death, exposure=anc, graph = FALSE)\n\n       anc\ndeath   Old New Total\n  No    373 316   689\n  Yes    46  20    66\n  Total 419 336   755\n\nOR =  0.51 \n95% CI =  0.3, 0.89  \nChi-squared = 5.9, 1 d.f., P value = 0.015\nFisher's exact test (2-sided) P value = 0.019 "},{"path":"confounding-and-interaction.html","id":"confounding-and-interaction","chapter":"16 Confounding and Interaction","heading":"16 Confounding and Interaction","text":"","code":""},{"path":"confounding-and-interaction.html","id":"introduction-1","chapter":"16 Confounding and Interaction","heading":"16.1 Introduction","text":"new waiter employed bar serve ice glasses Accra made \nobservation seem irrational. realized customers served\nice often ended drunk. first accept make sense \nstrongly believe right. approached friend researcher \ndecided investigate . friend decided take data 510\nrandomly selected customers. data recorded drinks.txt.variables collected include id sequentially allocated study id, sex,\nsex customer, liquor whether customer took alcoholic liquor\n(spirits, brandy, etc), ice whether customer served ice glass,\ndrunk whether customer ended drunk, food whether customer\nserved food age, age years customer. task now \ndetermine data ingesting ice associated drunk.","code":""},{"path":"confounding-and-interaction.html","id":"effect-and-effect-size","chapter":"16 Confounding and Interaction","heading":"16.2 Effect and effect size","text":"","code":""},{"path":"confounding-and-interaction.html","id":"effect","chapter":"16 Confounding and Interaction","heading":"16.2.1 Effect","text":"begin discuss problem first look \nstatistical terms meant effect. effect defined change\noccurs consequence action. statistical terms, effect \nusually change one variable another. instance, effect \nmean change blood pressure (effect) taking drug (action). Two \ncommon ways expressing effect categorical data analysis \nodds ratio () Relative Risk (RR). two usually determine effect \ncomparing odds risk two groups expressing effect \nratios.","code":""},{"path":"confounding-and-interaction.html","id":"effect-size","chapter":"16 Confounding and Interaction","heading":"16.2.2 Effect size","text":"suffice report effect also size. People \nwant know intervention makes difference also much\ndifference makes. Effect size can opposite direction. instance, \ndifference blood pressure taking medication may positive\n(pressure taking drug taking) negative\n(pressure becomes less drug taken). hand, effects\ncan side difference magnitude. 5.1 much\nhigher 1.5 despite indicating increased odds outcome.\ngoing apply notion determining confounders effect\nmodifiers.Now back waiter’s issue. First, read data.summarize dataIn section, make use two main functions cc() mhor() \nepicalc package. First, determine effect ice concerning\ndrunk using odds ratio.appears waiter right! Taking ice associated significantly\nhigher odds getting drunk (: 1.73, 95% CI: 1.17 2.55, p<.001). \nagree defies logic. question : arise?","code":"\ndf_drinks <- \n    read.table(\"./Data/drinks.txt\", header=T, sep=\"\\t\") %>% \n    mutate(\n        across(\n            c(liquor, ice, drunk, food), \n            ~factor(.x, levels = c(0,1), labels = c(\"No\",\"Yes\"))\n        ),\n        sex = factor(sex)\n    )options(huxtable.knit_print_df = FALSE)\ndf_drinks %>% \n    summarytools::dfSummary(graph.col = F)\nData Frame Summary  \ndf_drinks  \nDimensions: 510 x 7  \nDuplicates: 0  \n\n---------------------------------------------------------------------------------------\nNo   Variable    Stats / Values              Freqs (% of Valid)    Valid      Missing  \n---- ----------- --------------------------- --------------------- ---------- ---------\n1    id          Mean (sd) : 255.5 (147.4)   510 distinct values   510        0        \n     [integer]   min < med < max:            (Integer sequence)    (100.0%)   (0.0%)   \n                 1 < 255.5 < 510                                                       \n                 IQR (CV) : 254.5 (0.6)                                                \n\n2    sex         1. Female                   256 (50.2%)           510        0        \n     [factor]    2. Male                     254 (49.8%)           (100.0%)   (0.0%)   \n\n3    liquor      1. No                       155 (30.4%)           510        0        \n     [factor]    2. Yes                      355 (69.6%)           (100.0%)   (0.0%)   \n\n4    ice         1. No                       191 (37.5%)           510        0        \n     [factor]    2. Yes                      319 (62.5%)           (100.0%)   (0.0%)   \n\n5    drunk       1. No                       186 (36.5%)           510        0        \n     [factor]    2. Yes                      324 (63.5%)           (100.0%)   (0.0%)   \n\n6    age         Mean (sd) : 35.8 (5.1)      31 distinct values    510        0        \n     [integer]   min < med < max:                                  (100.0%)   (0.0%)   \n                 19 < 36 < 51                                                          \n                 IQR (CV) : 7 (0.1)                                                    \n\n7    food        1. No                       288 (56.5%)           510        0        \n     [factor]    2. Yes                      222 (43.5%)           (100.0%)   (0.0%)   \n---------------------------------------------------------------------------------------\n\noptions(huxtable.knit_print_df = TRUE)\ndf_drinks %$% epiDisplay::cc(drunk, ice)\n       ice\ndrunk    No Yes Total\n  No     85 101   186\n  Yes   106 218   324\n  Total 191 319   510\n\nOR =  1.73 \n95% CI =  1.2, 2.51  \nChi-squared = 8.5, 1 d.f., P value = 0.004\nFisher's exact test (2-sided) P value = 0.004 "},{"path":"confounding-and-interaction.html","id":"confounding","chapter":"16 Confounding and Interaction","heading":"16.2.3 Confounding","text":"research often arises situation observed effect \nvariable tends depend another. instance, case, effect ice\nmaking customers drunk associated another item.\ncustomers took ice also took hard liquor time \nmay make seem taking ice associated drunk. \ntypical case confounding liquor ingestion\nconfounding effect ice.variable confounder must meet basic propertiesThe confounder must related exposure (ice) variableThe confounder must related outcome (drunk) variableThe confounder causal pathway exposure(ice)\noutcome (drunk).first two conditions easily tested statistically last can \ntested prior knowledge, often coming epidemiological scientific\nfacts. investigator bar study suspects liquor confounder \neffect ice sets determine . First, looks \nrelationship suspected confounder outcomeHaving liquor strongly associated drunk \n= 2.41 (95%CI: 1.6, 3.62, p<.001). Next, test association \nexposure possible confounder.strong association ice taking hard liquor\n(: 13.71, 95% CI: 8.48 22.33, p<.001). relationship established\nfirst two conditions stated fulfilled.next task determine consumption liquor confounder \neffect ice. determining adjusted comparing \ncrude (unadjusted ). recall crude 1.73\n(95% CI = 1.17 2.55, p=0.004). Mantel-Haenszel odd ratios determined \nmhor() function adjusted possible confounder. shown\nbelowThe function first stratifies odds getting drunk taking ice \nindividual groups possible confounding variable. determines\nlevel confounder, 1.14(95%CI= 0.621 2.05, p=0.666) \ntook liquor 1.13 (95%CI: 0.497 2.58, p=0.848) \n. reports MH combined (adjusted) 1.14 (95%CI: 0.726 \n1.78, p=0.574). Thus stratification adjustment reduced effect \nice significant 1.7 non-significant relationship 1.1. effect \ndisappeared ice longer significantly associated getting\ndrunk adjustment. shows ice cause people \ndrunk observed effect just issue confounding \nconsumption liquor.shown relationship three variables involved \ndemonstrating confounding effect liquor effect taking ice. can\nask: ice confounder relationship drunk \nconsumption liquor? Remember crude effect 2.41 (95%CI:\n1.6, 3.62, p<.001). answer question determine adjusted .output shows adjusted (=2.24, 95%CI: 1.41 3.56, p<.001) \nbarely different crude also retains significant effect. \nconsumption ice therefore confounder effect hard liquor.summary determine variable confounder need determine \nassociation exposure outcome variable. association\ndetermine crude effect adjusted effect. two \nsignificantly different can conclude presence confounder.However, definition “significant effect” always difficult determine.\nsay change least 10% crude effect can considered enough.\nWhenever possible confounder adjusted effect reported.\nAlso, worth noting effect change making effect higher \nlower. confounder instance results crude 2.4 \nadjusted 1.5 positive confounder one crude \n1.5 adjusted 2.5 shows negative confounding.","code":"\ndf_drinks %$% epiDisplay::cc(drunk, liquor)\n       liquor\ndrunk    No Yes Total\n  No     79 107   186\n  Yes    76 248   324\n  Total 155 355   510\n\nOR =  2.41 \n95% CI =  1.63, 3.55  \nChi-squared = 20.2, 1 d.f., P value = 0\nFisher's exact test (2-sided) P value = 0 df_drinks %$% epiDisplay::cc(ice, liquor, graph = F)\n\n       liquor\nice      No Yes Total\n  No    120  71   191\n  Yes    35 284   319\n  Total 155 355   510\n\nOR =  13.71 \n95% CI =  8.68, 21.67  \nChi-squared = 151.85, 1 d.f., P value = 0\nFisher's exact test (2-sided) P value = 0 df_drinks %$% epiDisplay::mhor(drunk, ice, liquor)\n\nStratified analysis by  liquor \n               OR lower lim. upper lim. P value\nliquor No    1.13      0.497       2.58   0.848\nliquor Yes   1.14      0.621       2.05   0.666\nM-H combined 1.14      0.726       1.78   0.574\n\nM-H Chi2(1) = 0.32 , P value = 0.574 \nHomogeneity test, chi-squared 1 d.f. = 0 , P value = 0.986 df_drinks %$% epiDisplay::mhor(drunk, liquor, ice)\n\nStratified analysis by  ice \n               OR lower lim. upper lim.  P value\nice No       2.22       1.16       4.33 0.010714\nice Yes      2.24       1.03       4.86 0.032828\nM-H combined 2.24       1.41       3.56 0.000589\n\nM-H Chi2(1) = 11.81 , P value = 0.001 \nHomogeneity test, chi-squared 1 d.f. = 0 , P value = 0.981 "},{"path":"confounding-and-interaction.html","id":"interaction-or-effect-modification","chapter":"16 Confounding and Interaction","heading":"16.3 Interaction or Effect modification","text":"common knowledge among drink alcoholic beverages filling\ntummy food often delays getting drunk one consumes alcoholic\nbeverages. investigator bar data now wants determine \n. notion right getting drunk taking hard liquor\ndependent whether customer also ordered ate food \nwell. typical example effect modification (term often used \nepidemiologists) interaction (used statisticians). two essentially\nmeans . definition, effect modification occurs effect size \nexposure (liquor) outcome (drunk) differs depending level \nthird variable (eating food). occurs just computing reporting \noverall effect misleading.begin investigation food causing interaction effect \ndrinking hard liquor determining getting drunk one took \nfood one didn’t.begin ate food.statistically insignificant odds getting drunk taking hard\nliquor one eats well 1.41 (95% CI: 0.8 2.51, p=0.208).\nNext, eatThe getting drunk one takes liquor empty stomach much\nhigher statistically significant (: 3.38, 95% CI: 1.82 6.26, p<.001).\nseem quite substantial difference effect drinking liquor\ndepending food intake . sure food intake significant\neffect modifier subject formal test using mhor() function.stratified analysis output shows prior calculated stratified ORs\nwell combined Mantel-Haenszel . Homogeneity test tests \nnull hypothesis:H0: difference two stratified Odds ratios.p-value 0.031, therefore, indicates statistically significant difference\neffects () ate . , therefore, conclude\nsignificant interaction food intake getting drunk\none takes hard liquor.section, dealt detecting confounder interaction variable\ncategorical data analysis. just scratching surface. subsequent\nchapters, dealing lot using regression analysis.","code":"\ndf_drinks %>% \n    filter(food == \"Yes\") %$% \n    epiDisplay::cc(drunk, liquor)\n       liquor\ndrunk    No Yes Total\n  No     47  60   107\n  Yes    41  74   115\n  Total  88 134   222\n\nOR =  1.41 \n95% CI =  0.82, 2.43  \nChi-squared = 1.59, 1 d.f., P value = 0.208\nFisher's exact test (2-sided) P value = 0.219 \ndf_drinks %>% \n    filter(food == \"No\") %$% \n    epiDisplay::cc(drunk, liquor)\n       liquor\ndrunk    No Yes Total\n  No     32  47    79\n  Yes    35 174   209\n  Total  67 221   288\n\nOR =  3.38 \n95% CI =  1.9, 6.03  \nChi-squared = 18.13, 1 d.f., P value = 0\nFisher's exact test (2-sided) P value = 0 df_drinks %$% epiDisplay::mhor(drunk, liquor, food, graph = F)\n\nStratified analysis by  food \n               OR lower lim. upper lim.  P value\nfood No      3.37      1.817       6.26 4.16e-05\nfood Yes     1.41      0.795       2.51 2.19e-01\nM-H combined 2.08      1.406       3.09 1.78e-04\n\nM-H Chi2(1) = 14.05 , P value = 0 \nHomogeneity test, chi-squared 1 d.f. = 4.65 , P value = 0.031 "},{"path":"diagnostic-tests.html","id":"diagnostic-tests","chapter":"17 Diagnostic Tests","heading":"17 Diagnostic Tests","text":"Scientific testing presence various disease conditions processes\ncommon everyday life. range complex testing \npresence strange diseases newly manufactured electrical gadgets \ndefects. often Gold Standard test, one deemed \nperfectly determine presence absence condition. However, \nalways search alternative tests often cheaper easier\nuse compared Gold standard.study diagnose malaria children attending outpatient clinic Ghana, children clinical suspicion malaria tested using three\nmethods. First, blood film reported count malaria parasites\n(Gold standard) done. Two rapid diagnostic kits, called RDT.1 RDT.2\nalso done concurrently reported positive (1) negative (0). \ndone 100 patients recorded malaria.csv. task \nevaluate RDT.1’s ability accurately reliably diagnose malaria.First, read dataThe summary data shown belowAnd tabulate rdt.1 Gold Standard asThe table decomposes test results 4 distinct categories.RDT.1 gold standard positive (True positive) 50.group RDT.1 Gold standard negative (True Negative) 44.group showed positive RDT.1 results negative Gold standard (False positive) 2.Finally last group, whose RDT.1 results negative positive\njudging Gold standard (False negative) 4.operationalise extracting relevant portions table ","code":"\ndf_malaria <- \n    read_csv(\"./Data/malaria.txt\") %>% \n    mutate(\n        gold = ifelse(mps == 0, 0, 1) %>% \n            factor(levels = c(1,0),\n                   labels = c(\"Positive\", \"Negative\")),\n        across(\n            c(rdt.1, rdt.2), \n            ~factor(\n                .x, \n                levels = c(1,0),\n                labels = c(\"Positive\", \"Negative\"),\n            )\n        )\n    )df_malaria %>% summarytools::dfSummary(graph.col = F)\nData Frame Summary  \ndf_malaria  \nDimensions: 100 x 4  \nDuplicates: 44  \n\n-----------------------------------------------------------------------------------------\nNo   Variable    Stats / Values                 Freqs (% of Valid)   Valid      Missing  \n---- ----------- ------------------------------ -------------------- ---------- ---------\n1    mps         Mean (sd) : 3365.2 (23683.3)   53 distinct values   100        0        \n     [numeric]   min < med < max:                                    (100.0%)   (0.0%)   \n                 0 < 62.5 < 236155                                                       \n                 IQR (CV) : 413.8 (7)                                                    \n\n2    rdt.1       1. Positive                    52 (52.0%)           100        0        \n     [factor]    2. Negative                    48 (48.0%)           (100.0%)   (0.0%)   \n\n3    rdt.2       1. Positive                    51 (51.0%)           100        0        \n     [factor]    2. Negative                    49 (49.0%)           (100.0%)   (0.0%)   \n\n4    gold        1. Positive                    54 (54.0%)           100        0        \n     [factor]    2. Negative                    46 (46.0%)           (100.0%)   (0.0%)   \n-----------------------------------------------------------------------------------------\ndf_malaria %>% \n    gtsummary::tbl_cross(\n        col = gold,\n        row = rdt.1,\n        label = list(\n            gold ~ \"Gold Standard\",\n            rdt.1 ~ \"First RDT\"\n        )\n    ) %>% \n    gtsummary::bold_labels()\ntp <- 50\ntn <- 44\nfp <- 2\nfn <- 4"},{"path":"diagnostic-tests.html","id":"true-prevalence-of-the-disease","chapter":"17 Diagnostic Tests","heading":"17.1 True prevalence of the disease","text":"true prevalence disease proportion diseased individuals\nobserved study population determined gold standard. \nmathematically given \n\\[True~prevalence = \\frac{tp + fn}{tp + tn + fp + fn}\\]determined data ","code":"true.prevalence <- (tp+fn)/(tp+tn+fp+fn)\ntrue.prevalence\n[1] 0.54"},{"path":"diagnostic-tests.html","id":"apparent-prevalence-of-the-disease","chapter":"17 Diagnostic Tests","heading":"17.2 Apparent prevalence of the disease","text":"apparent prevalence disease proportion diseased\nindividuals observed study population determined RDT.1 test.\nmathematically given \n\\[Apparent~prevalence = \\frac{tp + fp}{tp + tn + fp + fn}\\]\ndetermined data ","code":"apparent.prevalence<-(tp+fp)/(tp+tn+fp+fn)\napparent.prevalence\n[1] 0.52"},{"path":"diagnostic-tests.html","id":"sensitivity-of-a-test","chapter":"17 Diagnostic Tests","heading":"17.3 Sensitivity of a test","text":"sensitivity test defines proportion individuals \ndisease correctly identified test applied. ranges 0, completely useless test 1, perfect test. Mathematically defined \\[Sensitivity = \\frac{tp}{tp + fn}\\]\ndetermined ","code":"sensitivity <- tp/(tp+fn)\nsensitivity\n[1] 0.9259259"},{"path":"diagnostic-tests.html","id":"specificity-of-a-test","chapter":"17 Diagnostic Tests","heading":"17.4 Specificity of a test","text":"specificity test defined proportion individuals without \ndisease correctly identified test used. ranges 0, \ncompletely useless test 1, perfect test. Mathematically defined \n\\[Specificity = \\frac{tn}{tn + fp}\\]determine ","code":"specificity<-tn/(tn+fp)\nspecificity\n[1] 0.9565217"},{"path":"diagnostic-tests.html","id":"predictive-value-of-a-test","chapter":"17 Diagnostic Tests","heading":"17.5 Predictive value of a test","text":"","code":""},{"path":"diagnostic-tests.html","id":"positive-predictive-value-of-a-test","chapter":"17 Diagnostic Tests","heading":"17.5.1 Positive predictive value of a test","text":"positive predictive value (PPV) test defined proportion \nindividuals positive test result disease. \nuseful measure compared sensitivity specificity indicates\nmuch weight one put positive test result confronted \none. Mathematically defined :\\[PPV = \\frac{tp}{tp + fp}\\]","code":"ppv <- tp/(tp+fp)\nppv\n[1] 0.9615385"},{"path":"diagnostic-tests.html","id":"negative-predictive-value-of-a-test","chapter":"17 Diagnostic Tests","heading":"17.5.2 Negative predictive value of a test","text":"negative predictive value (npv) test defined proportion \nindividuals negative test result disease. \nppv useful measure compared sensitivity \nspecificity indicates much weight one put negative test\nresult confronted one. Mathematically defined :\n\\[NPV = \\frac{tn}{tn + fn}\\]\ndetermined ","code":"npv <- tn/(tn+fn)\nnpv\n[1] 0.9166667"},{"path":"diagnostic-tests.html","id":"likelihood-ratio-of-a-test","chapter":"17 Diagnostic Tests","heading":"17.6 Likelihood ratio of a test","text":"likelihood ratio test another way expressing usefulness.\nUnlike previous statistics tests, likelihood ratios stretch beyond\n0 1. likelihood ratio 1 indicates useless (non-discriminatory) test.","code":""},{"path":"diagnostic-tests.html","id":"the-positive-likelihood-ratio-lr","chapter":"17 Diagnostic Tests","heading":"17.6.1 The Positive likelihood ratio (LR+)","text":"ratio chance positive result patient \ndisease chance positive result disease. \nhigher positive likelihood better test.mathematically equivalent \\[LR+ = \\frac{Sensitivity}{1-Specificity}\\]Applying data far ","code":"pLR <- sensitivity/(1-specificity)\npLR\n[1] 21.2963"},{"path":"diagnostic-tests.html","id":"negative-liklihood-ratio-lr-","chapter":"17 Diagnostic Tests","heading":"17.6.2 Negative liklihood ratio (LR-)","text":"negative likelihood ratio (LR-) hand ratio \nchance person negative result disease chance \nnegative result person disease. lower negative\nlikelihood better test.Computationally equivalent \n\\[LR+ = \\frac{1-Sensitivity}{Specificity}\\]\nApplying data far ","code":"nLR<-(1-sensitivity)/specificity\nnLR\n[1] 0.07744108"},{"path":"diagnostic-tests.html","id":"summary-2","chapter":"17 Diagnostic Tests","heading":"17.7 Summary","text":"Fortunately, can obtained one go using epi.tests() function\nepiRpackage. function however requires table formatted \nspecific way. create tableAnd evaluate testConclusion: high (0.9) Sensitivity, Specificity, PPV \nNPV, test appears good one. confirmed relatively\nhigh LR+ low LR-.","code":"table.test <- \n    df_malaria %$%\n    table(rdt.1, gold)\n\ntable.test\n          gold\nrdt.1      Positive Negative\n  Positive       50        2\n  Negative        4       44table.test %>% epiR::epi.tests()\n          Outcome +    Outcome -      Total\nTest +           50            2         52\nTest -            4           44         48\nTotal            54           46        100\n\nPoint estimates and 95% CIs:\n--------------------------------------------------------------\nApparent prevalence *                  0.52 (0.42, 0.62)\nTrue prevalence *                      0.54 (0.44, 0.64)\nSensitivity *                          0.93 (0.82, 0.98)\nSpecificity *                          0.96 (0.85, 0.99)\nPositive predictive value *            0.96 (0.87, 1.00)\nNegative predictive value *            0.92 (0.80, 0.98)\nPositive likelihood ratio              21.30 (5.48, 82.77)\nNegative likelihood ratio              0.08 (0.03, 0.20)\nFalse T+ proportion for true D- *      0.04 (0.01, 0.15)\nFalse T- proportion for true D+ *      0.07 (0.02, 0.18)\nFalse T+ proportion for T+ *           0.04 (0.00, 0.13)\nFalse T- proportion for T- *           0.08 (0.02, 0.20)\nCorrectly classified proportion *      0.94 (0.87, 0.98)\n--------------------------------------------------------------\n* Exact CIs"},{"path":"agreement.html","id":"agreement","chapter":"18 Agreement","heading":"18 Agreement","text":"","code":""},{"path":"agreement.html","id":"introduction-2","chapter":"18 Agreement","heading":"18.1 Introduction","text":"chapter deals methods evaluating agreement two different\nmeasurements, either done two different methods method done \ntwo different times. understand need define terms :Accuracy:Precision:Measurement variabilityMeasurement errorReliability:","code":""},{"path":"receiver-operating-characteristic.html","id":"receiver-operating-characteristic","chapter":"19 Receiver Operating Characteristic","heading":"19 Receiver Operating Characteristic","text":"now, dealt tests categorized either positive \nnegative. However, many tests quantitative rather qualitative. \ninstance, blood urea nitrogen, serum cholesterol serum protein among\nmany others measured continuous scale often ranging 0 infinity.\ntests pose different challenges often need cut-point \ndetermine range values can considered “normal” “abnormal”. \nlearned sensitivity specificity test often used \ndefine good . tests continuous scale sensitivity \nspecificity change depending cut-provided measure.section, use lbw.csv data collected study conducted \ncohort 350 newborns Ghana. identification babies born weight\nless 2.5 kg important special needs require. \nmany underdeveloped countries, however, unavailability reliable weighing\nscale makes challenge. prompted search surrogate\nmeasures easily available rural areas determining baby low birth\nweight (<2.5kgs). study aimed determine well length \nchest circumference baby used surrogate indicator low\nbirth weight newborns. turn good tests can easily \ndeployed rural area instrument needed \nmeasuring tape. variables collected include study ID (sid), birth\nweight (bweight), sex (gender), chest circumference (chc) length\nbaby (lgth).First, read data clearing workspaceAnd summarize itNext, introduce pROC package. function roc() package \nused extensively section.","code":"\ndf_lbw <- \n    read_csv(\"./Data/lbw.csv\") %>% \n    mutate(gender = factor(gender)) %>% \n    mutate(bwcat = ifelse(bweight < 2.5, 1, 0) %>% \n               factor(levels = c(0,1), labels = c(\"Normal\",\"Low\")))df_lbw %>% dfSummary(graph.col = F)\nData Frame Summary  \ndf_lbw  \nDimensions: 350 x 6  \nDuplicates: 0  \n\n---------------------------------------------------------------------------------------\nNo   Variable    Stats / Values              Freqs (% of Valid)    Valid      Missing  \n---- ----------- --------------------------- --------------------- ---------- ---------\n1    sid         Mean (sd) : 175.5 (101.2)   350 distinct values   350        0        \n     [numeric]   min < med < max:                                  (100.0%)   (0.0%)   \n                 1 < 175.5 < 350                                                       \n                 IQR (CV) : 174.5 (0.6)                                                \n\n2    bweight     Mean (sd) : 2.9 (0.6)       33 distinct values    350        0        \n     [numeric]   min < med < max:                                  (100.0%)   (0.0%)   \n                 1 < 2.9 < 4.5                                                         \n                 IQR (CV) : 0.7 (0.2)                                                  \n\n3    gender      1. Female                   166 (47.4%)           350        0        \n     [factor]    2. Male                     184 (52.6%)           (100.0%)   (0.0%)   \n\n4    chc         Mean (sd) : 31.7 (3.2)      115 distinct values   350        0        \n     [numeric]   min < med < max:                                  (100.0%)   (0.0%)   \n                 20 < 32 < 42.1                                                        \n                 IQR (CV) : 4 (0.1)                                                    \n\n5    lgth        Mean (sd) : 46.8 (4.3)      109 distinct values   350        0        \n     [numeric]   min < med < max:                                  (100.0%)   (0.0%)   \n                 28 < 47 < 60.3                                                        \n                 IQR (CV) : 5.5 (0.1)                                                  \n\n6    bwcat       1. Normal                   268 (76.6%)           350        0        \n     [factor]    2. Low                       82 (23.4%)           (100.0%)   (0.0%)   \n---------------------------------------------------------------------------------------"},{"path":"receiver-operating-characteristic.html","id":"sensitivity-specificity-and-cut-offs","chapter":"19 Receiver Operating Characteristic","heading":"19.1 Sensitivity, specificity and cut-offs","text":"mentioned one gold standard bivariate (indicating\npresence absence) quantitative test, sensitivity specificity \ntest depends cut-chosen. lbw.csv data gold standard\nlow birth weight baby birth weight categorised low birth\nweight (LBW) normal birth weight (NBW). Two continuous measures, chest\ncircumference length baby used tests.illustrate relationship various cut-offs sensitivity \nspecificity generate arbitrary cut-offs.cut-offs, generate categories length babies\ntabulate resultant categorical variable.count various groupsNext, determine sensitivities specificities various cut-offs \nusing roc() function pROC package. Since package requires\nordered categorical variable convert lgthcat ordered factor\nvariable. go ahead impute relevant information roc()\nfunction","code":"\ncut.off <- c(28, 42, 44, 46, 47, 49, 50, 51, 61)\ndf_lbw <- \n    df_lbw %>% \n    mutate(lgthcat = cut(lgth, br=cut.off, include.lowest=T))\ndf_lbw %>% \n    gtsummary::tbl_summary(\n        include = lgthcat,\n        digits = lgthcat ~ c(0,1)\n    ) %>% \n    gtsummary::bold_labels()"},{"path":"linear-regression.html","id":"linear-regression","chapter":"20 Linear Regression","heading":"20 Linear Regression","text":"","code":""},{"path":"linear-regression.html","id":"introduction-3","chapter":"20 Linear Regression","heading":"20.1 Introduction","text":"Regression plays key part modern-day statistics. R advanced regression\nfunctions includes; lm() (fitting linear models), glm() (fitting\ngeneralized linear models), nls() (fitting nonlinear models) coxph()\n(fitting Cox proportional hazards regression model).statistical analysis, often arises relationship two\ncontinuous variables expressed rate rise per unit .\ninstance, one can ask:average, many units rise blood hematocrit occurs unit rise blood haemoglobin content?Readers conversant may guess answer approximately 3.","code":""},{"path":"linear-regression.html","id":"regression-with-single-continuous-independent-variable","chapter":"20 Linear Regression","heading":"20.2 Regression with single continuous independent variable","text":"basic idea behind linear regression formula dependent\nvariable can derived independent variable(s). Simply put \ngiven one’s hb can predict person’s hct? come \nformula form\n\\[Y = aX + b\\]\n\\(Y\\) dependent variable (hct), \\(\\) slope straight line\ndraw points, \\(X\\) independent variable (hb) \\(b\\) \nintercept value \\(Y\\) \\(\\) 0.first logical step regression analysis plot scatter diagram \nvisualize relationship two variables. plot hct versus\nhb shown importing dataAnd summarize data belowWe now derive constants lm() function .Table 6.3:  table gives us values intercept (b) 1.625 slope\n() 2.778. can thus say based data increase \napproximately 2.788 hematocrit unit rise Hb. Also, hct \nperson Hb 0 (anything like ) 1.625. However, \nnever good idea extrapolate formula beyond range data \nhand. instance, predicting hct anyone hb 200 \nstatistically common sensically right.Conclusion: unit rise blood hb hematocrit rises 2.8%\nsample. Extrapolating onto general population 95% certain\nrate rise fall 2.6% 2.9%. observed slope \nsignificantly different slope 0. evident small p-value\n(<.001).","code":"\ndf_blood <- read_csv(\"./Data/blood.csv\")df_blood %>% summarytools::dfSummary(graph.col = F)\nData Frame Summary  \ndf_blood  \nDimensions: 50 x 7  \nDuplicates: 0  \n\n--------------------------------------------------------------------------------------\nNo   Variable    Stats / Values              Freqs (% of Valid)   Valid      Missing  \n---- ----------- --------------------------- -------------------- ---------- ---------\n1    stno        Mean (sd) : 1025.5 (14.6)   50 distinct values   50         0        \n     [numeric]   min < med < max:                                 (100.0%)   (0.0%)   \n                 1001 < 1025.5 < 1050                                                 \n                 IQR (CV) : 24.5 (0)                                                  \n\n2    age         Mean (sd) : 122.4 (30.7)    19 distinct values   50         0        \n     [numeric]   min < med < max:                                 (100.0%)   (0.0%)   \n                 72 < 132 < 180                                                       \n                 IQR (CV) : 48 (0.3)                                                  \n\n3    wgt         Mean (sd) : 27.4 (7.7)      42 distinct values   50         0        \n     [numeric]   min < med < max:                                 (100.0%)   (0.0%)   \n                 17 < 26.3 < 59.5                                                     \n                 IQR (CV) : 7.9 (0.3)                                                 \n\n4    hgt         Mean (sd) : 130.5 (11.4)    27 distinct values   50         0        \n     [numeric]   min < med < max:                                 (100.0%)   (0.0%)   \n                 107 < 130.5 < 155                                                    \n                 IQR (CV) : 15 (0.1)                                                  \n\n5    hb          Mean (sd) : 8.2 (1.8)       36 distinct values   50         0        \n     [numeric]   min < med < max:                                 (100.0%)   (0.0%)   \n                 5.3 < 7.7 < 12                                                       \n                 IQR (CV) : 2.6 (0.2)                                                 \n\n6    wbc         Mean (sd) : 13.9 (8.8)      44 distinct values   50         0        \n     [numeric]   min < med < max:                                 (100.0%)   (0.0%)   \n                 4.8 < 11.4 < 62.6                                                    \n                 IQR (CV) : 5.7 (0.6)                                                 \n\n7    hct         Mean (sd) : 24.4 (5.1)      45 distinct values   50         0        \n     [numeric]   min < med < max:                                 (100.0%)   (0.0%)   \n                 15.7 < 23 < 35                                                       \n                 IQR (CV) : 7.4 (0.2)                                                 \n--------------------------------------------------------------------------------------\ndf_blood %>% \n    ggplot(aes(x = hb, y = hct)) +\n    geom_point(color = \"red\",)+\n    geom_smooth(method = \"lm\", formula = y~x, color = \"skyblue\", se = F)+\n    labs(x = \"Hemoglobin (mg/dl)\", y = \"Hematocrit (%)\") +\n    theme_bw()\ndf_blood %>% \n    lm(hct ~ hb, data=.) %>% \n    broom::tidy(conf.int=T)"},{"path":"linear-regression.html","id":"regression-with-single-categorical-independent-variable","chapter":"20 Linear Regression","heading":"20.3 Regression with single categorical independent variable","text":"Previously implemented linear regression one continuous independent\nvariable. implement linear regression categorical independent\nvariable. blood data set, categorical variable \ngenerate one categorising high wbc (>11.0 x 109/ml) “High” others “Low”.Table 13.1:  Next, implement linear regressionTable 6.4:  interpretation slightly different single continuous\nvariable.estimate (Intercept) mean hct lower level \nwbc.cat .e. wbc categorised “Low”. mean hct \n“Low” wbc therefore 27.055.coefficient wbc.catHigh difference mean hct \n“High” “Low” wbc.cat categories. Therefore difference mean hct\n“High” “Low” wbcs -4.705.mean hct “High” wbc.cat therefore\n(Intercept) plus coefficient wbc.catHigh. \n\\(27.055 + (-4:405) = 22:35\\).comparative purposes, perform analysis t.test() function :Table 6.5:  close look shows two analyses produce identical results. t-statistic,\np-value, 95% confidence interval difference sample estimates \nidentical. question arises: can easily derive \nt.test() function go hassle fitting linear regression\nmodel? reason regression opens whole new world statistics without\nmany manipulations difficult impossible achieve.Conclusion: mean hct “Low” wbc.cat 27.0 95%\nconfidence interval (25.1 29.0). difference hct \n“High” “Low” wbc -4.7 95% confidence interval (-7.3 -2.1).\ndifference two means significantly different 0 \np-value = 0.001.","code":"\ndf_blood <-\n    df_blood %>% \n    mutate(wbc.cat = case_when(wbc > 11 ~ \"High\", TRUE ~ \"Low\") %>% \n               factor(levels=c(\"Low\",\"High\")))\n\ndf_blood %>% head()\ndf_blood %>% \n    lm(hct ~ wbc.cat, data=.) %>% \n    broom::tidy(conf.int=T)\ndf_blood %$% \n    t.test(hct ~ wbc.cat, var.equal=TRUE) %>% \n    broom::tidy()"},{"path":"linear-regression.html","id":"regression-with-two-continuous-independent-variables","chapter":"20 Linear Regression","heading":"20.4 Regression with two continuous independent variables","text":"Previously dealt identifying reporting confounder \nconfounding categorical data analysis. effect used odds\nratio. subsection, deal confounding linear regression using\nregression coefficient often represented \\(\\beta\\) effect.Previously identified significant linear relationship \nblood hb hct. illustrative purposes, present show just\ncoefficients, confidence interval p-values.Table 6.6:  output shows significant relationship hb hct\n(\\(\\beta\\) = 2.778, 95%CI: 2.644 2.932, p=<.001). Previously, learned \nconfounder related outcome exposure variable. \npreliminary analysis, decided see wbc also related hct.\ndone belowTable 6.7:  Interestingly appears . seems significant reduction wbc\ncount increasing hct. question arises:effect wbc confounded hb?begin investigate must first check wbc relationship \nhb well. done belowTable 6.8:  result indicates significant reduction wbc increasing hb.\nresult, demonstrated relationship three variables\nnecessary confounding exist.Next, determine adjusted coefficients comparison crude ones.\nput variables independent variables linear regression\nformula belowTable 6.9:  coefficients generated (hb wbc) adjusted . First\ncompare crude effect hb (\\(\\beta\\) = 2.778, 95%CI: 2.644 2.932, p<.001)\nadjusted effect (\\(\\beta\\) = 2.783, 95%CI: 2.621 2.946, p<.001). \nobvious literally confounding relationship hb hct\nwbc coefficient remains literally .Next, compare crude relationship wbc hct (\\(\\beta\\) = -0.255,\n95%CI: -0.405 -0.104, p=0.001) adjusted relationship (\\(\\beta\\) = -0.002,\n95%CI: -0.035 0.031, p=0.895). observe significant change\nsignificant negative crude relationship literally relationship\n. Thus conclude hb confounder relationship\nhct wbc.","code":"\ndf_blood %>% lm(hct ~ hb, data=.) %>% broom::tidy(conf.int=T) \ndf_blood %>% lm(hct ~ wbc, data=.) %>% broom::tidy(conf.int=T) \ndf_blood %>% lm(wbc ~ hb, data=.) %>% broom::tidy(conf.int=T) \ndf_blood %>% lm(hct ~ hb + wbc, data=.) %>% broom::tidy(conf.int=T) "},{"path":"linear-regression.html","id":"regression-with-continuous-and-categorical-independent-variables","chapter":"20 Linear Regression","heading":"20.4.1 Regression with continuous and categorical independent variables","text":"section perform linear regression involving three variables; hct,\nhb wbc.cat. type linear regression done answer questions like:rate change hct unit rise hb \n“High” “Low” wbc.cat?answer question perform linear regression :Table 6.10:  regression output three coefficients. First (intercept), \napparent value hct “Low” wbc Hb 0. determine \nvalue intercept persons High wbc add intercept term\ncoefficient wbc.catHigh.lines, slope coefficient hb. Thus intercept \n“Low” wbc 2.300622, High wbc \\(2.300622 + -0.435617 = 1.865005\\)\ncommon slope lines 2.735240. represented graphically\nbelowConclusion: data, hct persons High WBC count \n0.4% lower Low WBC assuming two rise rate \ngroups. difference however statistically significantly different\n0 (p = 0.128). Thus enough evidence \ndifference levels hct depending level one’s WBC.","code":"\ndf_blood %>% lm(hct ~ hb + wbc.cat, data=.) %>% broom::tidy(conf.int=T) \ndf_blood %>% \n    ggplot() +\n    geom_point(aes(x = hb, y = hct, col = wbc.cat))+\n    geom_abline(\n        aes(intercept = 2.300622, slope = 2.735240, col = \"Low\"), \n        show.legend = T)+\n    geom_abline(\n        aes(intercept = 2.300622 + -0.435617, slope = 2.735240, col = \"High\"), \n        show.legend = T) +\n    labs(x = \"Hemoglobin (mg/dl)\", y = \"Hematocrit (%)\")+\n    scale_color_manual(\n        name = \"WBC Category\", \n        values = c(\"Low\" = \"red\", \"High\" = \"blue\")) +\n    theme_bw()"},{"path":"linear-regression.html","id":"regression-with-continuous-and-categorical-independent-variables-with-interaction","chapter":"20 Linear Regression","heading":"20.5 Regression with continuous and categorical independent variables with interaction","text":"analysis assumed slopes two lines .\nHowever, usually case. determine individual slopes well\nintercepts need linear regression interaction term.\nanalysis, seek answer question:rate rise hct every rise hb significantly different \npersons High compared Low WBC?.Fitting linear regression done R .Table 13.2:  Four coefficients generated. (Intercept) intercept “Low”\nwbc group. hb coefficient represents slope line representing\n“Low” wbc. intercept “High” WBC sum (Intercept)\nwbc.catHigh (\\(1.93925961 + 0.19624236 = 2.135502\\)). Finally, slope \nregression line “High” wbc sum coefficients hb \nhb:wbc.catHigh (\\(2.77516971 + -0.07604741 = 2.699122\\)).graphically shown belowIt obvious slopes (rate rise hct concerninga unit rise hb) different two groups. High WBC\ngroup lower. However, decrease rate rise real effect just\nchance observation? answer question need use inferential\nstatistics.now concern line hb:wbc.catHigh indicates \ndifference slopes two. appears slope “High” wbc\ngroup -0.076 (95%CI: -0.394 0.242, p=0.633) less “Low” wbc\ngroup. difference however statistically significant.Conclusion: confidence interval contains null value 0 \nprobability difference arisen chance relatively high\n(0.633), conclude significant evidence difference \nslopes “High” “Low” WBCs.","code":"\ndf_blood %>% lm(hct ~ hb*wbc.cat, data=.) %>% broom::tidy(conf.int=T) df_blood %>% \n    ggplot(aes(x = hb, y = hct, color = wbc.cat))+\n    geom_point()+\n    geom_smooth(formula = y~x, se=FALSE, method = lm, size = .5)+\n    theme_bw()+\n    labs(x = \"Hemoglobin (mg/dl)\", y = \"Hematocrit (%)\")+\n    scale_color_manual(\n        name = \"WBC Category\", \n        values = c(\"Low\" = \"red\", \"High\" = \"blue\")) \nWarning: Using `size` aesthetic for lines was deprecated in ggplot2\n3.4.0.\nℹ Please use `linewidth` instead.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where\nthis warning was generated."},{"path":"linear-regression.html","id":"assumptions","chapter":"20 Linear Regression","heading":"20.6 Assumptions","text":"","code":"library(tidyverse)\n── Attaching core tidyverse packages ──── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nlibrary(magrittr)\n\nAttaching package: 'magrittr'\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\nThe following object is masked from 'package:tidyr':\n\n    extract\nlibrary(huxtable)\nWarning: package 'huxtable' was built under R version 4.3.1\n\nAttaching package: 'huxtable'\n\nThe following object is masked from 'package:dplyr':\n\n    add_rownames\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_grey"},{"path":"logistic-regression.html","id":"logistic-regression","chapter":"21 Logistic Regression","heading":"21 Logistic Regression","text":"now, dealt linear regression requires continuous\ndependent variable. However research, especially medical research, lots \noutcome variables binary disease present absent, death \nsurvival cured cured. Modelling binary outcome data usually requires\nlogistic regression done R using glm() function \nfamily specified binomial.section, go back ANCdata used previously.summarize ","code":"\ndf_anc <- \n    readstata13::read.dta13(\".\\\\Data\\\\ANCdata.dta\")df_anc %>% summarytools::dfSummary(graph.col = F)\nData Frame Summary  \ndf_anc  \nDimensions: 755 x 3  \nDuplicates: 747  \n\n--------------------------------------------------------------------------\nNo   Variable   Stats / Values   Freqs (% of Valid)   Valid      Missing  \n---- ---------- ---------------- -------------------- ---------- ---------\n1    death      1. no            689 (91.3%)          755        0        \n     [factor]   2. yes            66 ( 8.7%)          (100.0%)   (0.0%)   \n\n2    anc        1. old           419 (55.5%)          755        0        \n     [factor]   2. new           336 (44.5%)          (100.0%)   (0.0%)   \n\n3    clinic     1. A             497 (65.8%)          755        0        \n     [factor]   2. B             258 (34.2%)          (100.0%)   (0.0%)   \n--------------------------------------------------------------------------"},{"path":"logistic-regression.html","id":"logistic-regression-with-a-single-binary-predictor","chapter":"21 Logistic Regression","heading":"21.1 Logistic regression with a single binary predictor","text":"mission determine relationship anc (anc) type used \nmanaging pregnant women outcome pregnancy (death). answer \nquestion run logistic regression model simplest form belowTable 6.2:  object results glm() model class glm lm. lm also\nused linear modelling using lm() function.","code":"\ndf_anc %>% \n    glm(death ~ anc, family=binomial, data=.) %>% \n    broom::tidy()"},{"path":"analysis-of-variance.html","id":"analysis-of-variance","chapter":"22 Analysis of Variance","heading":"22 Analysis of Variance","text":"","code":""},{"path":"analysis-of-variance.html","id":"introduction-4","chapter":"22 Analysis of Variance","heading":"22.1 Introduction","text":"Hypertension, elevated blood pressure beyond normal, common medical\ncondition, especially adults. treat condition, persons hypertension\noften given blood pressure-lowering drugs. many types drug,\nvarying blood pressure-lowering effects taken. study identify\nblood pressure-lowering effect, four drugs, called , B, C D\nrandomly administered persons hypertension.\nsystolic blood pressure (SBP) measured administration\ndrugs.drop SBP recorded. data systolic.txt captured \nstudy. variables data include drug, drug administered 1, 2,\n3, 4 representing drugs , B, C D, respectively. variables \ndata disease representing diseases present patient 1,\n2, 3 representing Asthma, Diabetes Mellitus (DM) Obesity, systolic\nrepresenting drop systolic blood pressure week starting drug.first read data summarise .data analyst, investigator asks determine data \ndrug highest blood pressure-lowering effect best worst\nperforming drugs. Recollect two drugs \nlikely performing Student t-test .However, four categories answer questions \nt-test. Analysis Variance (ANOVA) simplest form\nkicks . First, visualize distribution SBP-lowering effect \nfour drugs boxplot :Summarizing change SBP drugs administered haveTable 6.2:  figure summary obvious drug greatest\nlowering effect appears , followed B, D C order. \nknow can say sure B better , turn better\nD etc? answer question perform ANOVA.","code":"\ndf_syst <- \n    read.table(\".\\\\Data\\\\systolic.txt\") %>% \n    mutate(\n        drug = factor(drug, levels = 1:4, labels = c(\"A\", \"B\", \"C\", \"D\")),\n        disease = factor(\n            disease, levels = 1:3, \n            labels = c(\"Asthma\", \"DM\", \"Obesity\")\n        )\n    )df_syst %>% summarytools::dfSummary(graph.col = F)\nData Frame Summary  \ndf_syst  \nDimensions: 58 x 3  \nDuplicates: 3  \n\n------------------------------------------------------------------------------------\nNo   Variable    Stats / Values            Freqs (% of Valid)   Valid      Missing  \n---- ----------- ------------------------- -------------------- ---------- ---------\n1    drug        1. A                      15 (25.9%)           58         0        \n     [factor]    2. B                      15 (25.9%)           (100.0%)   (0.0%)   \n                 3. C                      12 (20.7%)                               \n                 4. D                      16 (27.6%)                               \n\n2    disease     1. Asthma                 19 (32.8%)           58         0        \n     [factor]    2. DM                     19 (32.8%)           (100.0%)   (0.0%)   \n                 3. Obesity                20 (34.5%)                               \n\n3    systolic    Mean (sd) : 18.9 (12.8)   32 distinct values   58         0        \n     [integer]   min < med < max:                               (100.0%)   (0.0%)   \n                 -6 < 21 < 44                                                       \n                 IQR (CV) : 19 (0.7)                                                \n------------------------------------------------------------------------------------\ndf_syst %>% \n    ggplot(aes(x = drug, y = systolic, color = drug)) +\n    geom_boxplot()+\n    labs(title = \"Decrease in systolic BP for the various drugs\",\n         x = \"Drug\", color = \"Drug\", \n         y = \"Change in SBP (mmHg)\")+\n    theme_bw()\ndf_syst %>% \n    group_by(drug) %>% \n    rstatix::get_summary_stats(type = \"common\")"},{"path":"analysis-of-variance.html","id":"one-way-analysis-of-variance","chapter":"22 Analysis of Variance","heading":"22.2 One-way analysis of variance","text":"analysis variance parametric test used compare means \ntwo groups. tests null hypothesisH0: population means groups .\nHa: least one population means differ rest.proper ANOVA summarise change SBP different drugs,\npresenting data confidence interval mean.apparent confidence intervals mean change systolic\nblood pressures effect drug quite similar B.\nAlso, B quite different C D. C D hand\nsimilar effects. preliminary finding back minds, \nfit linear regression model .Table 6.3:  ANOVA output p-value order 0.000057! \nsmall indicating least one means significantly differs \nrest.","code":"\ndf_syst %>% \n    aov(systolic ~ drug, data = .) %>% \n    broom::tidy()"},{"path":"analysis-of-variance.html","id":"postestimation-pairwise-comparison","chapter":"22 Analysis of Variance","heading":"22.2.1 Postestimation pairwise comparison","text":"made point ANOVA tell us least one means \nsignificantly different others. pick drug’s mean effect(s)\ndiffer others use post-estimation tests. example \nPairwise t-test.don’t just multiple T-tests present results ? \nt-test designed . significance level \nset single comparisons multiple meaning p-values obtained \ncomparison invalid. Many authors come ways \ncorrecting p-values common one implemented R listed . \nfollowing extract help page functionp.adjust().“adjustment methods include Bonferroni correction (”Bonferroni”) \np-values multiplied number comparisons. Less conservative cor-\nreactions also included Holm (1979) (“Holm”), Hochberg (1988) (“Hochberg”),\nHommel (1988) (“hommel”), Benjamini & Hochberg (1995) (“BH” alias “fdr”),\nBenjamini & Yekutieli (2001) (“”), respectively. pass-option\n(“none”) also included.”determine p-values multiple comparisons various drugs\nusing “holm” methodTable 13.1:  analysis output generated p-values pairwise comparison \nmeans decrease SBP various drugs. can inferred \ndifference reduction B significant (p-value: 0.89214).\nwords, reduction obtained two drugs can said \ncomparable. However, significant difference C, \nD, B C, B D. Also isn’t significant difference C\nD (p-value: 0.50216). arguably informative way showing \npairwise differences can obtained R use Tukey’s\npost-estimation test.Table 6.4:  output shows pairwise differences, 95%CI differences\nTukey’s adjusted p-values. Comparing two methods, Holms Tukey\nobserve multiple comparison p-values differ slightly. However, \nconclusions remain .Conclusion: drugs highest SBP lowering effect B \nevidence one better . C D hand \nsignificantly smaller SBP lowering effects compared B. Drugs C D\ndon’t perform significantly differently .","code":"\ndf_syst %$% \n    pairwise.t.test(\n        x = systolic, g = drug, data = ., p.adjust.methods = \"holm\"\n        ) %>% \n    broom::tidy()\ndf_syst %>% \n    aov(systolic ~ drug, data = .) %>% \n    TukeyHSD() %>% \n    broom::tidy()"},{"path":"analysis-of-variance.html","id":"two-way-analysis-of-variance","chapter":"22 Analysis of Variance","heading":"22.3 Two-Way Analysis of Variance","text":"data, two possible independent variables may explain BP-lowering effect obtained. disease drug administered. Two-way analysis variance, primarily come three hypotheses:H0: population means took various drugs .H0: population means various diseases .H0: significant interaction drug taken disease study participant determining mean BP change.evaluate hypothesis, perform two-way analysis variance interaction.Table 6.5:  analysis output indicates significant difference means various drugs various diseases present study subjects. Also, significant interaction drug disease type. visual look effect, plot means :plot indicates systolic blood pressure among groups disease conditions seem vary significantly drug given. reflected high p-value interaction drug disease.","code":"\ndf_syst %>% \n    aov(systolic ~ drug*disease, data = .) %>% \n    broom::tidy()\ndf_syst %>% \n    aov(systolic ~ drug*disease, data = .) %>% \n    ggeffects::ggeffect(terms = c(\"drug\",\"disease\")) %>% \n    plot()"},{"path":"analysis-of-variance.html","id":"repeated-measure-analysis-of-variance","chapter":"22 Analysis of Variance","heading":"22.4 Repeated measure analysis of variance","text":"Often research, investigator desires determine change outcome repeated measures, often specific time interval. involves measuring outcome study participant multiple times. Since measurements independent, methodology analysis described . two measurements made, paired T-test suffices use . however, 2 measurements study participant. repeated measure used.subsection, use data involves set hypertension patients, whose blood pressures measured every 2 months year.Next, select required variablesAnd view dataNext, need convert data long format view first 6 records.first summarize blood pressures four periods measurement.observe differences four means. , show graphically.may insignificant drop BP period. Next, perform repeated measure ANOVA determine differences means various review periods.","code":"\nset.seed(7)\ndf_sbp <- \n    readxl::read_xlsx(\"./Data/sbp_longitudinal.xlsx\") %>% \n    sample_n(50)\ndf_sbp_selected <-\n    df_sbp %>%  \n    select(sid, sbp0, sbp4, sbp8, sbp12)df_sbp_selected %>% summarytools::dfSummary()\nData Frame Summary  \ndf_sbp_selected  \nDimensions: 50 x 5  \nDuplicates: 0  \n\n-----------------------------------------------------------------------------------------------------------\nNo   Variable      Stats / Values             Freqs (% of Valid)   Graph               Valid      Missing  \n---- ------------- -------------------------- -------------------- ------------------- ---------- ---------\n1    sid           1. AA0991KAB                1 ( 2.0%)                               50         0        \n     [character]   2. AB1053KAA                1 ( 2.0%)                               (100.0%)   (0.0%)   \n                   3. AC0162AGB                1 ( 2.0%)                                                   \n                   4. AD0510KAB                1 ( 2.0%)                                                   \n                   5. AD1208KAB                1 ( 2.0%)                                                   \n                   6. AF0129APA                1 ( 2.0%)                                                   \n                   7. AF0217KAB                1 ( 2.0%)                                                   \n                   8. AF0347TTB                1 ( 2.0%)                                                   \n                   9. AH0084TTB                1 ( 2.0%)                                                   \n                   10. AJ0478APB               1 ( 2.0%)                                                   \n                   [ 40 others ]              40 (80.0%)           IIIIIIIIIIIIIIII                        \n\n2    sbp0          Mean (sd) : 141.3 (20)     28 distinct values       :               50         0        \n     [numeric]     min < med < max:                                    :   :           (100.0%)   (0.0%)   \n                   106 < 139 < 189                                     : . :                               \n                   IQR (CV) : 25.2 (0.1)                             : : : : . :                           \n                                                                   : : : : : : : : :                       \n\n3    sbp4          Mean (sd) : 141.3 (27.1)   35 distinct values     :                 50         0        \n     [numeric]     min < med < max:                                : : .               (100.0%)   (0.0%)   \n                   100 < 136.5 < 215                               : : :                                   \n                   IQR (CV) : 34 (0.2)                             : : : :                                 \n                                                                   : : : : . :                             \n\n4    sbp8          Mean (sd) : 145.2 (32.1)   37 distinct values     :                 50         0        \n     [numeric]     min < med < max:                                . :                 (100.0%)   (0.0%)   \n                   101 < 138.5 < 277                               : : :                                   \n                   IQR (CV) : 38.5 (0.2)                           : : : .                                 \n                                                                   : : : : :   .   .                       \n\n5    sbp12         Mean (sd) : 138.5 (17.9)   37 distinct values     :                 50         0        \n     [numeric]     min < med < max:                                . : : .             (100.0%)   (0.0%)   \n                   110 < 136 < 179                                 : : : :                                 \n                   IQR (CV) : 23.5 (0.1)                           : : : : . :                             \n                                                                   : : : : : : :                           \n-----------------------------------------------------------------------------------------------------------df_sbp_long <- \n    df_sbp_selected %>% \n    pivot_longer(\n        cols = sbp0:sbp12, values_to = \"bp\", names_to = \"period\") %>% \n    mutate(\n        period = factor(period, levels = c(\"sbp0\", \"sbp4\", \"sbp8\", \"sbp12\")))\n\ndf_sbp_long %>% head()\n# A tibble: 6 × 3\n  sid       period    bp\n  <chr>     <fct>  <dbl>\n1 NG0200AGB sbp0     130\n2 NG0200AGB sbp4     127\n3 NG0200AGB sbp8     119\n4 NG0200AGB sbp12    147\n5 RA0112KAA sbp0     187\n6 RA0112KAA sbp4     207df_sbp_long %>% \n    group_by(period) %>% \n    summarize(Mean = mean(bp), SD = sd(bp))\n# A tibble: 4 × 3\n  period  Mean    SD\n  <fct>  <dbl> <dbl>\n1 sbp0    141.  20.0\n2 sbp4    141.  27.1\n3 sbp8    145.  32.1\n4 sbp12   139.  17.9\ndf_sbp_long %>% \nggplot(aes(x = period, y = bp, group = sid)) +\n    geom_line(alpha =.1, col = \"red\") +\n    stat_summary(\n        fun.data = mean_sdl, \n        geom=\"line\", \n        colour = \"black\", \n        linewidth = .8, \n        group=1, linetype = 2) +\n    labs(x = \"Time Blood pressure taken\",\n         y = \"Blood pressure (mmHg)\",\n         title = \"Variation of blood pressure over the review periods\",\n         subtitle = \"Sampling done on all patients\",\n         caption = \"Source: 2010 data\")+\n    theme_bw()aov(bp ~ period + Error(sid/period), data = df_sbp_long) %>% broom::tidy()\n# A tibble: 3 × 7\n  stratum    term         df  sumsq meansq statistic p.value\n  <chr>      <chr>     <dbl>  <dbl>  <dbl>     <dbl>   <dbl>\n1 sid        Residuals    49 61977.  1265.    NA      NA    \n2 sid:period period        3  1131.   377.     0.924   0.431\n3 sid:period Residuals   147 59984.   408.    NA      NA    "},{"path":"analysis-of-variance.html","id":"analysis-of-covariance","chapter":"22 Analysis of Variance","heading":"22.5 Analysis of covariance","text":"","code":""},{"path":"analysis-of-variance.html","id":"multivariate-analysis-of-variance","chapter":"22 Analysis of Variance","heading":"22.6 Multivariate Analysis of Variance","text":"","code":""},{"path":"analysis-of-variance.html","id":"kruskal-wallis-test","chapter":"22 Analysis of Variance","heading":"22.7 Kruskal Wallis Test","text":"beginning section, noted ANOVA parametric test.\nTherefore requires approximately normally distributed dependent data work\n. data deviates significantly normality? \nconditions use Kruskal-Wallis test, non-parametric equivalent \none-way ANOVA. tests null hypothesisH0: population distribution (centre) groups .\nHa: least one population distributions (centre) differs \nrest.use systolic blood pressure drug used beforeWith small p-value, conclude centre least one effects\ndrug significantly different others. conclusion \ndifferent derived analysis variance. least centre\none systolic blood pressure significantly different another","code":"df_syst %$% kruskal.test(systolic, drug) %>% broom::tidy()\n# A tibble: 1 × 4\n  statistic  p.value parameter method                      \n      <dbl>    <dbl>     <int> <chr>                       \n1      20.5 0.000136         3 Kruskal-Wallis rank sum test"},{"path":"analysis-of-variance.html","id":"assumptions-1","chapter":"22 Analysis of Variance","heading":"22.8 Assumptions","text":"","code":""},{"path":"ordinal-logistic-regression.html","id":"ordinal-logistic-regression","chapter":"23 Ordinal logistic regression","heading":"23 Ordinal logistic regression","text":"","code":""},{"path":"ordinal-logistic-regression.html","id":"importing-data","chapter":"23 Ordinal logistic regression","heading":"23.1 Importing data","text":"presentation, analyse dataset using ordinal logistic regression.\nbegin reading data selecting desired subset.view summary dataNote anemia_cat variable ordered factor variable.\ncompleteness single missing observation variable hosp_adm\nrecoded .","code":"\ndataF <- \n    dget(\"./Data/anemia_data\") %>% \n    select(sid, anemia_cat, community, fever, sex,\n           famsize, moccup2, foccup2, hosp_visit)dataF %>% glimpse()\nRows: 476\nColumns: 9\n$ sid        <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, …\n$ anemia_cat <fct> Mild, Moderate, Normal, Severe, Mild, M…\n$ community  <fct> Kasei, Kasei, Kasei, Kasei, Kasei, Kase…\n$ fever      <fct> Yes, Yes, Yes, Yes, Yes, No, No, Yes, Y…\n$ sex        <fct> Female, Female, Female, Male, Male, Fem…\n$ famsize    <dbl> 4, 4, 2, 3, 5, 4, 9, 4, 4, 10, 3, 4, 3,…\n$ moccup2    <fct> Farmer, Farmer, Other, Other, Farmer, F…\n$ foccup2    <fct> Farmer, Farmer, Other, Farmer, Farmer, …\n$ hosp_visit <fct> No, No, No, Yes, Yes, No, No, No, No, Y…dataF <- dataF %>% \n    mutate(hosp_visit = forcats::fct_explicit_na(hosp_visit, na_level = \"No\"))\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `hosp_visit =\n  forcats::fct_explicit_na(hosp_visit, na_level = \"No\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\nsummary(dataF)\n      sid           anemia_cat       community   fever    \n Min.   :  1.0   Normal  : 92   Asuogya   : 61   No :160  \n 1st Qu.:119.8   Mild    :143   Sunkwae   : 62   Yes:316  \n Median :240.5   Moderate:226   Dromankoma:229            \n Mean   :240.2   Severe  : 15   Kasei     :124            \n 3rd Qu.:360.2                                            \n Max.   :501.0                                            \n     sex         famsize         moccup2      foccup2   \n Male  :252   Min.   : 0.000   Farmer:314   Farmer:355  \n Female:224   1st Qu.: 4.000   Other :162   Other :121  \n              Median : 5.000                            \n              Mean   : 5.151                            \n              3rd Qu.: 6.000                            \n              Max.   :11.000                            \n hosp_visit\n No :320   \n Yes:156   \n           \n           \n           \n           "},{"path":"ordinal-logistic-regression.html","id":"model-specification","chapter":"23 Ordinal logistic regression","heading":"23.2 Model specification","text":"Now begin ordinal regression fixing first model, Null model.Subsequently, introduce fever variable independent express \nresults 95%CItermestimatestd.errorstatisticp.valueconf.lowconf.highcoef.typecharacternumericnumericnumericnumericnumericnumericcharacterNormal|Mild0.3060.163-7.2680.000interceptMild|Moderate1.2570.1521.5050.132interceptModerate|Severe40.1110.29312.6010.000interceptfeverYes1.4610.1812.0900.0371.0242.086locationResults indicate significant association fever degree anaemia (=1.46, 95%CI: 1.02 2.09). Performing ANOVA test see exists difference 2 models.results indicate adding fever Null model significantly improves null model.Next, add community variabletermestimatestd.errorstatisticp.valueconf.lowconf.highcoef.typecharacternumericnumericnumericnumericnumericnumericcharacterNormal|Mild0.1910.286-5.7890.000interceptMild|Moderate0.8080.274-0.7750.438interceptModerate|Severe27.0580.3678.9850.000interceptfeverYes1.3730.1831.7280.0840.9581.966locationcommunitySunkwae1.1790.3430.4790.6320.6022.314locationcommunityDromankoma0.6260.268-1.7470.0810.3681.054locationcommunityKasei0.4630.289-2.6590.0080.2610.813location","code":"Model_0 <- ordinal::clm(anemia_cat ~ 1, data = dataF, link = \"logit\")\nsummary(Model_0)\nformula: anemia_cat ~ 1\ndata:    dataF\n\n link  threshold nobs logLik  AIC     niter max.grad\n logit flexible  476  -543.39 1092.77 7(0)  2.15e-13\n cond.H \n 1.4e+01\n\nThreshold coefficients:\n                Estimate Std. Error z value\nNormal|Mild     -1.42885    0.11608 -12.310\nMild|Moderate   -0.02521    0.09168  -0.275\nModerate|Severe  3.42535    0.26237  13.056\nModel_1 <- ordinal::clm(anemia_cat ~ fever, data = dataF, link = \"logit\")\n\nbroom::tidy(Model_1, conf.int = TRUE, exponentiate = TRUE)%>% \n    flextable::as_flextable() %>% \n    flextable::colformat_double(\n        j = c(\"estimate\", \"std.error\", \"statistic\", \"p.value\", \n              \"conf.low\", \"conf.high\"), \n        digits = 3)anova(Model_0, Model_1)\nLikelihood ratio tests of cumulative link models:\n \n        formula:           link: threshold:\nModel_0 anemia_cat ~ 1     logit flexible  \nModel_1 anemia_cat ~ fever logit flexible  \n\n        no.par    AIC  logLik LR.stat df Pr(>Chisq)  \nModel_0      3 1092.8 -543.39                        \nModel_1      4 1090.4 -541.20  4.3658  1    0.03667 *\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nModel_2 <- \n     ordinal::clm(anemia_cat ~ fever + community, data = dataF, link = \"logit\")\n\nbroom::tidy(Model_2, conf.int = TRUE, exponentiate = TRUE)%>% \n    flextable::as_flextable() %>% \n    flextable::colformat_double(\n        j = c(\"estimate\", \"std.error\", \"statistic\", \"p.value\", \n              \"conf.low\", \"conf.high\"), \n        digits = 3)"},{"path":"ordinal-logistic-regression.html","id":"checking-proportional-odds-assumption-for-the-model","chapter":"23 Ordinal logistic regression","heading":"23.3 Checking proportional odds assumption for the model","text":"check proportional odd assumption second modelThe significant p-value community variable indicates breach proportional odd assumption","code":"ordinal::nominal_test(Model_2)\nTests of nominal effects\n\nformula: anemia_cat ~ fever + community\n          Df  logLik    AIC     LRT Pr(>Chi)   \n<none>       -534.53 1083.1                    \nfever      2 -534.34 1086.7  0.3792 0.827302   \ncommunity  6 -525.17 1076.3 18.7124 0.004678 **\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"ordinal-logistic-regression.html","id":"prediction","chapter":"23 Ordinal logistic regression","heading":"23.4 Prediction","text":"section, use model created predict observation specific anaemia severity group. First, begin forming prediction data call newData.now predict probability specific predictor combination falls within specific outcome category (anaemia category)better visualisation, bind original data predictions\nTable 6.7: Probabilities\n","code":"NewData <- expand.grid(community = levels(dataF$community),\n                       fever = levels(dataF$fever))\nNewData\n   community fever\n1    Asuogya    No\n2    Sunkwae    No\n3 Dromankoma    No\n4      Kasei    No\n5    Asuogya   Yes\n6    Sunkwae   Yes\n7 Dromankoma   Yes\n8      Kasei   Yes(preds <- predict(Model_2, newdata = NewData, type = \"prob\"))\n$fit\n     Normal      Mild  Moderate     Severe\n1 0.1601782 0.2868320 0.5173493 0.03564053\n2 0.1392894 0.2675468 0.5514246 0.04173921\n3 0.2335081 0.3300308 0.4138463 0.02261481\n4 0.2915487 0.3440404 0.3475709 0.01684010\n5 0.1220012 0.2486393 0.5810802 0.04827929\n6 0.1054658 0.2277287 0.6103913 0.05641416\n7 0.1816335 0.3030775 0.4845071 0.03078186\n8 0.2306604 0.3289444 0.4174245 0.02297070\nbind_cols(NewData, preds$fit) %>% \n    kableExtra::kbl(caption = \"Probabilities\", booktabs = T, digits = 3) %>%\n    kableExtra::kable_classic(full_width = F, html_font = \"Cambria\") %>% \n    kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\"))"},{"path":"ordinal-logistic-regression.html","id":"visualising-the-model","chapter":"23 Ordinal logistic regression","heading":"23.5 Visualising the model","text":"visualize model using MASS effects packages. begin fitting model polr function.visualise probability various forms anaemia giving one belonging various groups.","code":"\npol_model.1 <- MASS::polr(anemia_cat ~ community, data = dataF)\npol_model.2 <- MASS::polr(anemia_cat ~ fever*community, data = dataF)M1 <- effects::Effect(focal.predictors = \"community\", mod=pol_model.1)\n\nRe-fitting to get Hessian\nM2 <- effects::Effect(focal.predictors = c(\"community\", \"fever\"), mod=pol_model.2)\n\nRe-fitting to get Hessian\nplot(M1)\nplot(M2)"},{"path":"survival-analysis.html","id":"survival-analysis","chapter":"24 Survival analysis","heading":"24 Survival analysis","text":"","code":""},{"path":"cox-regression.html","id":"cox-regression","chapter":"25 Cox Regression","heading":"25 Cox Regression","text":"","code":""},{"path":"blocks.html","id":"blocks","chapter":"26 Blocks","heading":"26 Blocks","text":"","code":""},{"path":"blocks.html","id":"equations","chapter":"26 Blocks","heading":"26.1 Equations","text":"equation.\\[\\begin{equation}\n  f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k}\n  \\tag{26.1}\n\\end{equation}\\]may refer using \\@ref(eq:binom), like see Equation (26.1).","code":""},{"path":"blocks.html","id":"theorems-and-proofs","chapter":"26 Blocks","heading":"26.2 Theorems and proofs","text":"Labeled theorems can referenced text using \\@ref(thm:tri), example, check smart theorem 26.1.Theorem 26.1  right triangle, \\(c\\) denotes length hypotenuse\n\\(\\) \\(b\\) denote lengths two sides, \n\\[^2 + b^2 = c^2\\]Read https://bookdown.org/yihui/bookdown/markdown-extensions--bookdown.html.","code":""},{"path":"blocks.html","id":"callout-blocks","chapter":"26 Blocks","heading":"26.3 Callout blocks","text":"bs4_book theme also includes special callout blocks, like .rmdnote.can use markdown inside block.user define appearance blocks LaTeX output.may also use: .rmdcaution, .rmdimportant, .rmdtip, .rmdwarning block name.R Markdown Cookbook provides help use custom blocks design callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html","code":"head(beaver1, n = 5)\n  day time  temp activ\n1 346  840 36.33     0\n2 346  850 36.34     0\n3 346  900 36.35     0\n4 346  910 36.42     0\n5 346  920 36.55     0"},{"path":"footnotes-and-citations.html","id":"footnotes-and-citations","chapter":"27 Footnotes and citations","heading":"27 Footnotes and citations","text":"","code":""},{"path":"footnotes-and-citations.html","id":"footnotes","chapter":"27 Footnotes and citations","heading":"27.1 Footnotes","text":"Footnotes put inside square brackets caret ^[]. Like one 1.","code":""},{"path":"footnotes-and-citations.html","id":"citations","chapter":"27 Footnotes and citations","heading":"27.2 Citations","text":"Reference items bibliography file(s) using @key.example, using bookdown package2 (check last code chunk index.Rmd see citation key added) sample book, built top R Markdown knitr3 (citation added manually external file book.bib).\nNote .bib files need listed index.Rmd YAML bibliography key.bs4_book theme makes footnotes appear inline click . example book, added csl: chicago-fullnote-bibliography.csl index.Rmd YAML, include .csl file. download new style, recommend: https://www.zotero.org/styles/RStudio Visual Markdown Editor can also make easier insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations","code":""},{"path":"cross.html","id":"cross","chapter":"28 Cross-references","heading":"28 Cross-references","text":"Cross-references make easier readers find link elements book.","code":""},{"path":"cross.html","id":"chapters-and-sub-chapters","chapter":"28 Cross-references","heading":"28.1 Chapters and sub-chapters","text":"two steps cross-reference heading:Label heading: # Hello world {#nice-label}.\nLeave label like automated heading generated based heading title: example, # Hello world = # Hello world {#hello-world}.\nlabel un-numbered heading, use: # Hello world {-#nice-label} {# Hello world .unnumbered}.\nLeave label like automated heading generated based heading title: example, # Hello world = # Hello world {#hello-world}.label un-numbered heading, use: # Hello world {-#nice-label} {# Hello world .unnumbered}.Next, reference labeled heading anywhere text using \\@ref(nice-label); example, please see Chapter 28.\nprefer text link instead numbered reference use: text want can go .\nprefer text link instead numbered reference use: text want can go .","code":""},{"path":"cross.html","id":"captioned-figures-and-tables","chapter":"28 Cross-references","heading":"28.2 Captioned figures and tables","text":"Figures tables captions can also cross-referenced elsewhere book using \\@ref(fig:chunk-label) \\@ref(tab:chunk-label), respectively.See Figure 28.1.\nFigure 28.1: nice figure!\nDon’t miss Table 28.1.Table 28.1: nice table!","code":"\npar(mar = c(4, 4, .1, .1))\nplot(pressure, type = 'b', pch = 19)\nknitr::kable(\n  head(pressure, 10), caption = 'Here is a nice table!',\n  booktabs = TRUE\n)"},{"path":"parts.html","id":"parts","chapter":"29 Parts","heading":"29 Parts","text":"can add parts organize one book chapters together. Parts can inserted top .Rmd file, first-level chapter heading file.Add numbered part: # (PART) Act one {-} (followed # chapter)Add unnumbered part: # (PART\\*) Act one {-} (followed # chapter)Add appendix special kind un-numbered part: # (APPENDIX) stuff {-} (followed # chapter). Chapters appendix prepended letters instead numbers.","code":""},{"path":"sharing-your-book.html","id":"sharing-your-book","chapter":"30 Sharing your book","heading":"30 Sharing your book","text":"","code":""},{"path":"sharing-your-book.html","id":"publishing","chapter":"30 Sharing your book","heading":"30.1 Publishing","text":"HTML books can published online, see: https://bookdown.org/yihui/bookdown/publishing.html","code":""},{"path":"sharing-your-book.html","id":"pages","chapter":"30 Sharing your book","heading":"30.2 404 pages","text":"default, users directed 404 page try access webpage found. ’d like customize 404 page instead using default, may add either _404.Rmd _404.md file project root use code /Markdown syntax.","code":""},{"path":"sharing-your-book.html","id":"metadata-for-sharing","chapter":"30 Sharing your book","heading":"30.3 Metadata for sharing","text":"Bookdown HTML books provide HTML metadata social sharing platforms like Twitter, Facebook, LinkedIn, using information provide index.Rmd YAML. setup, set url book path cover-image file. book’s title description also used.bs4_book provides enhanced metadata social sharing, chapter shared unique description, auto-generated based content.Specify book’s source repository GitHub repo _output.yml file, allows users view chapter’s source file suggest edit. Read features output format :https://pkgs.rstudio.com/bookdown/reference/bs4_book.htmlOr use:","code":"\n?bookdown::bs4_book"}]
