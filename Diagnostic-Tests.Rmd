
# Diagnostic Tests

```{r include=F}
library(tidyverse)
library(magrittr)
library(huxtable)
```

Scientific testing for the presence of various disease conditions or processes 
is very common in everyday life. This could range from the complex testing for 
the presence of strange diseases to newly manufactured electrical gadgets for 
defects. Very often there is a Gold Standard test, one that is deemed to 
perfectly determine the presence or absence of the condition. However there is
always the search for alternative test often because they are cheaper or easier 
to use compared to the Gold standard.

In a study to diagnose malaria in children attending an outpatient clinic in 
Ghana, children with a clinical suspicion of malaria were tested using three 
methods. First a blood film reported as a count of the malaria parasites 
(Gold standard) was done. Two rapid diagnostic kits, called here RDT.1 and RDT.2 
were also done concurrently and reported as positive (1) or negative (0). These 
were done for 100 patients and recorded in `malaria.csv`. Our task is to 
evaluate RDT.1's ability to accurately and reliably diagnose malaria.

First we read in the data

```{r message=F}
df_malaria <- 
    read_csv("./Data/malaria.txt") %>% 
    mutate(
        gold = ifelse(mps == 0, 0, 1) %>% 
            factor(levels = c(1,0),
                   labels = c("Positive", "Negative")),
        across(
            c(rdt.1, rdt.2), 
            ~factor(
                .x, 
                levels = c(1,0),
                labels = c("Positive", "Negative"),
            )
        )
    )
```

Summary of the data is as shown below

```{r include=F}
options(huxtable.knit_print_df = F)
```


```{r}
df_malaria %>% summarytools::dfSummary(graph.col = F)
```


```{r include=F}
options(huxtable.knit_print_df = T)
```

And then tabulate rdt.1 and the Gold Standard as 

```{r}
df_malaria %>% 
    gtsummary::tbl_cross(
        col = gold,
        row = rdt.1,
        label = list(
            gold ~ "Gold Standard",
            rdt.1 ~ "First RDT"
        )
    ) %>% 
    gtsummary::bold_labels()
```

The table above decomposes the the test results into 4 distinct categories.

1. Those who had both RDT.1 and the gold standard positive (True positive) were 50.
1. The group with both RDT.1 and Gold standard negative (True Negative) were 44.
1. The group that apparently showed a positive RDT.1 results when they actually are negative by the Gold standard (False positive) were 2.
1. Finally the last group, those whose RDT.1 result were negative but are actually positive
judging by the Gold standard (False negative) were 4.

We operationalise these by extracting relevant portions of the table below

```{r}
tp <- 50
tn <- 44
fp <- 2
fn <- 4
```

## True prevalence of the disease
The true prevalence of the disease is the proportion of the diseased individuals 
observed in the study population as determine by the gold standard. This is 
mathematically given by
 $$True~prevalence = \frac{tp + fn}{tp + tn + fp + fn}$$


And determined with our data as

```{r}
true.prevalence <- (tp+fn)/(tp+tn+fp+fn)
true.prevalence
```

## Apparent prevalence of the disease
The apparent prevalence of the disease is the proportion of the diseased 
individuals observed in the study population as determine by the RDT.1 test. 
This is mathematically given by
 $$Apparent~prevalence = \frac{tp + fp}{tp + tn + fp + fn}$$
And determined with our data by
```{r}
apparent.prevalence<-(tp+fp)/(tp+tn+fp+fn)
apparent.prevalence
```

## Sensitivity of a test
The sensitivity of a test defines as the proportion of individuals with the 
disease who are correctly identified by the test applied. It ranges form 0, a completely useless test to 1,a perfect test. Mathematically this is defined as

$$Sensitivity = \frac{tp}{tp + fn}$$
And is determined as below
```{r}
sensitivity <- tp/(tp+fn)
sensitivity
```

## Specificity of a test
The specificity of a test is defined as proportion of individuals without the 
disease who are correctly identified by the test used. It ranges form 0, a 
completely useless test to 1, a perfect test. Mathematically this is defined as
$$Specificity = \frac{tn}{tn + fp}$$

And determine as below
```{r}
specificity<-tn/(tn+fp)
specificity
```

## Predictive value of a test
### Positive predictive value of a test
The positive predictive value (ppv) of a test is defined as the proportion of 
individuals with a positive test result who have the disease. This is a more 
useful measure compared to the sensitivity and specificity because it indicates 
how much weight one has to put on a positive test result when confronted with 
one. Mathematically it is defined as:

$$PPV = \frac{tp}{tp + fp}$$
```{r}
ppv <- tp/(tp+fp)
ppv
```

### Negative predictive value of a test
The negative predictive value (npv) of a test is defined as the proportion of 
individuals with a negative test result who do not have the disease. As with 
the ppv this is a more useful measure compared to the sensitivity and 
specificity as it indicates how much weight one has to put on a negative test 
result when confronted with one. Mathematically it is defined as:
$$NPV = \frac{tn}{tn + fn}$$
And determined as below

```{r}
npv <- tn/(tn+fn)
npv
```


## Likelihood ratio of a test
The likelihood ratio of a test is another way of expressing its usefulness. 
Unlike the previous statistics about tests the likelihood ratios stretch beyond 
0 to 1. A likelihood ratio of 1 indicates a useless (non-discriminatory) test.

### The Positive likelihood ratio (LR+) 
This is the ratio of the chance of a positive result if the patient has the 
disease to the chance of a positive result if he does not have the disease. The 
higher the positive likelihood the better the test.

This is mathematically equivalent to

$$LR+ = \frac{Sensitivity}{1-Specificity}$$

Applying this to our data so far we have

```{r}
pLR <- sensitivity/(1-specificity)
pLR
```

### Negative liklihood ratio (LR-)
The negative likelihood ratio (LR-) on the other hand is the ratio of the 
chance of a person having a negative result having the disease to the chance of 
a negative result in a person not having the disease. The lower the negative 
likelihood the better the test.

Computationally this is equivalent to
$$LR+ = \frac{1-Sensitivity}{Specificity}$$
Applying this to our data so far we have
```{r}
nLR<-(1-sensitivity)/specificity
nLR
```


## Summary
Fortunately all these can be obtained in one go using the `epi.tests()` function 
from the `epiR`package. The function however requires a table formatted in a 
specific way. Below we creat the table

```{r}
table.test <- 
    df_malaria %$%
    table(rdt.1, gold)

table.test
```

And then we evaluate the test

```{r}
table.test %>% epiR::epi.tests()
```

**Conclusion**: With the high (all above 0.9) Sensitivity, Specificity, PPV and 
NPV this appears to be a very good test. This is confirmed by the relatively 
high LR+ and low LR-.











