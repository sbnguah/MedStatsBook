
```{r echo =F, include=F}
library(tidyverse)
library(magrittr)
library(huxtable)
```

# Analysis of Variance
## Introduction
Hypertension, an elevated blood pressure beyond normal, is a very common medical 
condition especially in adults. To treat this condition persons with hypertension 
are often given blood pressure lowering drugs. There are many types of this drug, 
with varying blood pressure lowering effects when taken. In a study to identify 
the blood pressure lowering effect four of such drugs, here called A, B, C and D 
were randomly administered to persons with hypertension.
Their systolic blood pressure (SBP) were measured before and after administration 
of the drugs.

The drop in SBP was then recorded. The data `systolic.txt` was captured from this 
study. The variables in the data include `drug`, the drug administered with 1, 2, 
3, and 4 representing drugs A, B, C and D respectively. The other variables in 
the data are `disease` representing other diseases present in the patient with 1, 
2, 3 representing Asthma, Diabetes Mellitus (DM) and Obesity, and systolic 
representing the drop in systolic blood pressure a week after starting the drug.

We first read in the data and summarise it.

```{r}
df_syst <- 
    read.table(".\\Data\\systolic.txt") %>% 
    mutate(
        drug = factor(drug, levels = 1:4, labels = c("A", "B", "C", "D")),
        disease = factor(
            disease, levels = 1:3, 
            labels = c("Asthma", "DM", "Obesity")
        )
    )
```

```{r echo=F}
options(huxtable.knit_print_df = F)
```

```{r in}
df_syst %>% summarytools::dfSummary(graph.col = F)
```


```{r echo=F}
options(huxtable.knit_print_df = T)
```

As the data analyst the investigator asks you to tell him from the data which 
drug has the highest blood pressure lowering effect, the best and worst 
performing drugs in this regard. Recollect that if there were only two drugs we 
would most likely to performing a Student t-test for this.

However, we have four categories and as such cannot answer these questions with 
the t-test. This is where the Analysis of Variance (anova) in its simplest form 
kicks in. First we visualize the distribution of the SBP lowering effect in all 
four drugs in the boxplot below:

```{r fig.width=6, fig.height=4}
df_syst %>% 
    ggplot(aes(x = drug, y = systolic, color = drug)) +
    geom_boxplot()+
    labs(title = "Decrease in systolic BP for the various drugs",
         x = "Drug", color = "Drug", 
         y = "Change in SBP (mmHg)")+
    theme_bw()
```

Summarizing the change in SBP by the drugs administered we have

```{r}
df_syst %>% 
    group_by(drug) %>% 
    rstatix::get_summary_stats(type = "common")
```

From the figure and the summary above it is obvious the drug with the greatest 
lowering effect appears to be A, followed by B, D and C in that order. How do we 
know if we can say for sure that B is better than A, which in turn is better 
than D etc? To answer this question we perform an anova.

## Fitting the anova
The analysis of variance is a parametric test used to compare means for more 
than two groups. It tests the null hypothesis

> **H0**: The population means of all the groups are the same.
> **Ha**: At least one of the population means differ from the rest.

Before we do proper anova we summarise the change in SBP for the different drugs, 
presenting the data with the confidence interval of the mean.

It is apparent from the confidence intervals of the mean change in systolic 
blood pressures that the the effect of drug A is quite similar to that of B. 
Also, both A and B are quite different from C and D. C and D on the other hand 
have similar effect. With this preliminary finding at the back of our minds we 
fit a linear regression model as below.

```{r}
df_syst %>% aov(systolic ~ drug, data = .) %>% broom::tidy()
```

From the anova output above we have a p-value of the order 0.000057! This is 
very small indicating at least one of our means significantly differ from the 
rest.

## Postestimation pairwise comparison
We have made the point that anova only tell us at least one of the means is 
significantly different from the others. To pick up which drug's mean effect(s) 
differ from the others we use post-estimation tests. An example is the 
Pairwise t-test.

So why don't we just do multiple T-tests and present the results as such? This 
is because the t-test is not designed for this. The signicance level is only 
set up for single comparisons not multiple meaning the p-values obtained for 
such comparison will be invalid. Many authors have come up with ways of 
correcting these p-values with the common one implemented in R listed below. The 
following is an extract from the help page of function` p.adjust()`.

>"The adjustment methods include the Bonferroni correction ("bonferroni") in which
the p-values are multiplied by the number of comparisons. Less conservative cor-
rections are also included by Holm (1979) ("holm"), Hochberg (1988) ("hochberg"),
Hommel (1988) ("hommel"), Benjamini & Hochberg (1995) ("BH" or its alias "fdr"),
and Benjamini & Yekutieli (2001) ("BY"), respectively. A pass-through option
("none") is also included."

Below we determine the p-values for the multiple comparison of the various drugs 
using the "holm" method

```{r}
df_syst %$% 
    pairwise.t.test(
        x = systolic, g = drug, data = ., p.adjust.methods = "holm"
        ) %>% 
    broom::tidy()
```

The analysis output generated above are p-values of pairwise comparison of the 
means of the decrease in SBP for the various drugs. It can be inferred that the 
difference in the reduction between A and B is not significant (p-value: 0.89214). 
In other words the reduction obtained for the two drugs can be said to be 
comparable. However there is a significant difference between both A and C, A 
and D, B and C, and B and D. Also there isn't a significant difference between C 
and D (p-value: 0.50216). An arguably more informative way of showing these 
pairwise difference can be obtained in R by the use of the Tukey's 
post-estimation test. 

```{r}
df_syst %>% 
    aov(systolic ~ drug, data = .) %>% 
    TukeyHSD() %>% 
    broom::tidy()
```

The output above shows the pairwise differences, the 95%CI of the differences 
and the Tukey's adjusted p-values. Comparing the two methods, Holms and Tukey 
we observe the multiple comparison p-values differ slightly. However the 
conclusions remain the same.

**Conclusion**: The drugs with the highest SBP lowering effect are A and B with 
no evidence that one does better than the other. C and D on the other hand have 
significantly smaller SBP lowering effect compared to A and B. Drugs C and D 
don't perform significantly different from each other.

## Kruskal Wallis Test
In the beginning of this section we noted that anova is a parametric test. 
Therefore it requires approximately normally distributed dependent data to work 
with. So what if the data deviates significantly from normality? Under those 
conditions we use the Kruskal Wallis test, the non-parametric equivalent of the 
one way ANOVA. This tests the null hypothesis 

> H0: The population distribution (or centre) of all the groups are the same.
> Ha: At least one of the population distributions (or centre) differ from the 
rest.

Below we use this on the systolic blood pressure and drug used as before

```{r}
df_syst %$% kruskal.test(systolic, drug) %>% broom::tidy()
```

With the small p-value we conclude that the centre of at least one of the effect 
of the drug is significantly different from the others. This conclusion is not 
different from that derived with the analysis of variance. At least the centre 
of one of the systolic blood pressure is significantly different from another





## Assumptions

## One-way ANOVA

## Two-way ANOVA